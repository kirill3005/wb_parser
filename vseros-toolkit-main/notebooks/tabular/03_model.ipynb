{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6467f2",
   "metadata": {},
   "source": [
    "# 03 • Model & Blending (CV → OOF → Blend → Calib/τ → Submit)\n",
    "\n",
    "Цель: за 2–3 клика обучить/собрать кандидатов, сравнить по OOF, сделать бленд, при необходимости откалибровать/подобрать порог и сформировать сабмит.\n",
    "\n",
    "Шаги:\n",
    "1) Выбери `RUN_TAG` набора фич → «Проверить набор»\n",
    "2) Отметь кандидатов и запусти `Dry-run`, затем `Train selected`\n",
    "3) Загрузить готовые прогоны → сравнить → собрать бленд\n",
    "4) (Опционально) Калибровка/τ\n",
    "5) Собрать сабмит CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* ipywidgets v8 (JupyterLab 4) */\n",
    ".jp-OutputArea .widget-button .widget-label { \n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "/* fallback для ipywidgets v7 */\n",
    ".jupyter-widgets.widget-button .widget-label {\n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time, math, subprocess, textwrap, shutil, pickle, gc, uuid, warnings, glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "try:\n",
    "    import ipywidgets as w\n",
    "    from IPython.display import display, clear_output, HTML\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Нужен пакет ipywidgets (pip install ipywidgets)\") from e\n",
    "\n",
    "# -------------------- helpers --------------------\n",
    "def now_tag(prefix=\"run\"):\n",
    "    return f\"{prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def run_cmd(args, cwd=None, stream=False, log_file=None):\n",
    "    \"\"\"\n",
    "    args: list[str] - команда\n",
    "    stream: True → потоковый вывод в ячейку\n",
    "    log_file: путь для записи лога (append)\n",
    "    \"\"\"\n",
    "    if stream:\n",
    "        proc = subprocess.Popen(args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "        lines = []\n",
    "        if log_file:\n",
    "            Path(log_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "            lf = open(log_file, \"a\", encoding=\"utf-8\")\n",
    "        else:\n",
    "            lf = None\n",
    "        try:\n",
    "            for line in proc.stdout:\n",
    "                print(line, end=\"\")\n",
    "                if lf: lf.write(line)\n",
    "                lines.append(line)\n",
    "        finally:\n",
    "            if lf: lf.close()\n",
    "        code = proc.wait()\n",
    "        return code, \"\".join(lines)\n",
    "    else:\n",
    "        res = subprocess.run(args, cwd=cwd, capture_output=True, text=True)\n",
    "        if log_file:\n",
    "            Path(log_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(res.stdout)\n",
    "                f.write(res.stderr)\n",
    "        return res.returncode, (res.stdout + res.stderr)\n",
    "\n",
    "def tail_log(path, n=120):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return f\"[нет лога] {p}\"\n",
    "    with p.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        data = f.readlines()\n",
    "    return \"\".join(data[-n:])\n",
    "\n",
    "def read_json(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def write_json(path, obj):\n",
    "    p = Path(path); p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def try_read_parquet(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    try:\n",
    "        return pd.read_parquet(p)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            import fastparquet  # noqa\n",
    "            return pd.read_parquet(p, engine=\"fastparquet\")\n",
    "        except Exception:\n",
    "            raise e\n",
    "\n",
    "def mem_df_gb(df: pd.DataFrame) -> float:\n",
    "    try:\n",
    "        return float(df.memory_usage(deep=True).sum())/(1024**3)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def list_run_tags(sets_root=\"artifacts/sets\"):\n",
    "    base = Path(sets_root)\n",
    "    if not base.exists():\n",
    "        return []\n",
    "    return sorted([p.name for p in base.iterdir() if p.is_dir()])\n",
    "\n",
    "UI_STATE_PATH = Path(\".tmp/model_ui_state.json\")\n",
    "def load_ui_state():\n",
    "    return read_json(UI_STATE_PATH) or {}\n",
    "\n",
    "def save_ui_state(d):\n",
    "    write_json(UI_STATE_PATH, d)\n",
    "\n",
    "def autoload_or(default, key):\n",
    "    st = load_ui_state()\n",
    "    return st.get(key, default)\n",
    "\n",
    "def badge(text, color=\"#0a0\"):\n",
    "    return HTML(f\"<span style='display:inline-block;background:{color};color:#fff;padding:3px 8px;border-radius:7px;font-weight:600'>{text}</span>\")\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_LAYOUT = w.Layout(min_width=\"220px\", width=\"auto\", height=\"36px\", flex=\"0 0 auto\")\n",
    "ROW_LAYOUT = w.Layout(flex_flow=\"row wrap\", grid_gap=\"8px\")\n",
    "GRID_LAYOUT = w.Layout(grid_template_columns=\"repeat(3, minmax(220px, 1fr))\", grid_gap=\"8px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбор набора фич\n",
    "RUN_TAG = w.Combobox(\n",
    "    placeholder=\"RUN_TAG (из artifacts/sets/*)\",\n",
    "    options=list_run_tags(),\n",
    "    value=autoload_or(\"\", \"RUN_TAG\"),\n",
    "    description=\"RUN_TAG\",\n",
    "    ensure_option=False,\n",
    "    layout=w.Layout(width=\"50%\")\n",
    ")\n",
    "SETS_DIR = w.Text(value=autoload_or(\"\", \"SETS_DIR\"), description=\"SETS_DIR\", layout=w.Layout(width=\"70%\"))\n",
    "BTN_AUTOFILL = w.Button(description=\"Автоподстановка\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "BTN_CHECK_SET = w.Button(description=\"Проверить набор\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "OUT_SET = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def autofill_sets_dir(_):\n",
    "    tag = RUN_TAG.value.strip()\n",
    "    if tag:\n",
    "        SETS_DIR.value = f\"artifacts/sets/{tag}\"\n",
    "\n",
    "def check_set(_):\n",
    "    OUT_SET.clear_output(wait=True)\n",
    "    with OUT_SET:\n",
    "        sd = Path(SETS_DIR.value) if SETS_DIR.value.strip() else (Path(\"artifacts/sets\")/RUN_TAG.value.strip())\n",
    "        print(\"SETS_DIR:\", sd.as_posix())\n",
    "        need = [\"y_train.parquet\",\"ids_train.parquet\",\"ids_test.parquet\",\"folds.pkl\"]\n",
    "        for f in need:\n",
    "            print(f, \"✓\" if (sd/f).exists() else \"❌\")\n",
    "        Xdtr, Xdte = sd/\"X_dense_train.parquet\", sd/\"X_dense_test.parquet\"\n",
    "        Xstr, Xste = sd/\"X_sparse_train.npz\", sd/\"X_sparse_test.npz\"\n",
    "        print(\"Dense:\", \"OK\" if (Xdtr.exists() and Xdte.exists()) else \"—\",\n",
    "              \"| Sparse:\", \"OK\" if (Xstr.exists() and Xste.exists()) else \"—\")\n",
    "        if Xdtr.exists():\n",
    "            try:\n",
    "                x = try_read_parquet(Xdtr)\n",
    "                print(\"Dense train shape:\", x.shape, \"| mem:\", round(mem_df_gb(x),3),\"GB\")\n",
    "            except Exception as e:\n",
    "                print(\"dense чтение:\", e)\n",
    "        if (sd/\"folds.pkl\").exists():\n",
    "            import pickle\n",
    "            folds = pickle.loads((sd/\"folds.pkl\").read_bytes())\n",
    "            print(\"Folds:\", len(folds), \"| вал. размеры:\", [len(v) for _,v in folds[:5]], \"...\")\n",
    "        if (sd/\"meta.json\").exists():\n",
    "            meta = read_json(sd/\"meta.json\") or {}\n",
    "            print(\"META keys:\", list(meta.keys()))\n",
    "\n",
    "BTN_AUTOFILL.on_click(autofill_sets_dir)\n",
    "BTN_CHECK_SET.on_click(check_set)\n",
    "display(w.VBox([w.HBox([RUN_TAG, BTN_AUTOFILL], layout=ROW_LAYOUT), SETS_DIR, w.HBox([BTN_CHECK_SET], layout=ROW_LAYOUT), OUT_SET]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# автопоиск yaml-кандидатов\n",
    "def list_candidates(config_dir=\"configs/models\"):\n",
    "    items = []\n",
    "    for p in sorted(Path(config_dir).glob(\"*.yaml\")):\n",
    "        items.append(p.stem)\n",
    "    return items\n",
    "\n",
    "CANDS_ALL = list_candidates()\n",
    "\n",
    "CANDS_MULTI = w.SelectMultiple(\n",
    "    options=CANDS_ALL, value=tuple(autoload_or([], \"CANDS_MULTI\") or []),\n",
    "    description=\"cands\", rows=10, layout=w.Layout(width=\"45%\")\n",
    ")\n",
    "\n",
    "TASK  = w.Dropdown(options=[\"auto\",\"binary\",\"multiclass\",\"regression\",\"multilabel\"], value=autoload_or(\"auto\",\"TASK\"), description=\"TASK\")\n",
    "METRIC= w.Dropdown(options=[\"roc_auc\",\"pr_auc\",\"logloss\",\"accuracy\",\"f1\",\"rmse\",\"mae\",\"mape\"], value=autoload_or(\"roc_auc\",\"METRIC\"), description=\"METRIC\")\n",
    "DEVICE= w.Dropdown(options=[\"auto\",\"cpu\",\"gpu\"], value=autoload_or(\"auto\",\"DEVICE\"), description=\"DEVICE\")\n",
    "THREADS = w.IntText(value=int(autoload_or(-1,\"THREADS\")), description=\"THREADS\")\n",
    "SEED    = w.IntText(value=int(autoload_or(42,\"SEED\")), description=\"SEED\")\n",
    "TIMEOUT = w.IntText(value=int(autoload_or(0,\"TIMEOUT\")), description=\"TIMEOUT_MIN\")\n",
    "RESUME  = w.Checkbox(value=bool(autoload_or(True,\"RESUME\")), description=\"RESUME\")\n",
    "CALIB   = w.Dropdown(options=[\"off\",\"platt\",\"isotonic\"], value=autoload_or(\"off\",\"CALIB\"), description=\"CALIBRATE\")\n",
    "SAVE_TEST = w.Checkbox(value=bool(autoload_or(True,\"SAVE_TEST\")), description=\"SAVE_TEST\")\n",
    "\n",
    "display(w.HBox([CANDS_MULTI, w.VBox([TASK, METRIC, DEVICE, THREADS, SEED, TIMEOUT, RESUME, CALIB, SAVE_TEST])], layout=ROW_LAYOUT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_DRY = w.Button(description=\"Dry-run (план)\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "OUT_DRY = w.Output(layout={'border':'1px dashed #e0a'})\n",
    "\n",
    "def on_dry(_):\n",
    "    OUT_DRY.clear_output(wait=True)\n",
    "    with OUT_DRY:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\"\n",
    "        cands = list(CANDS_MULTI.value)\n",
    "        if not tag or not cands:\n",
    "            print(\"Укажи RUN_TAG и выбери хотя бы одного кандидата.\")\n",
    "            return\n",
    "        args = [\n",
    "            sys.executable, \"tools/run_model.py\",\n",
    "            \"--tag\", tag,\n",
    "            \"--cands\", \",\".join(cands),\n",
    "            \"--metric\", METRIC.value,\n",
    "            \"--device\", DEVICE.value,\n",
    "            \"--threads\", str(THREADS.value),\n",
    "            \"--seed\", str(SEED.value),\n",
    "            \"--sets-dir\", sd,\n",
    "            \"--dry-run\"\n",
    "        ]\n",
    "        if TASK.value!=\"auto\": args += [\"--task\", TASK.value]\n",
    "        if RESUME.value: args += [\"--resume\"]\n",
    "        if TIMEOUT.value>0: args += [\"--timeout-min\", str(TIMEOUT.value)]\n",
    "        if SAVE_TEST.value: args += [\"--save-test\"]\n",
    "        if CALIB.value!=\"off\": args += [\"--calibrate\", CALIB.value]\n",
    "        print(\"CMD:\", \" \".join(args))\n",
    "        code, out = run_cmd(args, stream=False, log_file=None)\n",
    "        print(out if out.strip() else f\"[exit code {code}]\")\n",
    "        print()\n",
    "        print(\"Если ок — запускай обучение.\")\n",
    "\n",
    "BTN_DRY.on_click(on_dry)\n",
    "display(w.VBox([BTN_DRY, OUT_DRY]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_TRAIN = w.Button(description=\"Train selected\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "OUT_TRAIN = w.Output(layout={'border':'1px solid #ccc', 'height':'300px', 'overflow_y':'auto'})\n",
    "OUT_SUM   = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def on_train(_):\n",
    "    OUT_TRAIN.clear_output(wait=True); OUT_SUM.clear_output(wait=True)\n",
    "    with OUT_TRAIN:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\"\n",
    "        cands = list(CANDS_MULTI.value)\n",
    "        if not tag or not cands:\n",
    "            print(\"Укажи RUN_TAG и выбери кандидатов.\")\n",
    "            return\n",
    "        args = [\n",
    "            sys.executable, \"tools/run_model.py\",\n",
    "            \"--tag\", tag,\n",
    "            \"--cands\", \",\".join(cands),\n",
    "            \"--metric\", METRIC.value,\n",
    "            \"--device\", DEVICE.value,\n",
    "            \"--threads\", str(THREADS.value),\n",
    "            \"--seed\", str(SEED.value),\n",
    "            \"--sets-dir\", sd\n",
    "        ]\n",
    "        if TASK.value!=\"auto\": args += [\"--task\", TASK.value]\n",
    "        if RESUME.value: args += [\"--resume\"]\n",
    "        if TIMEOUT.value>0: args += [\"--timeout-min\", str(TIMEOUT.value)]\n",
    "        if SAVE_TEST.value: args += [\"--save-test\"]\n",
    "        if CALIB.value!=\"off\": args += [\"--calibrate\", CALIB.value]\n",
    "        log_file = Path(\"artifacts\")/\"models\"/f\"log_{tag}.txt\"\n",
    "        print(\"CMD:\", \" \".join(args))\n",
    "        print(\"Лог:\", log_file.as_posix())\n",
    "        code, _ = run_cmd(args, stream=True, log_file=log_file)\n",
    "        print(\"[EXIT CODE]\", code)\n",
    "    # сводка по новым моделям\n",
    "    with OUT_SUM:\n",
    "        idx_path = Path(\"artifacts/models/index.json\")\n",
    "        if idx_path.exists():\n",
    "            idx = read_json(idx_path) or {}\n",
    "            rows=[]\n",
    "            for rid, rec in idx.items():\n",
    "                if rec.get(\"tag\")==tag:\n",
    "                    rows.append({\n",
    "                        \"run_id\": rid,\n",
    "                        \"cand\": rec.get(\"cand\"),\n",
    "                        \"lib\": rec.get(\"lib\"),\n",
    "                        \"task\": rec.get(\"task\"),\n",
    "                        \"metric\": rec.get(\"metric\"),\n",
    "                        \"cv_mean\": rec.get(\"cv_mean\"),\n",
    "                        \"cv_std\": rec.get(\"cv_std\"),\n",
    "                        \"time_sec\": rec.get(\"time_sec\"),\n",
    "                        \"path\": rec.get(\"path\")\n",
    "                    })\n",
    "            if rows:\n",
    "                df = pd.DataFrame(rows).sort_values(\"cv_mean\", ascending=False)\n",
    "                display(df)\n",
    "                # сохраним\n",
    "                ensure_dir(Path(\"artifacts\")/\"models\")\n",
    "                df.to_csv(Path(\"artifacts\")/\"models\"/f\"last_runs_{tag}.csv\", index=False)\n",
    "            else:\n",
    "                print(\"Пока нет записей в index.json для этого RUN_TAG.\")\n",
    "        else:\n",
    "            print(\"artifacts/models/index.json не найден.\")\n",
    "\n",
    "BTN_TRAIN.on_click(on_train)\n",
    "display(w.VBox([BTN_TRAIN, OUT_TRAIN, OUT_SUM]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c267df",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_REFRESH_RUNS = w.Button(description=\"Обновить список\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "RUNS_MULTI = w.SelectMultiple(options=[], description=\"run_id\", rows=12, layout=w.Layout(width=\"80%\"))\n",
    "OUT_RUNS   = w.Output()\n",
    "\n",
    "def refresh_runs(_=None):\n",
    "    tag = RUN_TAG.value.strip()\n",
    "    idx_path = Path(\"artifacts/models/index.json\")\n",
    "    items=[]\n",
    "    if idx_path.exists():\n",
    "        idx = read_json(idx_path) or {}\n",
    "        for rid, rec in idx.items():\n",
    "            if rec.get(\"tag\")==tag:\n",
    "                items.append((f\"{rec.get('cv_mean'):.6f} | {rec.get('cand')} | {rid}\", rid))\n",
    "    RUNS_MULTI.options = [rid for _,rid in sorted(items, reverse=True)]\n",
    "\n",
    "BTN_REFRESH_RUNS.on_click(refresh_runs)\n",
    "refresh_runs()\n",
    "display(w.HBox([BTN_REFRESH_RUNS], layout=ROW_LAYOUT), RUNS_MULTI, OUT_RUNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_LOAD_PREDS = w.Button(description=\"Загрузить OOF/test\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "OUT_LOAD = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "# храним загруженные предсказания в памяти\n",
    "LOADED = {\"run_ids\": [], \"oof\": {}, \"test\": {}, \"paths\": {}}\n",
    "\n",
    "def norm_preds(task, arr):\n",
    "    a = np.asarray(arr)\n",
    "    if task==\"binary\":\n",
    "        if a.ndim==2 and a.shape[1]==1: return a.reshape(-1)\n",
    "        if a.ndim==2 and a.shape[1]==2: return a[:,1]\n",
    "        if a.ndim==1: return a\n",
    "        return a.reshape(-1)\n",
    "    return a  # multiclass/regression\n",
    "       \n",
    "def on_load_preds(_):\n",
    "    OUT_LOAD.clear_output(wait=True)\n",
    "    with OUT_LOAD:\n",
    "        ids = list(RUNS_MULTI.value)\n",
    "        if not ids:\n",
    "            print(\"Выбери хотя бы один run_id.\")\n",
    "            return\n",
    "        idx_path = Path(\"artifacts/models/index.json\")\n",
    "        idx = read_json(idx_path) or {}\n",
    "        # определим task\n",
    "        run0 = idx[ids[0]]\n",
    "        task = run0.get(\"task\",\"binary\")\n",
    "        LOADED[\"run_ids\"].clear()\n",
    "        LOADED[\"oof\"].clear()\n",
    "        LOADED[\"test\"].clear()\n",
    "        LOADED[\"paths\"].clear()\n",
    "        for rid in ids:\n",
    "            rec = idx.get(rid, {})\n",
    "            p = Path(rec.get(\"path\",\"\"))\n",
    "            oof_p = p/\"oof.npy\"\n",
    "            test_p = p/\"test_pred.npy\"\n",
    "            if not oof_p.exists():\n",
    "                print(\"skip:\", rid, \"— нет oof.npy\")\n",
    "                continue\n",
    "            oof = np.load(oof_p)\n",
    "            test = np.load(test_p) if test_p.exists() else None\n",
    "            LOADED[\"run_ids\"].append(rid)\n",
    "            LOADED[\"oof\"][rid] = norm_preds(task, oof)\n",
    "            LOADED[\"test\"][rid] = None if test is None else norm_preds(task, test)\n",
    "            LOADED[\"paths\"][rid] = p.as_posix()\n",
    "            print(\"OK:\", rid, \"| OOF:\", LOADED[\"oof\"][rid].shape, \"| TEST:\", None if LOADED[\"test\"][rid] is None else LOADED[\"test\"][rid].shape)\n",
    "        print(\"Загружено:\", len(LOADED[\"run_ids\"]), \"кандидатов.\")\n",
    "\n",
    "BTN_LOAD_PREDS.on_click(on_load_preds)\n",
    "display(BTN_LOAD_PREDS, OUT_LOAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_ANALYZE = w.Button(description=\"Сводка и корреляции\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "OUT_ANALYZE = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def metric_fn(task: str, metric: str):\n",
    "    m = metric.lower()\n",
    "    if task in (\"binary\",\"multiclass\",\"multilabel\"):\n",
    "        from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, accuracy_score, f1_score\n",
    "        if m in (\"roc_auc\",\"auc\"):\n",
    "            def _f(y_true, y_pred):\n",
    "                if task==\"binary\":\n",
    "                    return roc_auc_score(y_true, y_pred.reshape(-1))\n",
    "                elif task==\"multiclass\":\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    classes = np.unique(y_true)\n",
    "                    Y = label_binarize(y_true, classes=classes)\n",
    "                    return roc_auc_score(Y, y_pred, average=\"macro\", multi_class=\"ovr\")\n",
    "                else:\n",
    "                    return roc_auc_score(y_true, y_pred, average=\"macro\")\n",
    "            return _f\n",
    "        if m in (\"pr_auc\",\"ap\",\"average_precision\"):\n",
    "            def _f(y_true, y_pred):\n",
    "                if task==\"binary\":\n",
    "                    return average_precision_score(y_true, y_pred.reshape(-1))\n",
    "                elif task==\"multiclass\":\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    classes = np.unique(y_true)\n",
    "                    Y = label_binarize(y_true, classes=classes)\n",
    "                    return average_precision_score(Y, y_pred, average=\"macro\")\n",
    "                else:\n",
    "                    return average_precision_score(y_true, y_pred, average=\"macro\")\n",
    "            return _f\n",
    "        if m == \"logloss\":\n",
    "            def _f(y_true, y_pred):\n",
    "                if task==\"binary\":\n",
    "                    p = np.clip(y_pred.reshape(-1), 1e-15, 1-1e-15)\n",
    "                    P = np.vstack([1-p,p]).T\n",
    "                    return log_loss(y_true, P, labels=[0,1])\n",
    "                elif task==\"multiclass\":\n",
    "                    return log_loss(y_true, y_pred)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            return _f\n",
    "        if m in (\"accuracy\",\"acc\"):\n",
    "            def _f(y_true, y_pred):\n",
    "                if task==\"binary\":\n",
    "                    return ((y_pred.reshape(-1)>=0.5).astype(int)==y_true).mean()\n",
    "                elif task==\"multiclass\":\n",
    "                    return (np.argmax(y_pred,1)==y_true).mean()\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            return _f\n",
    "        if m in (\"f1\",\"macro_f1\"):\n",
    "            def _f(y_true, y_pred):\n",
    "                from sklearn.metrics import f1_score\n",
    "                if task==\"binary\":\n",
    "                    return f1_score(y_true, (y_pred.reshape(-1)>=0.5).astype(int))\n",
    "                elif task==\"multiclass\":\n",
    "                    return f1_score(y_true, np.argmax(y_pred,1), average=\"macro\")\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            return _f\n",
    "    if metric==\"rmse\":\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        return lambda y_true, y_pred: math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    if metric==\"mae\":\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        return lambda y_true, y_pred: mean_absolute_error(y_true, y_pred)\n",
    "    if metric==\"mape\":\n",
    "        def _m(y_true, y_pred):\n",
    "            y_true = np.asarray(y_true, float)\n",
    "            y_pred = np.asarray(y_pred, float)\n",
    "            eps = 1e-9\n",
    "            return np.mean(np.abs((y_true-y_pred)/np.clip(np.abs(y_true), eps, None)))*100.0\n",
    "        return _m\n",
    "    raise ValueError(\"Неизвестная метрика\")\n",
    "\n",
    "def on_analyze(_):\n",
    "    OUT_ANALYZE.clear_output(wait=True)\n",
    "    with OUT_ANALYZE:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        ydf = try_read_parquet(sd/\"y_train.parquet\")\n",
    "        if ydf is None:\n",
    "            print(\"Нет y_train.parquet\")\n",
    "            return\n",
    "        target_col = [c for c in ydf.columns if c!=ydf.columns[0]][0]\n",
    "        y = ydf[target_col].to_numpy()\n",
    "        # определим task\n",
    "        task = TASK.value if TASK.value!=\"auto\" else (\"binary\" if len(np.unique(y))<=2 else \"multiclass\")\n",
    "        # таблица метрик для загруженных\n",
    "        if not LOADED[\"run_ids\"]:\n",
    "            print(\"Сначала загрузите OOF/test (прошлая ячейка).\")\n",
    "            return\n",
    "        scorer = metric_fn(task, METRIC.value)\n",
    "        rows=[]\n",
    "        mats=[]\n",
    "        names=[]\n",
    "        for rid in LOADED[\"run_ids\"]:\n",
    "            oof = LOADED[\"oof\"][rid]\n",
    "            rows.append({\"run_id\": rid, \"metric\": scorer(y, oof)})\n",
    "            mats.append(oof.reshape(-1,1) if task==\"binary\" else oof)\n",
    "            names.append(rid[:10])\n",
    "        df = pd.DataFrame(rows).sort_values(\"metric\", ascending=False)\n",
    "        display(df)\n",
    "        # корреляции OOF\n",
    "        try:\n",
    "            if len(mats)>=2:\n",
    "                M = np.hstack([m if m.ndim==2 and m.shape[1]==1 else m.max(1).reshape(-1,1) for m in mats])  # упрощённая редукция для нелинейности\n",
    "                C = np.corrcoef(M.T)\n",
    "                plt.figure()\n",
    "                plt.imshow(C, interpolation=\"nearest\")\n",
    "                plt.colorbar(); plt.title(\"Корреляция OOF (сжатая)\")\n",
    "                plt.xticks(range(len(names)), names, rotation=90)\n",
    "                plt.yticks(range(len(names)), names)\n",
    "                plt.tight_layout(); plt.show()\n",
    "        except Exception as e:\n",
    "            print(\"corr skipped:\", e)\n",
    "\n",
    "BTN_ANALYZE.on_click(on_analyze)\n",
    "display(BTN_ANALYZE, OUT_ANALYZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбор на бленд\n",
    "BLEND_RUNS = w.SelectMultiple(options=[], description=\"В бленд\", rows=10, layout=w.Layout(width=\"80%\"))\n",
    "BTN_REFRESH_FOR_BLEND = w.Button(description=\"← из загруженных\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "BTN_EQ   = w.Button(description=\"Equal-weight\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "BTN_DIR  = w.Button(description=\"Dirichlet-search\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "BTN_L2   = w.Button(description=\"Level-2 (Ridge/LogReg)\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "OUT_BLEND= w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def refresh_for_blend(_=None):\n",
    "    BLEND_RUNS.options = list(LOADED[\"run_ids\"])\n",
    "\n",
    "BTN_REFRESH_FOR_BLEND.on_click(refresh_for_blend)\n",
    "display(w.HBox([BTN_REFRESH_FOR_BLEND], layout=ROW_LAYOUT), BLEND_RUNS, w.HBox([BTN_EQ, BTN_DIR, BTN_L2], layout=ROW_LAYOUT), OUT_BLEND)\n",
    "\n",
    "BLEND_STATE = {\"oof\": None, \"test\": None, \"weights\": None, \"type\": None, \"members\": None, \"metric\": None}\n",
    "\n",
    "def _collect_stack(task, members):\n",
    "    ys = []\n",
    "    tests = []\n",
    "    for rid in members:\n",
    "        ys.append(LOADED[\"oof\"][rid].reshape(-1,1) if task==\"binary\" else LOADED[\"oof\"][rid])\n",
    "        t = LOADED[\"test\"][rid]\n",
    "        if t is None:\n",
    "            raise RuntimeError(f\"{rid}: нет test_pred.npy\")\n",
    "        tests.append(t.reshape(-1,1) if task==\"binary\" else t)\n",
    "    return ys, tests\n",
    "\n",
    "def blend_equal(task, y_true, members):\n",
    "    Ys, Ts = _collect_stack(task, members)\n",
    "    Y = np.hstack(Ys)\n",
    "    T = np.hstack(Ts)\n",
    "    oof_bl = np.mean(Y, axis=1) if task!=\"multiclass\" else np.mean(Y, axis=2)  # multiclass Y stacking shape?\n",
    "    if task==\"multiclass\":\n",
    "        oof_bl = np.mean(np.stack(Ys, axis=0), axis=0)  # (m, n, C) -> (n, C)\n",
    "        test_bl= np.mean(np.stack(Ts, axis=0), axis=0)\n",
    "    else:\n",
    "        oof_bl = np.mean(np.hstack(Ys), axis=1)\n",
    "        test_bl= np.mean(np.hstack(Ts), axis=1)\n",
    "    return oof_bl, test_bl, np.ones(len(members))/len(members)\n",
    "\n",
    "def dirichlet_search(task, y_true, members, metric, n_samples=2000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Ys, Ts = _collect_stack(task, members)\n",
    "    if task==\"multiclass\":\n",
    "        Y = np.stack(Ys, axis=0)  # (m, n, C)\n",
    "        T = np.stack(Ts, axis=0)  # (m, nt, C)\n",
    "    else:\n",
    "        Y = np.hstack(Ys)         # (n, m)\n",
    "        T = np.hstack(Ts)         # (nt, m)\n",
    "    scorer = metric_fn(task, metric)\n",
    "    best_w, best_s = None, -1e9\n",
    "    for _ in range(n_samples):\n",
    "        w = rng.dirichlet([1.0]*len(members))\n",
    "        if task==\"multiclass\":\n",
    "            oof = np.tensordot(w, Y, axes=(0,0))  # (n, C)\n",
    "        else:\n",
    "            oof = (Y @ w).reshape(-1)\n",
    "        s = scorer(y_true, oof)\n",
    "        if s>best_s:\n",
    "            best_s, best_w = s, w\n",
    "    if task==\"multiclass\":\n",
    "        test_bl = np.tensordot(best_w, T, axes=(0,0))\n",
    "        oof_bl  = np.tensordot(best_w, Y, axes=(0,0))\n",
    "    else:\n",
    "        test_bl = (T @ best_w).reshape(-1)\n",
    "        oof_bl  = (Y @ best_w).reshape(-1)\n",
    "    return oof_bl, test_bl, best_w\n",
    "\n",
    "def level2_stack(task, y_true, members):\n",
    "    from sklearn.linear_model import Ridge, LogisticRegression\n",
    "    Ys, Ts = _collect_stack(task, members)\n",
    "    if task==\"binary\":\n",
    "        X = np.hstack(Ys)     # (n, m)\n",
    "        Xt= np.hstack(Ts)     # (nt, m)\n",
    "        mdl = LogisticRegression(max_iter=1000)\n",
    "        mdl.fit(X, y_true.astype(int))\n",
    "        oof = mdl.predict_proba(X)[:,1]\n",
    "        test= mdl.predict_proba(Xt)[:,1]\n",
    "        return oof, test, mdl\n",
    "    elif task==\"multiclass\":\n",
    "        X = np.hstack([y for y in Ys])  # (n, m*C) упрощённо — берём argmax proba? лучше конкатенировать все классы\n",
    "        Xt= np.hstack([t for t in Ts])\n",
    "        mdl = Ridge(alpha=1.0)\n",
    "        mdl.fit(X, pd.get_dummies(y_true).values)\n",
    "        oof = np.clip(mdl.predict(X), 0, 1)\n",
    "        oof = oof / np.clip(oof.sum(1, keepdims=True), 1e-9, None)\n",
    "        test = np.clip(mdl.predict(Xt), 0, 1)\n",
    "        test = test / np.clip(test.sum(1, keepdims=True), 1e-9, None)\n",
    "        return oof, test, mdl\n",
    "    else:  # regression\n",
    "        X = np.hstack(Ys)\n",
    "        Xt= np.hstack(Ts)\n",
    "        mdl = Ridge(alpha=1.0)\n",
    "        mdl.fit(X, y_true)\n",
    "        return mdl.predict(X), mdl.predict(Xt), mdl\n",
    "\n",
    "def on_blend_equal(_):\n",
    "    OUT_BLEND.clear_output(wait=True)\n",
    "    with OUT_BLEND:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        ydf = try_read_parquet(sd/\"y_train.parquet\")\n",
    "        y = ydf[[c for c in ydf.columns if c!=ydf.columns[0]][0]].to_numpy()\n",
    "        task = TASK.value if TASK.value!=\"auto\" else (\"binary\" if len(np.unique(y))<=2 else \"multiclass\")\n",
    "        members = list(BLEND_RUNS.value)\n",
    "        if not members: print(\"Выбери участников бленда\"); return\n",
    "        oof, test, w = blend_equal(task, y, members)\n",
    "        scorer = metric_fn(task, METRIC.value); s = scorer(y, oof)\n",
    "        print(\"Equal-weight blend:\", \"metric=\", s)\n",
    "        BLEND_STATE.update({\"oof\":oof, \"test\":test, \"weights\":w, \"type\":\"equal\", \"members\":members, \"metric\":float(s)})\n",
    "\n",
    "def on_blend_dirichlet(_):\n",
    "    OUT_BLEND.clear_output(wait=True)\n",
    "    with OUT_BLEND:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        ydf = try_read_parquet(sd/\"y_train.parquet\")\n",
    "        y = ydf[[c for c in ydf.columns if c!=ydf.columns[0]][0]].to_numpy()\n",
    "        task = TASK.value if TASK.value!=\"auto\" else (\"binary\" if len(np.unique(y))<=2 else \"multiclass\")\n",
    "        members = list(BLEND_RUNS.value)\n",
    "        if not members: print(\"Выбери участников бленда\"); return\n",
    "        oof, test, w = dirichlet_search(task, y, members, METRIC.value, n_samples=2000, seed=42)\n",
    "        scorer = metric_fn(task, METRIC.value); s = scorer(y, oof)\n",
    "        print(\"Dirichlet-search blend:\", \"metric=\", s, \"| weights:\", np.round(w,4))\n",
    "        BLEND_STATE.update({\"oof\":oof, \"test\":test, \"weights\":w, \"type\":\"dirichlet\", \"members\":members, \"metric\":float(s)})\n",
    "\n",
    "def on_blend_l2(_):\n",
    "    OUT_BLEND.clear_output(wait=True)\n",
    "    with OUT_BLEND:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        ydf = try_read_parquet(sd/\"y_train.parquet\")\n",
    "        y = ydf[[c for c in ydf.columns if c!=ydf.columns[0]][0]].to_numpy()\n",
    "        task = TASK.value if TASK.value!=\"auto\" else (\"binary\" if len(np.unique(y))<=2 else \"multiclass\")\n",
    "        members = list(BLEND_RUNS.value)\n",
    "        if not members: print(\"Выбери участников бленда\"); return\n",
    "        oof, test, mdl = level2_stack(task, y, members)\n",
    "        scorer = metric_fn(task, METRIC.value); s = scorer(y, oof)\n",
    "        print(\"Level-2 blend:\", \"metric=\", s)\n",
    "        BLEND_STATE.update({\"oof\":oof, \"test\":test, \"weights\":None, \"type\":\"level2\", \"members\":members, \"metric\":float(s)})\n",
    "\n",
    "BTN_EQ.on_click(on_blend_equal)\n",
    "BTN_DIR.on_click(on_blend_dirichlet)\n",
    "BTN_L2.on_click(on_blend_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_SAVE_BLEND = w.Button(description=\"Сохранить бленд\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "OUT_SAVE_BLEND = w.Output()\n",
    "\n",
    "def on_save_blend(_):\n",
    "    OUT_SAVE_BLEND.clear_output(wait=True)\n",
    "    with OUT_SAVE_BLEND:\n",
    "        if BLEND_STATE[\"oof\"] is None or BLEND_STATE[\"test\"] is None:\n",
    "            print(\"Сначала соберите бленд.\")\n",
    "            return\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        blend_id = f\"blend_{BLEND_STATE['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        out_dir = ensure_dir(Path(\"artifacts\")/\"models\"/\"blends\"/blend_id)\n",
    "        np.save(out_dir/\"oof.npy\", BLEND_STATE[\"oof\"])\n",
    "        np.save(out_dir/\"test_pred.npy\", BLEND_STATE[\"test\"])\n",
    "        cfg = {\n",
    "            \"run_tag\": tag,\n",
    "            \"type\": BLEND_STATE[\"type\"],\n",
    "            \"members\": BLEND_STATE[\"members\"],\n",
    "            \"weights\": None if BLEND_STATE[\"weights\"] is None else list(map(float, BLEND_STATE[\"weights\"])),\n",
    "            \"metric\": BLEND_STATE[\"metric\"]\n",
    "        }\n",
    "        write_json(out_dir/\"blend_config.json\", cfg)\n",
    "        print(\"blend saved →\", out_dir.as_posix())\n",
    "\n",
    "BTN_SAVE_BLEND.on_click(on_save_blend)\n",
    "display(BTN_SAVE_BLEND, OUT_SAVE_BLEND)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddfffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALIB_MODE = w.Dropdown(options=[\"off\",\"platt\",\"isotonic\"], value=\"off\", description=\"Calibrate\")\n",
    "THR_MODE   = w.Dropdown(options=[\"f1\",\"youden\"], value=\"f1\", description=\"τ strategy\")\n",
    "BTN_CALIB  = w.Button(description=\"Калибровать бленд/кандидат\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "OUT_CALIB  = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "CALIB_STATE = {\"cal\": None, \"tau\": None, \"oof_cal\": None, \"test_cal\": None}\n",
    "\n",
    "def fit_calibrator(method, y, p):\n",
    "    method = method.lower()\n",
    "    if method in (\"off\",\"none\",\"\"): return None, lambda z: z\n",
    "    if method==\"platt\":\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        lr = LogisticRegression(max_iter=1000)\n",
    "        lr.fit(p.reshape(-1,1), y.astype(int))\n",
    "        return (\"platt\", lr), (lambda z: lr.predict_proba(z.reshape(-1,1))[:,1])\n",
    "    if method==\"isotonic\":\n",
    "        from sklearn.isotonic import IsotonicRegression\n",
    "        ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "        ir.fit(p.reshape(-1), y.astype(int))\n",
    "        return (\"isotonic\", ir), (lambda z: ir.predict(z.reshape(-1)))\n",
    "    raise ValueError\n",
    "\n",
    "def find_tau(y, p, mode=\"f1\"):\n",
    "    from sklearn.metrics import f1_score, roc_curve\n",
    "    if mode==\"f1\":\n",
    "        best, best_t = -1, 0.5\n",
    "        for t in np.linspace(0,1,401):\n",
    "            s = f1_score(y, (p>=t).astype(int))\n",
    "            if s>best: best, best_t = s, t\n",
    "        return best_t, best\n",
    "    # Youden J on ROC\n",
    "    fpr, tpr, thr = roc_curve(y, p)\n",
    "    j = tpr - fpr\n",
    "    i = int(np.argmax(j))\n",
    "    return float(thr[i]), float(j[i])\n",
    "\n",
    "def on_calib(_):\n",
    "    OUT_CALIB.clear_output(wait=True)\n",
    "    with OUT_CALIB:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        ydf = try_read_parquet(sd/\"y_train.parquet\")\n",
    "        y = ydf[[c for c in ydf.columns if c!=ydf.columns[0]][0]].to_numpy()\n",
    "        task = TASK.value if TASK.value!=\"auto\" else (\"binary\" if len(np.unique(y))<=2 else \"multiclass\")\n",
    "        if task!=\"binary\":\n",
    "            print(\"Калибровка/τ активны только для binary.\")\n",
    "            return\n",
    "        # источник: если есть BLEND_STATE, используем его; иначе — первый загруженный\n",
    "        if BLEND_STATE[\"oof\"] is not None:\n",
    "            p_oof = BLEND_STATE[\"oof\"].reshape(-1)\n",
    "            p_test= BLEND_STATE[\"test\"].reshape(-1)\n",
    "        else:\n",
    "            if not LOADED[\"run_ids\"]:\n",
    "                print(\"Нет источника предсказаний (соберите бленд или загрузите run_id).\")\n",
    "                return\n",
    "            rid = LOADED[\"run_ids\"][0]\n",
    "            p_oof = LOADED[\"oof\"][rid].reshape(-1)\n",
    "            p_test= LOADED[\"test\"][rid].reshape(-1)\n",
    "        cal_mode = CALIB_MODE.value\n",
    "        cal_obj, apply_fn = fit_calibrator(cal_mode, y, p_oof)\n",
    "        p_oof_cal = apply_fn(p_oof) if cal_obj else p_oof\n",
    "        p_test_cal= apply_fn(p_test) if cal_obj else p_test\n",
    "        tau, score = find_tau(y, p_oof_cal, THR_MODE.value)\n",
    "        CALIB_STATE.update({\"cal\":cal_obj, \"tau\":tau, \"oof_cal\":p_oof_cal, \"test_cal\":p_test_cal})\n",
    "        print(\"calibration:\", cal_mode, \"| τ:\", tau, \"|\", THR_MODE.value, \"score:\", score)\n",
    "\n",
    "display(w.HBox([CALIB_MODE, THR_MODE, BTN_CALIB], layout=ROW_LAYOUT), OUT_CALIB)\n",
    "BTN_CALIB.on_click(on_calib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SRC = w.Dropdown(options=[\"blend\"], value=\"blend\", description=\"Источник\")\n",
    "SUB_TAG = w.Text(value=now_tag(\"submit\"), description=\"SUB_TAG\", layout=w.Layout(width=\"50%\"))\n",
    "BTN_SUB = w.Button(description=\"Собрать сабмит\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "OUT_SUB = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def on_submit(_):\n",
    "    OUT_SUB.clear_output(wait=True)\n",
    "    with OUT_SUB:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        ids_te = try_read_parquet(sd/\"ids_test.parquet\")\n",
    "        if ids_te is None:\n",
    "            print(\"Нет ids_test.parquet\")\n",
    "            return\n",
    "        id_col = ids_te.columns[0]\n",
    "        # выбрать источник\n",
    "        if SUB_SRC.value==\"blend\":\n",
    "            if BLEND_STATE[\"test\"] is None:\n",
    "                print(\"Нет test предсказаний бленда.\")\n",
    "                return\n",
    "            pred = BLEND_STATE[\"test\"]\n",
    "            # если есть калибровка/τ и от нас ожидается класс — применить при необходимости отдельно\n",
    "        else:\n",
    "            print(\"Сейчас поддержан только 'blend' как источник.\")\n",
    "            return\n",
    "        # формируем CSV как score (id, target)\n",
    "        df_sub = pd.DataFrame({id_col: ids_te[id_col].values, \"target\": pred.reshape(-1)})\n",
    "        out_dir = ensure_dir(Path(\"artifacts\")/\"submits\"/tag/SUB_TAG.value.strip())\n",
    "        sub_path = out_dir/\"submission.csv\"\n",
    "        df_sub.to_csv(sub_path, index=False)\n",
    "        manifest = {\n",
    "            \"run_tag\": tag,\n",
    "            \"source\": SUB_SRC.value,\n",
    "            \"blend\": {\n",
    "                \"type\": BLEND_STATE[\"type\"],\n",
    "                \"members\": BLEND_STATE[\"members\"],\n",
    "                \"weights\": None if BLEND_STATE[\"weights\"] is None else list(map(float, BLEND_STATE[\"weights\"])),\n",
    "                \"metric_on_oof\": BLEND_STATE[\"metric\"]\n",
    "            },\n",
    "            \"calibration\": {\n",
    "                \"used\": CALIB_STATE[\"cal\"] is not None,\n",
    "                \"tau\": None if CALIB_STATE[\"tau\"] is None else float(CALIB_STATE[\"tau\"]),\n",
    "                \"mode\": CALIB_MODE.value if CALIB_MODE.value!=\"off\" else \"off\"\n",
    "            }\n",
    "        }\n",
    "        write_json(out_dir/\"manifest.json\", manifest)\n",
    "        print(\"SUBMISSION →\", sub_path.as_posix())\n",
    "\n",
    "display(w.HBox([SUB_SRC, SUB_TAG, BTN_SUB], layout=ROW_LAYOUT), OUT_SUB)\n",
    "BTN_SUB.on_click(on_submit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae34194",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOR_IMPORTANCE = w.Text(value=\"\", description=\"run_id\")\n",
    "BTN_IMPORTANCE = w.Button(description=\"Показать важности\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "OUT_IMP = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def on_importance(_):\n",
    "    OUT_IMP.clear_output(wait=True)\n",
    "    with OUT_IMP:\n",
    "        rid = RUN_FOR_IMPORTANCE.value.strip()\n",
    "        if not rid:\n",
    "            print(\"Укажи run_id (из сводной таблицы).\")\n",
    "            return\n",
    "        p = Path(\"artifacts/models\")/rid/\"feature_importance.csv\"\n",
    "        if not p.exists():\n",
    "            print(\"Нет feature_importance.csv\")\n",
    "            return\n",
    "        df = pd.read_csv(p)\n",
    "        df = df.sort_values(\"gain\", ascending=False).head(20)\n",
    "        display(df)\n",
    "        plt.figure()\n",
    "        plt.bar(df[\"feature\"], df[\"gain\"])\n",
    "        plt.xticks(rotation=90); plt.title(\"Top-20 feature importance\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "display(w.HBox([RUN_FOR_IMPORTANCE, BTN_IMPORTANCE], layout=ROW_LAYOUT), OUT_IMP)\n",
    "BTN_IMPORTANCE.on_click(on_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36633722",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICE_COL = w.Text(value=\"\", description=\"slice_col\")\n",
    "BTN_SLICE = w.Button(description=\"Посчитать по срезам\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "OUT_SLICE = w.Output(layout={'border':'1px solid #ccc'})\n",
    "\n",
    "def on_slice(_):\n",
    "    OUT_SLICE.clear_output(wait=True)\n",
    "    with OUT_SLICE:\n",
    "        tag = RUN_TAG.value.strip()\n",
    "        sd  = Path(SETS_DIR.value.strip() or f\"artifacts/sets/{tag}\")\n",
    "        Xd  = try_read_parquet(sd/\"X_dense_train.parquet\")\n",
    "        if Xd is None:\n",
    "            print(\"Нет dense train для срезов.\")\n",
    "            return\n",
    "        col = SLICE_COL.value.strip()\n",
    "        if not col or col not in Xd.columns:\n",
    "            print(\"Укажи корректный столбец из dense набора.\")\n",
    "            return\n",
    "        ydf = try_read_parquet(sd/\"y_train.parquet\")\n",
    "        y   = ydf[[c for c in ydf.columns if c!=ydf.columns[0]][0]].to_numpy()\n",
    "        task = TASK.value if TASK.value!=\"auto\" else (\"binary\" if len(np.unique(y))<=2 else \"multiclass\")\n",
    "        scorer = metric_fn(task, METRIC.value)\n",
    "        # возьмём источник: бленд или первый загруженный\n",
    "        if BLEND_STATE[\"oof\"] is not None:\n",
    "            p = BLEND_STATE[\"oof\"]\n",
    "        elif LOADED[\"run_ids\"]:\n",
    "            p = LOADED[\"oof\"][LOADED[\"run_ids\"][0]]\n",
    "        else:\n",
    "            print(\"Нет предсказаний для анализа.\")\n",
    "            return\n",
    "        groups = pd.qcut(Xd[col], q=5, duplicates=\"drop\") if pd.api.types.is_numeric_dtype(Xd[col]) else Xd[col].astype(str)\n",
    "        df = pd.DataFrame({\"g\": groups, \"y\": y, \"p\": p if task!=\"multiclass\" else p.max(1)})\n",
    "        rows=[]\n",
    "        for g, chunk in df.groupby(\"g\"):\n",
    "            rows.append({\"slice\": str(g), \"metric\": scorer(chunk[\"y\"].values, chunk[\"p\"].values)})\n",
    "        out = pd.DataFrame(rows).sort_values(\"metric\")\n",
    "        display(out)\n",
    "\n",
    "display(w.HBox([SLICE_COL, BTN_SLICE], layout=ROW_LAYOUT), OUT_SLICE)\n",
    "BTN_SLICE.on_click(on_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_SAVE_UI = w.Button(description=\"Сохранить UI\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "BTN_LOAD_UI = w.Button(description=\"Загрузить UI\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "OUT_UI = w.Output()\n",
    "\n",
    "def on_save_ui(_):\n",
    "    save_ui_state({\n",
    "        \"RUN_TAG\": RUN_TAG.value, \"SETS_DIR\": SETS_DIR.value,\n",
    "        \"CANDS_MULTI\": list(CANDS_MULTI.value),\n",
    "        \"TASK\": TASK.value, \"METRIC\": METRIC.value, \"DEVICE\": DEVICE.value,\n",
    "        \"THREADS\": THREADS.value, \"SEED\": SEED.value, \"TIMEOUT\": TIMEOUT.value,\n",
    "        \"RESUME\": RESUME.value, \"CALIB\": CALIB.value, \"SAVE_TEST\": SAVE_TEST.value\n",
    "    })\n",
    "    display(badge(\"SAVED\", \"#0a0\"))\n",
    "\n",
    "def on_load_ui(_):\n",
    "    st = load_ui_state()\n",
    "    try:\n",
    "        RUN_TAG.value = st.get(\"RUN_TAG\", RUN_TAG.value)\n",
    "        SETS_DIR.value= st.get(\"SETS_DIR\", SETS_DIR.value)\n",
    "        CANDS_MULTI.value = tuple(st.get(\"CANDS_MULTI\", list(CANDS_MULTI.value)))\n",
    "        TASK.value = st.get(\"TASK\", TASK.value)\n",
    "        METRIC.value = st.get(\"METRIC\", METRIC.value)\n",
    "        DEVICE.value = st.get(\"DEVICE\", DEVICE.value)\n",
    "        THREADS.value= st.get(\"THREADS\", THREADS.value)\n",
    "        SEED.value   = st.get(\"SEED\", SEED.value)\n",
    "        TIMEOUT.value= st.get(\"TIMEOUT\", TIMEOUT.value)\n",
    "        RESUME.value = st.get(\"RESUME\", RESUME.value)\n",
    "        CALIB.value  = st.get(\"CALIB\", CALIB.value)\n",
    "        SAVE_TEST.value = st.get(\"SAVE_TEST\", SAVE_TEST.value)\n",
    "        display(badge(\"LOADED\", \"#0a0\"))\n",
    "    except Exception as e:\n",
    "        print(\"load err:\", e)\n",
    "\n",
    "BTN_SAVE_UI.on_click(on_save_ui)\n",
    "BTN_LOAD_UI.on_click(on_load_ui)\n",
    "display(w.HBox([BTN_SAVE_UI, BTN_LOAD_UI], layout=ROW_LAYOUT), OUT_UI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41642274",
   "metadata": {},
   "source": [
    "### Чеклист перед сабмитом\n",
    "- [ ] Формат CSV совпадает с регламентом (id, target)?\n",
    "- [ ] Выбран лучший по OOF источник (или бленд)?\n",
    "- [ ] Для AUC/PR-AUC сабмитим **скор/вероятность**, без порога.\n",
    "- [ ] Если применяли калибровку/τ — это требовалось форматом?\n",
    "- [ ] Файлы `blend_config.json` / `manifest.json` сохранены."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
