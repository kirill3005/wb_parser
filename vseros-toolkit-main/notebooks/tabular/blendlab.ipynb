{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3533212d",
   "metadata": {},
   "source": [
    "\n",
    "# BlendLab (блендинг/стакинг без утечек)\n",
    "\n",
    "Цель: быстро собрать бленд/стакинг из уже обученных прогонов (**run_id**) с прозрачными артефактами.\n",
    "\n",
    "План:\n",
    "1) выбрать **RUN_TAG** (набор фич),\n",
    "2) выбрать состав кандидатов (run_id) из `artifacts/models/index.json`,\n",
    "3) посмотреть корреляции OOF и диверсификацию,\n",
    "4) выбрать **blend-space** (proba / logit / rank) и режим бленда,\n",
    "5) (опц.) калибровка (Platt/Isotonic) и/или τ (для binary),\n",
    "6) сохранить бленд и сформировать сабмит.\n",
    "\n",
    "Анти-утечки:\n",
    "- Подбор весов `--cv-weights`: веса ищутся на train-OOF, применяются на val-OOF.\n",
    "- Level-2 (стакинг) делается fold-safe.\n",
    "- Для AUC сабмит — **вероятности**, не классы (без глобального τ).\n",
    "\n",
    "Зависимости: `numpy, pandas, matplotlib, ipywidgets, scikit-learn`. Скрипт: `tools/run_blend.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34760fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* ipywidgets v8 (JupyterLab 4) */\n",
    ".jp-OutputArea .widget-button .widget-label { \n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "/* fallback для ipywidgets v7 */\n",
    ".jupyter-widgets.widget-button .widget-label {\n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd505ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core\n",
    "import os, sys, json, math, subprocess, shutil, gc, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Widgets\n",
    "try:\n",
    "    import ipywidgets as W\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "except Exception:\n",
    "    W = None\n",
    "    print(\"[warn] ipywidgets не установлен — будет вариант без UI\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "SETS_ROOT = Path(\"artifacts/sets\")\n",
    "MODELS_INDEX = Path(\"artifacts/models/index.json\")\n",
    "BLENDS_ROOT = Path(\"artifacts/models/blends\")\n",
    "SUBMITS_ROOT = Path(\"artifacts/submits\")\n",
    "\n",
    "# ------- helpers --------\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_json(p: Path):\n",
    "    if not p.exists(): return None\n",
    "    try: return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception: return None\n",
    "\n",
    "def save_json(p: Path, obj: dict):\n",
    "    ensure_dir(p.parent)\n",
    "    p.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def read_parquet_any(p: Path):\n",
    "    if not p.exists(): return None\n",
    "    try:\n",
    "        return pd.read_parquet(p)\n",
    "    except Exception:\n",
    "        try:\n",
    "            import fastparquet  # noqa\n",
    "            return pd.read_parquet(p, engine=\"fastparquet\")\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def run_cmd(cmd: list, cwd: Path | None = None, verbose=True) -> tuple[int, str, str]:\n",
    "    \"\"\"Run shell command and capture output.\"\"\"\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, cwd=str(cwd) if cwd else None,\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "    )\n",
    "    out, err = proc.communicate()\n",
    "    if verbose:\n",
    "        print(\" \".join(cmd))\n",
    "        print(out)\n",
    "        if err.strip():\n",
    "            print(\"[stderr]\", err)\n",
    "    return proc.returncode, out, err\n",
    "\n",
    "def detect_task_from_y(y: np.ndarray) -> str:\n",
    "    u = np.unique(y)\n",
    "    if np.issubdtype(y.dtype, np.integer):\n",
    "        return \"binary\" if len(u) <= 2 else \"multiclass\"\n",
    "    if len(u) <= 2 and set(np.unique(y)).issubset({0.0, 1.0}):\n",
    "        return \"binary\"\n",
    "    return \"regression\"\n",
    "\n",
    "def metric_fn(task: str, name: str):\n",
    "    \"\"\"Return scorer(y_true, y_pred) -> float (higher=better).\"\"\"\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, average_precision_score, log_loss, accuracy_score,\n",
    "        f1_score, mean_squared_error, mean_absolute_error\n",
    "    )\n",
    "    name = name.lower()\n",
    "    if task in (\"binary\",\"multiclass\"):\n",
    "        if name in (\"roc_auc\",\"auc\"):\n",
    "            def f(y, p):\n",
    "                if task==\"binary\":\n",
    "                    return roc_auc_score(y, p.reshape(-1))\n",
    "                else:\n",
    "                    # multiclass\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    cls = np.unique(y)\n",
    "                    Y = label_binarize(y, classes=cls)\n",
    "                    return roc_auc_score(Y, p, average=\"macro\", multi_class=\"ovr\")\n",
    "            return f\n",
    "        if name in (\"pr_auc\",\"ap\",\"average_precision\"):\n",
    "            def f(y, p):\n",
    "                if task==\"binary\":\n",
    "                    return average_precision_score(y, p.reshape(-1))\n",
    "                else:\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    cls = np.unique(y)\n",
    "                    Y = label_binarize(y, classes=cls)\n",
    "                    return average_precision_score(Y, p, average=\"macro\")\n",
    "            return f\n",
    "        if name == \"logloss\":\n",
    "            def f(y, p):\n",
    "                if task==\"binary\":\n",
    "                    q = np.clip(p.reshape(-1), 1e-15, 1-1e-15)\n",
    "                    P = np.vstack([1-q, q]).T\n",
    "                    return -log_loss(y, P, labels=[0,1])\n",
    "                else:\n",
    "                    return -log_loss(y, p)\n",
    "            return f\n",
    "        if name in (\"accuracy\",\"acc\"):\n",
    "            def f(y, p):\n",
    "                if task==\"binary\":\n",
    "                    return ( (p.reshape(-1)>=0.5).astype(int) == y ).mean()\n",
    "                else:\n",
    "                    return ( np.argmax(p,1) == y ).mean()\n",
    "            return f\n",
    "        if name in (\"f1\",\"macro_f1\"):\n",
    "            def f(y, p):\n",
    "                if task==\"binary\":\n",
    "                    return f1_score(y, (p.reshape(-1)>=0.5).astype(int))\n",
    "                else:\n",
    "                    return f1_score(y, np.argmax(p,1), average=\"macro\")\n",
    "            return f\n",
    "    # regression\n",
    "    if name==\"rmse\":\n",
    "        def f(y, p): return -math.sqrt(mean_squared_error(y, p))\n",
    "        return f\n",
    "    if name==\"mae\":\n",
    "        def f(y, p): return -mean_absolute_error(y, p)\n",
    "        return f\n",
    "    if name==\"mape\":\n",
    "        def f(y, p):\n",
    "            y = np.asarray(y,float)\n",
    "            p = np.asarray(p,float)\n",
    "            eps=1e-9\n",
    "            return -np.mean(np.abs((y-p)/np.clip(np.abs(y),eps,None)))*100\n",
    "        return f\n",
    "    raise ValueError(f\"Unknown metric {name}\")\n",
    "\n",
    "def normalize_pred_for_task(task: str, arr: np.ndarray) -> np.ndarray:\n",
    "    a = np.asarray(arr)\n",
    "    if task==\"binary\":\n",
    "        if a.ndim==1: return a\n",
    "        if a.ndim==2:\n",
    "            if a.shape[1]==1: return a.reshape(-1)\n",
    "            if a.shape[1]==2: return a[:,1]\n",
    "            return a.max(1)\n",
    "        return a.reshape(-1)\n",
    "    elif task==\"multiclass\":\n",
    "        assert a.ndim==2, \"multiclass ожидает (n, C)\"\n",
    "        return a\n",
    "    else:\n",
    "        return a.reshape(-1)\n",
    "\n",
    "def clip_proba(p, eps=1e-6):\n",
    "    return np.clip(p, eps, 1-eps)\n",
    "\n",
    "def to_blend_space(task: str, X: np.ndarray, space: str) -> np.ndarray:\n",
    "    space = space.lower()\n",
    "    if space==\"proba\":\n",
    "        if task==\"binary\":\n",
    "            return clip_proba(X)\n",
    "        if task==\"multiclass\":\n",
    "            return np.clip(X, 1e-8, 1-1e-8)\n",
    "        return X\n",
    "    if space==\"logit\":\n",
    "        if task==\"binary\":\n",
    "            p = clip_proba(X)\n",
    "            return np.log(p/(1-p))\n",
    "        if task==\"multiclass\":\n",
    "            P = np.clip(X, 1e-8, 1-1e-8)\n",
    "            Z = np.log(P/np.clip(1-P,1e-8,None))\n",
    "            return Z\n",
    "        return X\n",
    "    if space==\"rank\":\n",
    "        if task in (\"binary\",\"regression\"):\n",
    "            r = pd.Series(X).rank(method=\"average\").to_numpy()\n",
    "            r = (r-1)/max(len(r)-1,1)\n",
    "            return r\n",
    "        if task==\"multiclass\":\n",
    "            R = np.zeros_like(X, float)\n",
    "            for c in range(X.shape[1]):\n",
    "                rc = pd.Series(X[:,c]).rank(method=\"average\").to_numpy()\n",
    "                rc = (rc-1)/max(len(rc)-1,1)\n",
    "                R[:,c] = rc\n",
    "            return R\n",
    "        return X\n",
    "    raise ValueError(space)\n",
    "\n",
    "def from_blend_space(task: str, yb: np.ndarray, space: str) -> np.ndarray:\n",
    "    space = space.lower()\n",
    "    if space==\"logit\":\n",
    "        if task==\"binary\":\n",
    "            return 1/(1+np.exp(-yb))\n",
    "        if task==\"multiclass\":\n",
    "            P = 1/(1+np.exp(-yb))\n",
    "            P = P/np.clip(P.sum(1, keepdims=True), 1e-8, None)\n",
    "            return P\n",
    "        return yb\n",
    "    # rank/proba — уже [0..1] или proba\n",
    "    return yb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be59592",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_LAYOUT = W.Layout(min_width=\"220px\", width=\"auto\", height=\"36px\", flex=\"0 0 auto\")\n",
    "ROW_LAYOUT = W.Layout(flex_flow=\"row wrap\", grid_gap=\"8px\")\n",
    "GRID_LAYOUT = W.Layout(grid_template_columns=\"repeat(3, minmax(220px, 1fr))\", grid_gap=\"8px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Автосписок тэгов\n",
    "AVAILABLE_TAGS = [p.name for p in SETS_ROOT.glob(\"*\") if p.is_dir()]\n",
    "AVAILABLE_TAGS.sort()\n",
    "\n",
    "# UI\n",
    "if W:\n",
    "    dd_tag = W.Dropdown(options=AVAILABLE_TAGS, description=\"RUN_TAG:\", layout=W.Layout(width=\"400px\"))\n",
    "    btn_check = W.Button(description=\"Проверить набор\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "    out_check = W.Output()\n",
    "    display(W.HBox([dd_tag, btn_check], layout=ROW_LAYOUT), out_check)\n",
    "else:\n",
    "    print(\"Доступные RUN_TAG:\", AVAILABLE_TAGS)\n",
    "    dd_tag = type(\"Dummy\", (), {\"value\": AVAILABLE_TAGS[-1] if AVAILABLE_TAGS else None})()\n",
    "    print(\"Использую:\", dd_tag.value)\n",
    "\n",
    "STATE = {\n",
    "    \"RUN_TAG\": None,\n",
    "    \"task\": None,\n",
    "    \"metric\": \"roc_auc\",\n",
    "    \"y\": None,\n",
    "    \"folds\": None,\n",
    "    \"ids_test\": None,\n",
    "    \"id_col\": None,\n",
    "    \"target_col\": None\n",
    "}\n",
    "\n",
    "def check_set(tag: str):\n",
    "    base = SETS_ROOT / tag\n",
    "    y_path = base / \"y_train.parquet\"\n",
    "    ids_path = base / \"ids_test.parquet\"\n",
    "    folds_path = base / \"folds.pkl\"\n",
    "\n",
    "    ydf = read_parquet_any(y_path)\n",
    "    ids = read_parquet_any(ids_path)\n",
    "    folds = None\n",
    "    if (folds_path).exists():\n",
    "        import pickle\n",
    "        folds = pickle.loads(folds_path.read_bytes())\n",
    "\n",
    "    if ydf is None or ydf.shape[1] < 2:\n",
    "        print(\"[warn] Нет y_train.parquet с id+target — можно починить внизу.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    id_col = ydf.columns[0]\n",
    "    target_col = [c for c in ydf.columns if c != id_col][0]\n",
    "    y = ydf[target_col].to_numpy()\n",
    "\n",
    "    task = detect_task_from_y(y)\n",
    "    print(f\"RUN_TAG={tag} | y: {y.shape} | ids_test: {None if ids is None else ids.shape} | folds: {None if folds is None else len(folds)}\")\n",
    "    print(f\"task: {task} | id_col: {id_col} | target_col: {target_col}\")\n",
    "\n",
    "    return y, folds, ids, id_col, target_col\n",
    "\n",
    "def on_check(_):\n",
    "    out_check.clear_output()\n",
    "    with out_check:\n",
    "        tag = dd_tag.value\n",
    "        STATE[\"RUN_TAG\"] = tag\n",
    "        y, folds, ids, id_col, target_col = check_set(tag)\n",
    "        STATE.update({\"y\": y, \"folds\": folds, \"ids_test\": ids, \"id_col\": id_col, \"target_col\": target_col, \"task\": detect_task_from_y(y) if y is not None else None})\n",
    "\n",
    "if W:\n",
    "    btn_check.on_click(on_check)\n",
    "else:\n",
    "    # автопроверка\n",
    "    STATE[\"RUN_TAG\"] = dd_tag.value\n",
    "    y, folds, ids, id_col, target_col = check_set(dd_tag.value)\n",
    "    STATE.update({\"y\": y, \"folds\": folds, \"ids_test\": ids, \"id_col\": id_col, \"target_col\": target_col, \"task\": detect_task_from_y(y) if y is not None else None})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cf7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Если данных не хватает, можно собрать y_train/ids_test с нуля из CSV.\n",
    "# Укажи пути и колонки и нажми \"Собрать сет-файлы\".\n",
    "\n",
    "if W:\n",
    "    tb_data_dir = W.Text(value=\"data\", description=\"DATA_DIR:\", layout=W.Layout(width=\"400px\"))\n",
    "    tb_train = W.Text(value=\"train.csv\", description=\"TRAIN:\", layout=W.Layout(width=\"400px\"))\n",
    "    tb_test = W.Text(value=\"test.csv\", description=\"TEST:\", layout=W.Layout(width=\"400px\"))\n",
    "    tb_id = W.Text(value=\"id\", description=\"ID_COL:\", layout=W.Layout(width=\"300px\"))\n",
    "    tb_tgt = W.Text(value=\"target\", description=\"TARGET_COL:\", layout=W.Layout(width=\"300px\"))\n",
    "    btn_fix = W.Button(description=\"Собрать сет-файлы\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "    out_fix = W.Output()\n",
    "    display(W.HBox([tb_data_dir, tb_train, tb_test], layout=ROW_LAYOUT), W.HBox([tb_id, tb_tgt], layout=ROW_LAYOUT), W.HBox([btn_fix], layout=ROW_LAYOUT), out_fix)\n",
    "else:\n",
    "    print(\"Если нужно, вручную создай y_train.parquet (id+target) и ids_test.parquet (id).\")\n",
    "\n",
    "def fix_set(_):\n",
    "    out_fix.clear_output()\n",
    "    with out_fix:\n",
    "        if not STATE[\"RUN_TAG\"]:\n",
    "            print(\"Сначала выбери RUN_TAG и нажми Проверить.\")\n",
    "            return\n",
    "        base = SETS_ROOT / STATE[\"RUN_TAG\"]\n",
    "        ensure_dir(base)\n",
    "\n",
    "        data_dir = Path(tb_data_dir.value)\n",
    "        train_p = data_dir / tb_train.value\n",
    "        test_p = data_dir / tb_test.value\n",
    "        idc = tb_id.value\n",
    "        tgt = tb_tgt.value\n",
    "\n",
    "        if not train_p.exists():\n",
    "            print(\"Нет TRAIN CSV:\", train_p); return\n",
    "        if not test_p.exists():\n",
    "            print(\"Нет TEST CSV:\", test_p); return\n",
    "\n",
    "        tr = pd.read_csv(train_p)\n",
    "        te = pd.read_csv(test_p)\n",
    "        assert idc in tr.columns and idc in te.columns, \"ID_COL не найден\"\n",
    "        assert tgt in tr.columns, \"TARGET_COL не найден в train\"\n",
    "\n",
    "        ydf = tr[[idc, tgt]].copy()\n",
    "        ids = te[[idc]].copy()\n",
    "\n",
    "        y_path = base/\"y_train.parquet\"\n",
    "        ids_path = base/\"ids_test.parquet\"\n",
    "        ydf.to_parquet(y_path)\n",
    "        ids.to_parquet(ids_path)\n",
    "        print(\"Собрано:\", y_path, ids_path)\n",
    "\n",
    "        # создадим KFold по умолчанию, если нет time/group\n",
    "        from sklearn.model_selection import KFold\n",
    "        idx = np.arange(len(ydf))\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        folds = [(tr_idx, va_idx) for tr_idx, va_idx in kf.split(idx)]\n",
    "        import pickle\n",
    "        (base/\"folds.pkl\").write_bytes(pickle.dumps(folds))\n",
    "        print(\"Создан folds.pkl (KFold=5)\")\n",
    "\n",
    "        # Обновим состояние:\n",
    "        y, folds, ids, id_col, target_col = check_set(STATE[\"RUN_TAG\"])\n",
    "        STATE.update({\"y\": y, \"folds\": folds, \"ids_test\": ids, \"id_col\": id_col, \"target_col\": target_col, \"task\": detect_task_from_y(y)})\n",
    "\n",
    "if W:\n",
    "    btn_fix.on_click(fix_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430541db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Метрика (по умолчанию roc_auc для binary/multiclass, rmse для regression)\n",
    "\n",
    "if W:\n",
    "    dd_metric = W.Dropdown(options=[\"roc_auc\",\"pr_auc\",\"logloss\",\"accuracy\",\"f1\",\"rmse\",\"mae\",\"mape\"],\n",
    "                           description=\"metric:\", value=\"roc_auc\", layout=W.Layout(width=\"300px\"))\n",
    "    btn_load_runs = W.Button(description=\"Загрузить список кандидатов\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "    out_runs = W.Output()\n",
    "    display(W.HBox([dd_metric, btn_load_runs], layout=ROW_LAYOUT), out_runs)\n",
    "else:\n",
    "    dd_metric = type(\"Dummy\", (), {\"value\":\"roc_auc\"})()\n",
    "    out_runs = None\n",
    "\n",
    "RUNS_DF = None\n",
    "\n",
    "def load_runs(_):\n",
    "    global RUNS_DF\n",
    "    if STATE[\"RUN_TAG\"] is None:\n",
    "        print(\"Сначала выбери RUN_TAG\"); return\n",
    "    idx = read_json(MODELS_INDEX) or {}\n",
    "    rows = []\n",
    "    for rid, rec in idx.items():\n",
    "        if rec.get(\"tag\")==STATE[\"RUN_TAG\"]:\n",
    "            rows.append({\n",
    "                \"run_id\": rid,\n",
    "                \"cand\": rec.get(\"cand\"),\n",
    "                \"task\": rec.get(\"task\"),\n",
    "                \"metric\": rec.get(\"metric\"),\n",
    "                \"cv_mean\": rec.get(\"cv_mean\"),\n",
    "                \"path\": rec.get(\"path\"),\n",
    "                \"blend\": bool(rec.get(\"blend\", False))\n",
    "            })\n",
    "    RUNS_DF = pd.DataFrame(rows).sort_values(\"cv_mean\", ascending=False).reset_index(drop=True)\n",
    "    with out_runs:\n",
    "        out_runs.clear_output()\n",
    "        if len(RUNS_DF)==0:\n",
    "            print(\"Нет кандидатов для этого RUN_TAG\")\n",
    "        else:\n",
    "            display(RUNS_DF)\n",
    "\n",
    "if W:\n",
    "    btn_load_runs.on_click(load_runs)\n",
    "else:\n",
    "    load_runs(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf450cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SELECTED_RUNS = []\n",
    "\n",
    "if W:\n",
    "    # Список доступных\n",
    "    def refresh_picklist():\n",
    "        if RUNS_DF is None or len(RUNS_DF)==0:\n",
    "            return W.SelectMultiple(options=[], description=\"runs\")\n",
    "        opts = [f'{r.run_id} | {r.cand} | {r.cv_mean:.6f}' for _, r in RUNS_DF.iterrows()]\n",
    "        return W.SelectMultiple(options=opts, description=\"members:\", rows=12, layout=W.Layout(width=\"750px\"))\n",
    "\n",
    "    pick = refresh_picklist()\n",
    "    btn_pick = W.Button(description=\"Добавить в корзину\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "    btn_clear = W.Button(description=\"Очистить корзину\", layout=BTN_LAYOUT)\n",
    "    out_pick = W.Output()\n",
    "\n",
    "    def _on_pick(_):\n",
    "        with out_pick:\n",
    "            for s in pick.value:\n",
    "                rid = s.split(\" | \")[0].strip()\n",
    "                if rid not in SELECTED_RUNS:\n",
    "                    SELECTED_RUNS.append(rid)\n",
    "            print(\"Корзина:\", SELECTED_RUNS)\n",
    "\n",
    "    def _on_clear(_):\n",
    "        SELECTED_RUNS.clear()\n",
    "        with out_pick:\n",
    "            out_pick.clear_output()\n",
    "            print(\"Корзина очищена.\")\n",
    "\n",
    "    btn_pick.on_click(_on_pick)\n",
    "    btn_clear.on_click(_on_clear)\n",
    "\n",
    "    display(pick, W.HBox([btn_pick, btn_clear], layout=ROW_LAYOUT), out_pick)\n",
    "else:\n",
    "    print(\"Укажи вручную SELECTED_RUNS = [...]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72637726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OOF_CACHE = {}   # run_id -> np.ndarray\n",
    "TEST_CACHE = {}  # run_id -> np.ndarray|None\n",
    "LOCAL_SCORES = {}  # run_id -> float\n",
    "\n",
    "def load_member_preds(run_id: str, task: str):\n",
    "    idx = read_json(MODELS_INDEX) or {}\n",
    "    rec = idx.get(run_id)\n",
    "    if rec is None:\n",
    "        raise KeyError(f\"Нет в index.json: {run_id}\")\n",
    "    path = Path(rec.get(\"path\",\"\"))\n",
    "    if not path.exists():\n",
    "        path = Path(\"artifacts/models\")/run_id\n",
    "    oof_p = path/\"oof.npy\"\n",
    "    test_p = path/\"test_pred.npy\"\n",
    "    oof = np.load(oof_p)\n",
    "    test = np.load(test_p) if test_p.exists() else None\n",
    "    return normalize_pred_for_task(task, oof), (None if test is None else normalize_pred_for_task(task, test))\n",
    "\n",
    "def compute_local_scores():\n",
    "    if STATE[\"y\"] is None: return\n",
    "    y = STATE[\"y\"]\n",
    "    task = STATE[\"task\"]\n",
    "    scorer = metric_fn(task, dd_metric.value)\n",
    "    LOCAL_SCORES.clear()\n",
    "    for rid in SELECTED_RUNS:\n",
    "        p = OOF_CACHE[rid]\n",
    "        try:\n",
    "            LOCAL_SCORES[rid] = float(scorer(y, p))\n",
    "        except Exception as e:\n",
    "            LOCAL_SCORES[rid] = float(\"nan\")\n",
    "\n",
    "def load_selected():\n",
    "    if STATE[\"task\"] is None:\n",
    "        print(\"Сначала проверь сет (RUN_TAG)\"); return\n",
    "    for rid in SELECTED_RUNS:\n",
    "        if rid not in OOF_CACHE:\n",
    "            p_oof, p_test = load_member_preds(rid, STATE[\"task\"])\n",
    "            OOF_CACHE[rid] = p_oof\n",
    "            TEST_CACHE[rid] = p_test\n",
    "    compute_local_scores()\n",
    "    df = pd.DataFrame([{ \"run_id\": rid, \"local_metric\": LOCAL_SCORES.get(rid)} for rid in SELECTED_RUNS])            .sort_values(\"local_metric\", ascending=False)\n",
    "    display(df)\n",
    "\n",
    "load_selected()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cabba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def oof_corr_matrix(task: str, run_ids: list[str]) -> pd.DataFrame:\n",
    "    if len(run_ids) < 2:\n",
    "        return pd.DataFrame()\n",
    "    if task==\"multiclass\":\n",
    "        # возьмём max по классу как быструю эвристику\n",
    "        M = np.column_stack([OOF_CACHE[r].max(1) for r in run_ids])\n",
    "    else:\n",
    "        M = np.column_stack([OOF_CACHE[r].reshape(-1) for r in run_ids])\n",
    "    C = np.corrcoef(M.T)\n",
    "    return pd.DataFrame(C, index=run_ids, columns=run_ids)\n",
    "\n",
    "if len(SELECTED_RUNS) >= 2:\n",
    "    corr = oof_corr_matrix(STATE[\"task\"], SELECTED_RUNS)\n",
    "    display(corr.round(3))\n",
    "    plt.imshow(corr.values, interpolation=\"nearest\")\n",
    "    plt.xticks(range(len(SELECTED_RUNS)), SELECTED_RUNS, rotation=90)\n",
    "    plt.yticks(range(len(SELECTED_RUNS)), SELECTED_RUNS)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"OOF correlation\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Добавь >=2 моделей для анализа корреляций.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc60f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if W:\n",
    "    rb_space = W.RadioButtons(options=[\"proba\",\"logit\",\"rank\"], description=\"space:\", value=\"rank\")\n",
    "    dd_mode = W.Dropdown(options=[\"equal\",\"dirichlet\",\"nnls\",\"coord\",\"level2\"], description=\"mode:\", value=\"dirichlet\")\n",
    "\n",
    "    hb_params = W.HBox([\n",
    "        W.IntText(value=4000, description=\"dir_samples\"),\n",
    "        W.Checkbox(value=True, description=\"nnls (warm)\"),\n",
    "        W.IntText(value=2000, description=\"coord_iters\"),\n",
    "        W.FloatText(value=0.01, description=\"coord_step\"),\n",
    "        W.Checkbox(value=True, description=\"nonneg\"),\n",
    "        W.Checkbox(value=True, description=\"sum1\"),\n",
    "        W.Checkbox(value=True, description=\"cv_weights\"),\n",
    "        W.Checkbox(value=False, description=\"reopt_after_cv\"),\n",
    "    ], layout=ROW_LAYOUT)\n",
    "    display(rb_space, dd_mode, hb_params)\n",
    "else:\n",
    "    rb_space = type(\"Dummy\", (), {\"value\":\"rank\"})()\n",
    "    dd_mode = type(\"Dummy\", (), {\"value\":\"dirichlet\"})()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66086538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_blend_analyze():\n",
    "    assert STATE[\"RUN_TAG\"], \"RUN_TAG не выбран\"\n",
    "    assert len(SELECTED_RUNS)>=1, \"Нет участников\"\n",
    "    members = \",\".join(SELECTED_RUNS)\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, \"tools/run_blend.py\",\n",
    "        \"--tag\", STATE[\"RUN_TAG\"],\n",
    "        \"--members\", members,\n",
    "        \"--mode\", dd_mode.value,\n",
    "        \"--metric\", dd_metric.value,\n",
    "        \"--task\", STATE[\"task\"],\n",
    "        \"--blend-space\", rb_space.value,\n",
    "        \"--sets-dir\", str(SETS_ROOT/STATE[\"RUN_TAG\"]),\n",
    "        \"--models-index\", str(MODELS_INDEX),\n",
    "        \"--analyze-only\",\n",
    "        \"--verbose\"\n",
    "    ]\n",
    "    # параметры\n",
    "    if dd_mode.value == \"dirichlet\":\n",
    "        ds = 4000 if not W else hb_params.children[0].value\n",
    "        cmd += [\"--dirichlet-samples\", str(ds)]\n",
    "    if dd_mode.value == \"coord\":\n",
    "        ct = 2000 if not W else hb_params.children[2].value\n",
    "        cs = 0.01 if not W else hb_params.children[3].value\n",
    "        cmd += [\"--coord-iters\", str(ct), \"--coord-step\", str(cs)]\n",
    "    if (not W and True) or (W and hb_params.children[1].value):\n",
    "        cmd += [\"--nnls\"]\n",
    "    if (not W and True) or (W and hb_params.children[4].value):\n",
    "        cmd += [\"--nonneg\"]\n",
    "    if (not W and True) or (W and hb_params.children[5].value):\n",
    "        cmd += [\"--sum-to-one\"]\n",
    "    if (not W and True) or (W and hb_params.children[6].value):\n",
    "        cmd += [\"--cv-weights\"]\n",
    "    if (not W and False) or (W and hb_params.children[7].value):\n",
    "        cmd += [\"--reopt-after-cv\"]\n",
    "\n",
    "    rc, out, err = run_cmd(cmd, verbose=True)\n",
    "    return rc, out, err\n",
    "\n",
    "rc, out, err = run_blend_analyze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdd867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if STATE[\"task\"]==\"binary\":\n",
    "    if W:\n",
    "        dd_cal = W.Dropdown(options=[\"off\",\"platt\",\"isotonic\"], value=\"off\", description=\"calibrate:\")\n",
    "        dd_thr = W.Text(value=\"off\", description=\"threshold:\")\n",
    "        display(dd_cal, dd_thr)\n",
    "    else:\n",
    "        dd_cal = type(\"D\", (), {\"value\":\"off\"})()\n",
    "        dd_thr = type(\"D\", (), {\"value\":\"off\"})()\n",
    "else:\n",
    "    dd_cal = type(\"D\", (), {\"value\":\"off\"})()\n",
    "    dd_thr = type(\"D\", (), {\"value\":\"off\"})()\n",
    "\n",
    "print(\"Подсказка: для AUC сабмита обычно калибровка/τ не применяются к файлу сабмита (только к отчёту).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_blend_save(name: str, save_test: bool=True):\n",
    "    assert STATE[\"RUN_TAG\"], \"RUN_TAG не выбран\"\n",
    "    assert len(SELECTED_RUNS)>=1, \"Нет участников\"\n",
    "    members = \",\".join(SELECTED_RUNS)\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, \"tools/run_blend.py\",\n",
    "        \"--tag\", STATE[\"RUN_TAG\"],\n",
    "        \"--members\", members,\n",
    "        \"--mode\", dd_mode.value,\n",
    "        \"--metric\", dd_metric.value,\n",
    "        \"--task\", STATE[\"task\"],\n",
    "        \"--blend-space\", rb_space.value,\n",
    "        \"--sets-dir\", str(SETS_ROOT/STATE[\"RUN_TAG\"]),\n",
    "        \"--models-index\", str(MODELS_INDEX),\n",
    "        \"--name\", name\n",
    "    ]\n",
    "    if dd_mode.value == \"dirichlet\":\n",
    "        ds = 4000 if not W else hb_params.children[0].value\n",
    "        cmd += [\"--dirichlet-samples\", str(ds)]\n",
    "    if dd_mode.value == \"coord\":\n",
    "        ct = 2000 if not W else hb_params.children[2].value\n",
    "        cs = 0.01 if not W else hb_params.children[3].value\n",
    "        cmd += [\"--coord-iters\", str(ct), \"--coord-step\", str(cs)]\n",
    "    if (not W and True) or (W and hb_params.children[1].value): cmd += [\"--nnls\"]\n",
    "    if (not W and True) or (W and hb_params.children[4].value): cmd += [\"--nonneg\"]\n",
    "    if (not W and True) or (W and hb_params.children[5].value): cmd += [\"--sum-to-one\"]\n",
    "    if (not W and True) or (W and hb_params.children[6].value): cmd += [\"--cv-weights\"]\n",
    "    if (not W and False) or (W and hb_params.children[7].value): cmd += [\"--reopt-after-cv\"]\n",
    "\n",
    "    if STATE[\"task\"]==\"binary\":\n",
    "        cmd += [\"--calibrate\", (dd_cal.value if W else \"off\")]\n",
    "        cmd += [\"--threshold\", (dd_thr.value if W else \"off\")]\n",
    "    if save_test:\n",
    "        cmd += [\"--save-test\"]\n",
    "\n",
    "    rc, out, err = run_cmd(cmd, verbose=True)\n",
    "    return rc, out\n",
    "\n",
    "# UI\n",
    "if W:\n",
    "    tb_name = W.Text(value=\"auc_rank_dir\", description=\"blend name:\")\n",
    "    cb_save_test = W.Checkbox(value=True, description=\"save test\")\n",
    "    btn_save = W.Button(description=\"Сохранить бленд\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "    out_save = W.Output()\n",
    "    display(W.HBox([tb_name, cb_save_test], layout=ROW_LAYOUT), btn_save, out_save)\n",
    "\n",
    "    def _on_save(_):\n",
    "        out_save.clear_output()\n",
    "        with out_save:\n",
    "            rc, out = run_blend_save(tb_name.value, cb_save_test.value)\n",
    "            print(\"RC:\", rc)\n",
    "    btn_save.on_click(_on_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_blends_for_tag(tag: str):\n",
    "    rows=[]\n",
    "    for d in BLENDS_ROOT.glob(\"*/metrics.json\"):\n",
    "        cfg = read_json(d.parent/\"config.json\")\n",
    "        met = read_json(d)\n",
    "        if not cfg: continue\n",
    "        if cfg.get(\"tag\") != tag: continue\n",
    "        rows.append({\n",
    "            \"blend_id\": d.parent.name,\n",
    "            \"mode\": cfg.get(\"mode\"),\n",
    "            \"space\": cfg.get(\"blend_space\"),\n",
    "            \"metric\": met.get(\"oof_metric\"),\n",
    "            \"metric_name\": met.get(\"oof_metric_name\"),\n",
    "            \"calibration\": cfg.get(\"calibration\"),\n",
    "            \"threshold\": cfg.get(\"threshold\"),\n",
    "            \"members\": \",\".join(cfg.get(\"members\",[]))\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"metric\", ascending=False)\n",
    "    return df\n",
    "\n",
    "if STATE[\"RUN_TAG\"]:\n",
    "    display(list_blends_for_tag(STATE[\"RUN_TAG\"]))\n",
    "else:\n",
    "    print(\"Выбери RUN_TAG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Выбор blend_id, имя сабмита, имя столбца (целевой), контроль id-колонки.\n",
    "\n",
    "if W:\n",
    "    # Соберём список blend_id\n",
    "    OPTS = [p.name for p in BLENDS_ROOT.glob(\"*\") if (p/\"config.json\").exists()]\n",
    "    dd_blend = W.Dropdown(options=OPTS, description=\"blend_id:\", layout=W.Layout(width=\"500px\"))\n",
    "    tb_subname = W.Text(value=f\"submit_{datetime.now().strftime('%m%d_%H%M')}\", description=\"SUB_TAG:\")\n",
    "    tb_col = W.Text(value=STATE[\"target_col\"] or \"target\", description=\"submit_col:\")\n",
    "    btn_makesub = W.Button(description=\"Сформировать сабмит\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "    out_sub = W.Output()\n",
    "    display(W.HBox([dd_blend, tb_subname], layout=ROW_LAYOUT), tb_col, btn_makesub, out_sub)\n",
    "else:\n",
    "    print(\"Укажи вручную переменные: SELECTED_BLEND_ID, SUB_TAG, SUBMIT_COL\")\n",
    "\n",
    "def make_submit(blend_id: str, sub_tag: str, submit_col: str):\n",
    "    assert STATE[\"RUN_TAG\"], \"RUN_TAG?\"\n",
    "    base = SETS_ROOT/STATE[\"RUN_TAG\"]\n",
    "    ids = read_parquet_any(base/\"ids_test.parquet\")\n",
    "    assert ids is not None, \"Нет ids_test.parquet\"\n",
    "    id_col = ids.columns[0]\n",
    "\n",
    "    bdir = BLENDS_ROOT/blend_id\n",
    "    test_p = bdir/\"test_pred.npy\"\n",
    "    assert test_p.exists(), \"В бленде нет test_pred.npy (пересоздай с --save-test)\"\n",
    "\n",
    "    yhat = np.load(test_p)\n",
    "    # бинарь/регрессия — вектор; multiclass — нужно выбрать класс/вероятности\n",
    "    if STATE[\"task\"]==\"multiclass\":\n",
    "        # делаем сабмит «класс» или «proba class_k?» — зависит от регламента.\n",
    "        # По умолчанию выведем класс argmax как baseline:\n",
    "        yout = np.argmax(yhat,1)\n",
    "    else:\n",
    "        yout = yhat.reshape(-1)\n",
    "\n",
    "    sub = pd.DataFrame({id_col: ids[id_col].values, submit_col: yout})\n",
    "    SUB_DIR = SUBMITS_ROOT/STATE[\"RUN_TAG\"]/sub_tag\n",
    "    ensure_dir(SUB_DIR)\n",
    "    out_csv = SUB_DIR/\"submission.csv\"\n",
    "    sub.to_csv(out_csv, index=False)\n",
    "\n",
    "    manifest = {\n",
    "        \"run_tag\": STATE[\"RUN_TAG\"],\n",
    "        \"blend_id\": blend_id,\n",
    "        \"submit_col\": submit_col,\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"task\": STATE[\"task\"]\n",
    "    }\n",
    "    save_json(SUB_DIR/\"manifest.json\", manifest)\n",
    "    print(\"Готово →\", out_csv)\n",
    "    display(sub.head())\n",
    "\n",
    "if W:\n",
    "    def _on_make(_):\n",
    "        out_sub.clear_output()\n",
    "        with out_sub:\n",
    "            make_submit(dd_blend.value, tb_subname.value, tb_col.value)\n",
    "    btn_makesub.on_click(_on_make)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Быстрая диагностика: бинарь — метрика по квинтилям/категориям относительно колонки из y_train.parquet.\n",
    "# Для multiclass/regression можно расширить аналогично.\n",
    "\n",
    "def slice_metric_binary(y, p, mask, scorer):\n",
    "    try:\n",
    "        return float(scorer(y[mask], p[mask]))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def quick_slices_binary(colname: str, bins: int=5):\n",
    "    assert STATE[\"task\"]==\"binary\", \"Сейчас реализовано для binary\"\n",
    "    y_path = SETS_ROOT/STATE[\"RUN_TAG\"]/ \"y_train.parquet\"\n",
    "    ydf = read_parquet_any(y_path).copy()\n",
    "    id_col = ydf.columns[0]\n",
    "    tgt_col = [c for c in ydf.columns if c!=id_col][0]\n",
    "\n",
    "    # нужна OOF выбранного бленда или одного из run_id\n",
    "    ref = None\n",
    "    if len(SELECTED_RUNS)>=1:\n",
    "        # возьмем первую модель как пример\n",
    "        ref = OOF_CACHE[SELECTED_RUNS[0]].reshape(-1)\n",
    "    else:\n",
    "        print(\"Добавь модели и перезагрузи OOF\")\n",
    "        return\n",
    "\n",
    "    scorer = metric_fn(\"binary\", dd_metric.value)\n",
    "\n",
    "    if colname not in ydf.columns:\n",
    "        print(\"Колонки нет в y_train.parquet\")\n",
    "        return\n",
    "\n",
    "    x = ydf[colname]\n",
    "    y = ydf[tgt_col].values\n",
    "    p = ref\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(x):\n",
    "        q = pd.qcut(x, q=bins, duplicates='drop')\n",
    "        tab = []\n",
    "        for lvl in sorted(q.cat.categories, key=lambda z: z.left):\n",
    "            mask = (q == lvl).values\n",
    "            tab.append({\"bin\": str(lvl), \"n\": int(mask.sum()), \"metric\": slice_metric_binary(y, p, mask, scorer)})\n",
    "        df = pd.DataFrame(tab)\n",
    "    else:\n",
    "        vc = x.value_counts()\n",
    "        cats = list(vc.index)\n",
    "        tab = []\n",
    "        for c in cats[:min(len(cats), 12)]:\n",
    "            mask = (x==c).values\n",
    "            tab.append({\"cat\": str(c), \"n\": int(mask.sum()), \"metric\": slice_metric_binary(y, p, mask, scorer)})\n",
    "        df = pd.DataFrame(tab).sort_values(\"metric\", ascending=False)\n",
    "\n",
    "    display(df)\n",
    "\n",
    "# Пример вызова:\n",
    "# quick_slices_binary(\"some_column\", bins=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def panic_blend():\n",
    "    # топ-3 по локальной метрике → rank-space + dirichlet + cv_weights, без калибровки\n",
    "    if len(LOCAL_SCORES)==0:\n",
    "        print(\"Нет локальных метрик (загрузи OOF)\"); return\n",
    "    top = sorted(LOCAL_SCORES.items(), key=lambda kv: kv[1], reverse=True)[:3]\n",
    "    members = [k for k,_ in top]\n",
    "    print(\"panic members:\", members)\n",
    "    cmd = [\n",
    "        sys.executable, \"tools/run_blend.py\",\n",
    "        \"--tag\", STATE[\"RUN_TAG\"], \"--members\", \",\".join(members),\n",
    "        \"--mode\", \"dirichlet\", \"--blend-space\", \"rank\",\n",
    "        \"--metric\", dd_metric.value, \"--task\", STATE[\"task\"],\n",
    "        \"--cv-weights\", \"--dirichlet-samples\", \"4000\",\n",
    "        \"--sets-dir\", str(SETS_ROOT/STATE[\"RUN_TAG\"]),\n",
    "        \"--models-index\", str(MODELS_INDEX),\n",
    "        \"--name\", \"panic_rank_dir\", \"--save-test\"\n",
    "    ]\n",
    "    run_cmd(cmd, verbose=True)\n",
    "\n",
    "# panic_blend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e21fc",
   "metadata": {},
   "source": [
    "\n",
    "### Траблшутинг\n",
    "- **Нет `y_train.parquet` или `ids_test.parquet`** → собери в Ячейке 3 (ремонт).\n",
    "- **У участников разная длина OOF** → убедись, что все `run_id` обучались на одном `RUN_TAG`.\n",
    "- **`level2` требует `folds.pkl`** → собери KFold в Ячейке 3 или используй режимы весов.\n",
    "- **`logit`-space** → до логита клиппим `p∈[1e-6, 1-1e-6]`, в multiclass возвращаемся к вероятностям нормировкой по строке.\n",
    "- **Сабмит под AUC/PR** → в файл сабмита кладём **скоры/вероятности**, не классы, τ хранится в manifest.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
