{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ecd8d0",
   "metadata": {},
   "source": [
    "# 01 ¬∑ Data Sanity ‚Äî –±—ã—Å—Ç—Ä—ã–π —Ä–µ–Ω—Ç–≥–µ–Ω –¥–∞–Ω–Ω—ã—Ö ‚öôÔ∏è\n",
    "\n",
    "–¶–µ–ª—å:\n",
    "- –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ö–µ–º—É, –≤—Ä–µ–º—è, –¥—É–±–ª–∏–∫–∞—Ç—ã/–ø—Ä–æ–ø—É—Å–∫–∏, –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, —Ö–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç;\n",
    "- –ø–æ—Å—Ç—Ä–æ–∏—Ç—å (–ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏) `session_id`;\n",
    "- —Å–¥–µ–ª–∞—Ç—å time-safe —Å–ø–ª–∏—Ç—ã —Å —ç–º–±–∞—Ä–≥–æ;\n",
    "- —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ parquet + `splits.json` + –∫—Ä–∞—Ç–∫–∏–π `report.json`.\n",
    "\n",
    "**–°—Ç–æ–ø-—É—Å–ª–æ–≤–∏—è:** –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –∫–ª—é—á–∞—Ö, –≥—Ä—É–±—ã–µ —É—Ç–µ—á–∫–∏ –≤—Ä–µ–º–µ–Ω–∏, –ø—É—Å—Ç–æ–π –≤–∞–ª/—Ç–µ—Å—Ç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35382a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* ipywidgets v8 (JupyterLab 4) */\n",
    ".jp-OutputArea .widget-button .widget-label { \n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "/* fallback –¥–ª—è ipywidgets v7 */\n",
    ".jupyter-widgets.widget-button .widget-label {\n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, math, glob, shlex, subprocess, warnings, pathlib, time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as W\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "REPO = Path.cwd()\n",
    "ART_ROOT = Path(\"artifacts/recsys/dataio\")\n",
    "\n",
    "def mem_gb(obj=None):\n",
    "    try:\n",
    "        import psutil\n",
    "        if obj is None:\n",
    "            return psutil.Process().memory_info().rss / (1024**3)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if hasattr(obj, \"memory_usage\"):\n",
    "            return float(obj.memory_usage(deep=True).sum())/(1024**3)\n",
    "        return float(np.array(obj).nbytes)/(1024**3)\n",
    "    except Exception:\n",
    "        return float('nan')\n",
    "\n",
    "def peek(df, n=5):\n",
    "    display(df.head(n))\n",
    "    print(df.shape, \"| mem:\", f\"{mem_gb(df):.3f} GB\")\n",
    "\n",
    "def parse_embargo(s: str) -> pd.Timedelta:\n",
    "    \"\"\"–°—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ '2D', '12h', '30m' ‚Üí Timedelta.\"\"\"\n",
    "    if s is None or str(s).strip()==\"\":\n",
    "        return pd.Timedelta(0)\n",
    "    s = str(s).strip().lower()\n",
    "    if s.endswith(\"d\"):\n",
    "        return pd.Timedelta(days=float(s[:-1]))\n",
    "    if s.endswith(\"h\"):\n",
    "        return pd.Timedelta(hours=float(s[:-1]))\n",
    "    if s.endswith(\"m\"):\n",
    "        return pd.Timedelta(minutes=float(s[:-1]))\n",
    "    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —á–∞—Å—ã\n",
    "    try:\n",
    "        return pd.Timedelta(hours=float(s))\n",
    "    except:\n",
    "        return pd.Timedelta(0)\n",
    "\n",
    "def to_utc(series):\n",
    "    \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ –≤ UTC pandas datetime64[ns, UTC].\"\"\"\n",
    "    s = pd.to_datetime(series, errors=\"coerce\", utc=True)\n",
    "    return s\n",
    "\n",
    "def ts_floor_hour(ts: pd.Timestamp) -> pd.Timestamp:\n",
    "    if ts.tz is None:\n",
    "        ts = ts.tz_localize(\"UTC\")\n",
    "    return ts.floor(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_LAYOUT = W.Layout(min_width=\"220px\", width=\"auto\", height=\"36px\", flex=\"0 0 auto\")\n",
    "ROW_LAYOUT = W.Layout(flex_flow=\"row wrap\", grid_gap=\"8px\")\n",
    "GRID_LAYOUT = W.Layout(grid_template_columns=\"repeat(3, minmax(220px, 1fr))\", grid_gap=\"8px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = dict(\n",
    "    DATASET_ID=\"s5e11\",\n",
    "    RAW_INTERACTIONS=\"data/s5e11/interactions.parquet\",\n",
    "    RAW_ITEMS=\"data/s5e11/items.parquet\",\n",
    "    SESSION_GAP_MIN=30,\n",
    "    MAX_SESSION_LEN=200,\n",
    "    VAL_FRAC=0.1,\n",
    "    TEST_FRAC=0.1,\n",
    "    EMBARGO=\"2D\",\n",
    ")\n",
    "\n",
    "# –í–∏–¥–∂–µ—Ç—ã\n",
    "w_dataset  = W.Text(STATE[\"DATASET_ID\"], description=\"dataset_id:\", layout=W.Layout(width=\"280px\"))\n",
    "w_inter    = W.Text(STATE[\"RAW_INTERACTIONS\"], description=\"interactions:\", layout=W.Layout(width=\"640px\"))\n",
    "w_items    = W.Text(STATE[\"RAW_ITEMS\"], description=\"items:\", layout=W.Layout(width=\"640px\"))\n",
    "\n",
    "w_gap      = W.IntText(STATE[\"SESSION_GAP_MIN\"], description=\"session_gap_min:\", layout=W.Layout(width=\"220px\"))\n",
    "w_maxlen   = W.IntText(STATE[\"MAX_SESSION_LEN\"], description=\"max_session_len:\", layout=W.Layout(width=\"220px\"))\n",
    "w_valfrac  = W.FloatText(STATE[\"VAL_FRAC\"], description=\"val_frac:\", layout=W.Layout(width=\"180px\"))\n",
    "w_testfrac = W.FloatText(STATE[\"TEST_FRAC\"], description=\"test_frac:\", layout=W.Layout(width=\"180px\"))\n",
    "w_embargo  = W.Text(STATE[\"EMBARGO\"], description=\"embargo:\", layout=W.Layout(width=\"180px\"))\n",
    "\n",
    "btn_apply  = W.Button(description=\"–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_apply  = W.Output()\n",
    "\n",
    "def on_apply(_):\n",
    "    with out_apply:\n",
    "        clear_output()\n",
    "        STATE[\"DATASET_ID\"]        = w_dataset.value.strip()\n",
    "        STATE[\"RAW_INTERACTIONS\"]  = w_inter.value.strip()\n",
    "        STATE[\"RAW_ITEMS\"]         = w_items.value.strip()\n",
    "        STATE[\"SESSION_GAP_MIN\"]   = int(w_gap.value)\n",
    "        STATE[\"MAX_SESSION_LEN\"]   = int(w_maxlen.value)\n",
    "        STATE[\"VAL_FRAC\"]          = float(w_valfrac.value)\n",
    "        STATE[\"TEST_FRAC\"]         = float(w_testfrac.value)\n",
    "        STATE[\"EMBARGO\"]           = w_embargo.value.strip()\n",
    "        print(json.dumps(STATE, ensure_ascii=False, indent=2))\n",
    "btn_apply.on_click(on_apply)\n",
    "\n",
    "W.VBox([\n",
    "    W.HTML(\"<h3>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã</h3>\"),\n",
    "    w_dataset,\n",
    "    w_inter, \n",
    "    w_items,\n",
    "    W.HBox([w_gap, w_maxlen, w_valfrac, w_testfrac, w_embargo], layout=ROW_LAYOUT),\n",
    "    btn_apply,\n",
    "    out_apply\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_load = W.Output()\n",
    "btn_load = W.Button(description=\"–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—ã—Ä—å—ë –∏ –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ä–µ–∑—ã\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "RAW = dict(inter=None, items=None)\n",
    "\n",
    "def load_raw():\n",
    "    p_int = Path(STATE[\"RAW_INTERACTIONS\"])\n",
    "    p_itm = Path(STATE[\"RAW_ITEMS\"])\n",
    "    if not p_int.exists():\n",
    "        raise FileNotFoundError(f\"–ù–µ –Ω–∞–π–¥–µ–Ω interactions: {p_int}\")\n",
    "    if not p_itm.exists():\n",
    "        raise FileNotFoundError(f\"–ù–µ –Ω–∞–π–¥–µ–Ω items: {p_itm}\")\n",
    "    inter = pd.read_parquet(p_int) if p_int.suffix==\".parquet\" else pd.read_csv(p_int)\n",
    "    items = pd.read_parquet(p_itm) if p_itm.suffix==\".parquet\" else pd.read_csv(p_itm)\n",
    "    return inter, items\n",
    "\n",
    "def on_load(_):\n",
    "    with out_load:\n",
    "        clear_output()\n",
    "        inter, items = load_raw()\n",
    "        RAW[\"inter\"] = inter\n",
    "        RAW[\"items\"] = items\n",
    "        print(\"interactions:\")\n",
    "        peek(inter)\n",
    "        print(\"items:\")\n",
    "        peek(items)\n",
    "        # –∫–ª—é—á–µ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n",
    "        need = {\"user_id\",\"item_id\",\"ts\"}\n",
    "        missing = need - set(inter.columns)\n",
    "        if missing:\n",
    "            raise AssertionError(f\"–í interactions –Ω–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {missing}\")\n",
    "        if inter.shape[0]==0 or items.shape[0]==0:\n",
    "            raise AssertionError(\"–û–¥–∏–Ω –∏–∑ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤ –ø—É—Å—Ç\")\n",
    "\n",
    "btn_load.on_click(on_load)\n",
    "W.VBox([btn_load, out_load])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_schema = W.Output()\n",
    "btn_schema = W.Button(description=\"–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Å—Ö–µ–º—É –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ —Ç–∏–ø—ã\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "NORM = dict(inter=None, items=None, notes=dict())\n",
    "\n",
    "def normalize_schema(inter: pd.DataFrame, items: pd.DataFrame):\n",
    "    inter = inter.copy()\n",
    "    items = items.copy()\n",
    "    notes = {}\n",
    "\n",
    "    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ\n",
    "    for col in [\"user_id\",\"item_id\"]:\n",
    "        if col not in inter.columns:\n",
    "            raise AssertionError(f\"[schema] –ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ {col} –≤ interactions\")\n",
    "    if \"ts\" not in inter.columns:\n",
    "        raise AssertionError(\"[schema] –ù–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ ts –≤ interactions\")\n",
    "\n",
    "    # –ö–∞—Å—Ç –∫–ª—é—á–µ–π\n",
    "    for col in [\"user_id\",\"item_id\"]:\n",
    "        if not pd.api.types.is_integer_dtype(inter[col]):\n",
    "            inter[col] = pd.to_numeric(inter[col], errors=\"coerce\").astype(\"Int64\").astype(\"int64\")\n",
    "        if not pd.api.types.is_integer_dtype(items[col]) and col in items.columns:\n",
    "            items[col] = pd.to_numeric(items[col], errors=\"coerce\").astype(\"Int64\").astype(\"int64\")\n",
    "\n",
    "    # –í—Ä–µ–º—è\n",
    "    inter[\"ts\"] = to_utc(inter[\"ts\"])\n",
    "    if inter[\"ts\"].isna().mean() > 0.01:\n",
    "        raise AssertionError(\"[schema] >1% –Ω–µ—Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö ts\")\n",
    "\n",
    "    # –ö–∞—Å—Ç —á–∞—Å—Ç—ã—Ö –ø–æ–ª–µ–π\n",
    "    opt_num = [\"price\"]\n",
    "    for c in opt_num:\n",
    "        if c in inter.columns:\n",
    "            inter[c] = pd.to_numeric(inter[c], errors=\"coerce\").astype(\"float32\")\n",
    "        if c in items.columns:\n",
    "            items[c] = pd.to_numeric(items[c], errors=\"coerce\").astype(\"float32\")\n",
    "    for c in [\"brand\",\"category\",\"event_type\",\"title\"]:\n",
    "        if c in inter.columns:\n",
    "            inter[c] = inter[c].astype(\"string\")\n",
    "        if c in items.columns:\n",
    "            items[c] = items[c].astype(\"string\")\n",
    "\n",
    "    if \"created_ts\" in items.columns:\n",
    "        items[\"created_ts\"] = to_utc(items[\"created_ts\"])\n",
    "\n",
    "    # –î–æ–ø. –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏\n",
    "    inter = inter.sort_values([\"user_id\",\"ts\"]).reset_index(drop=True)\n",
    "    inter[\"date\"] = inter[\"ts\"].dt.date\n",
    "    inter[\"hour\"] = inter[\"ts\"].dt.hour.astype(\"int16\")\n",
    "    inter[\"dow\"]  = inter[\"ts\"].dt.dayofweek.astype(\"int16\")\n",
    "\n",
    "    # –ü—Ä–æ–ø—É—Å–∫–∏ –≤ –∫–ª—é—á–∞—Ö\n",
    "    if inter[[\"user_id\",\"item_id\",\"ts\"]].isna().any().any():\n",
    "        raise AssertionError(\"[schema] –ü—Ä–æ–ø—É—Å–∫–∏ –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö\" )\n",
    "\n",
    "    notes[\"counts\"] = dict(n_events=int(inter.shape[0]), n_users=int(inter[\"user_id\"].nunique()), n_items=int(inter[\"item_id\"].nunique()))\n",
    "    notes[\"time_span\"] = dict(min=str(inter[\"ts\"].min()), max=str(inter[\"ts\"].max()))\n",
    "    return inter, items, notes\n",
    "\n",
    "def on_schema(_):\n",
    "    with out_schema:\n",
    "        clear_output()\n",
    "        if RAW[\"inter\"] is None:\n",
    "            print(\"–°–ø–µ—Ä–≤–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ (–∫–Ω–æ–ø–∫–∞ –≤—ã—à–µ).\")\n",
    "            return\n",
    "        inter, items, notes = normalize_schema(RAW[\"inter\"], RAW[\"items\"])\n",
    "        NORM[\"inter\"], NORM[\"items\"], NORM[\"notes\"] = inter, items, notes\n",
    "        print(\"‚úì –°—Ö–µ–º–∞ –æ–∫. –°—Ä–µ–∑—ã:\")\n",
    "        print(json.dumps(notes, ensure_ascii=False, indent=2))\n",
    "        peek(inter)\n",
    "        if \"created_ts\" in items.columns:\n",
    "            print(\"items[created_ts] –¥–∏–∞–ø–∞–∑–æ–Ω:\", items[\"created_ts\"].min(), \"‚Üí\", items[\"created_ts\"].max())\n",
    "        peek(items)\n",
    "\n",
    "btn_schema.on_click(on_schema)\n",
    "W.VBox([btn_schema, out_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee101fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dups = W.Output()\n",
    "btn_dups = W.Button(description=\"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ —É–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "QC = dict(dup_rate=None, nan_by_col=None)\n",
    "\n",
    "def drop_dups(inter: pd.DataFrame):\n",
    "    key_cols = [c for c in [\"user_id\",\"item_id\",\"ts\",\"event_type\"] if c in inter.columns]\n",
    "    before = inter.shape[0]\n",
    "    inter2 = inter.drop_duplicates(subset=key_cols, keep=\"first\")\n",
    "    after = inter2.shape[0]\n",
    "    dup_rate = (before - after) / max(1,before)\n",
    "    nans = inter2.isna().mean().sort_values(ascending=False).head(10).to_dict()\n",
    "    return inter2, dup_rate, nans\n",
    "\n",
    "def on_dups(_):\n",
    "    with out_dups:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã.\")\n",
    "            return\n",
    "        inter2, dup_rate, nans = drop_dups(NORM[\"inter\"])\n",
    "        NORM[\"inter\"] = inter2.reset_index(drop=True)\n",
    "        QC[\"dup_rate\"] = dup_rate\n",
    "        QC[\"nan_by_col\"] = nans\n",
    "        print(f\"dup_rate: {dup_rate:.4%}\")\n",
    "        print(\"NaN top-10:\", json.dumps(nans, ensure_ascii=False, indent=2))\n",
    "        peek(inter2)\n",
    "\n",
    "btn_dups.on_click(on_dups)\n",
    "W.VBox([btn_dups, out_dups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sess = W.Output()\n",
    "btn_sess = W.Button(description=\"–ü–æ—Å—Ç—Ä–æ–∏—Ç—å session_id\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "def build_sessions(inter: pd.DataFrame, gap_min=30, max_len=200):\n",
    "    inter = inter.sort_values([\"user_id\",\"ts\"]).reset_index(drop=True)\n",
    "    # —Ä–∞–∑—Ä—ã–≤—ã –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é\n",
    "    gid = (inter[\"user_id\"] != inter[\"user_id\"].shift(1)).astype(int)\n",
    "    dt = inter[\"ts\"].view(\"int64\").diff().fillna(10**18)  # –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã\n",
    "    gap_ns = int(gap_min*60*1e9)\n",
    "    cut = (dt > gap_ns).astype(int)\n",
    "    # –Ω–æ–≤–∞—è —Å–µ—Å—Å–∏—è –µ—Å–ª–∏: –Ω–æ–≤—ã–π user –∏–ª–∏ gap –∏–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –¥–ª–∏–Ω—ã\n",
    "    # –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏\n",
    "    sess_len = np.zeros(len(inter), dtype=np.int32)\n",
    "    sess_len[0] = 1\n",
    "    for i in range(1, len(inter)):\n",
    "        if gid[i]==1 or cut[i]==1 or sess_len[i-1] >= max_len:\n",
    "            sess_len[i] = 1\n",
    "        else:\n",
    "            sess_len[i] = sess_len[i-1] + 1\n",
    "    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º session_id –∫–∞–∫ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—É—é —Å—É–º–º—É ¬´—Å—Ç–∞—Ä—Ç–æ–≤¬ª\n",
    "    start = ((sess_len==1).astype(int)).cumsum()\n",
    "    # –ø—Ä–∏–∫–ª–µ–∏–º user, —á—Ç–æ–±—ã —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –±—ã–ª–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–π\n",
    "    inter[\"session_id\"] = (inter[\"user_id\"].astype(\"int64\")<<32) + start.astype(\"int64\")\n",
    "    stats = {\n",
    "        \"n_sessions\": int(inter[\"session_id\"].nunique()),\n",
    "        \"len_p50\": int(inter.groupby(\"session_id\").size().median()),\n",
    "        \"len_p90\": int(inter.groupby(\"session_id\").size().quantile(0.9))\n",
    "    }\n",
    "    return inter, stats\n",
    "\n",
    "def on_sess(_):\n",
    "    with out_sess:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã.\")\n",
    "            return\n",
    "        inter2, stats = build_sessions(NORM[\"inter\"], gap_min=STATE[\"SESSION_GAP_MIN\"], max_len=STATE[\"MAX_SESSION_LEN\"])\n",
    "        NORM[\"inter\"] = inter2\n",
    "        NORM[\"notes\"][\"sessions\"] = stats\n",
    "        print(\"‚úì sessions –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã:\", stats)\n",
    "        peek(inter2[[\"user_id\",\"ts\",\"session_id\"]])\n",
    "\n",
    "btn_sess.on_click(on_sess)\n",
    "W.VBox([btn_sess, out_sess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_split = W.Output()\n",
    "btn_split = W.Button(description=\"–ü–æ—Å—Ç—Ä–æ–∏—Ç—å time-splits + —ç–º–±–∞—Ä–≥–æ\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "SPLITS = dict(bounds=None, sizes=None, embargo=STATE[\"EMBARGO\"])\n",
    "\n",
    "def build_time_splits(inter: pd.DataFrame, val_frac=0.1, test_frac=0.1):\n",
    "    inter = inter.sort_values(\"ts\")\n",
    "    t_min, t_max = inter[\"ts\"].min(), inter[\"ts\"].max()\n",
    "    if not (0 < val_frac < 0.5 and 0 < test_frac < 0.5 and (val_frac+test_frac)<0.8):\n",
    "        raise AssertionError(\"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–æ–ª–∏ val/test\")\n",
    "    n = len(inter)\n",
    "    q_train_end = 1 - (val_frac + test_frac)\n",
    "    q_val_end   = 1 - test_frac\n",
    "    t_train_end = inter[\"ts\"].quantile(q_train_end)\n",
    "    t_val_end   = inter[\"ts\"].quantile(q_val_end)\n",
    "\n",
    "    # –æ–∫—Ä—É–≥–ª–∏–º –¥–æ —á–∞—Å–∞\n",
    "    t_train_end = ts_floor_hour(t_train_end)\n",
    "    t_val_end   = ts_floor_hour(t_val_end)\n",
    "\n",
    "    train = inter[inter[\"ts\"] <= t_train_end]\n",
    "    val   = inter[(inter[\"ts\"] > t_train_end) & (inter[\"ts\"] <= t_val_end)]\n",
    "    test  = inter[inter[\"ts\"] > t_val_end]\n",
    "\n",
    "    sizes = dict(train=int(train.shape[0]), val=int(val.shape[0]), test=int(test.shape[0]))\n",
    "    bounds = dict(t_min=str(t_min), train_end=str(t_train_end), val_end=str(t_val_end), t_max=str(t_max))\n",
    "    return bounds, sizes\n",
    "\n",
    "def check_embargo(inter: pd.DataFrame, bounds: dict, embargo_str: str):\n",
    "    emb = parse_embargo(embargo_str)\n",
    "    if emb == pd.Timedelta(0):\n",
    "        return dict(ok=True, msg=\"embargo=0\")\n",
    "    t_train_end = pd.to_datetime(bounds[\"train_end\"])\n",
    "    t_val_start = t_train_end + pd.Timedelta(0)\n",
    "    # –∑–∞–ø—Ä–µ—Ç–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –±–ª–∏–∂–µ —ç–º–±–∞—Ä–≥–æ –∫ –≥—Ä–∞–Ω–∏—Ü–µ\n",
    "    train_edge = inter[(inter[\"ts\"] > t_train_end - emb) & (inter[\"ts\"] <= t_train_end)]\n",
    "    val_edge   = inter[(inter[\"ts\"] > t_train_end) & (inter[\"ts\"] <= t_train_end + emb)]\n",
    "    ok = len(val_edge)==0  # —Å—Ç—Ä–æ–≥–∏–π –≤–∞—Ä–∏–∞–Ω—Ç: –≤–∞–ª –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –æ–∫–Ω–∞ —ç–º–±–∞—Ä–≥–æ\n",
    "    msg = f\"near-train-end: train_edge={len(train_edge)}, val_edge={len(val_edge)}, embargo={emb}\"\n",
    "    return dict(ok=ok, msg=msg)\n",
    "\n",
    "def on_split(_):\n",
    "    with out_split:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã.\")\n",
    "            return\n",
    "        bounds, sizes = build_time_splits(NORM[\"inter\"], STATE[\"VAL_FRAC\"], STATE[\"TEST_FRAC\"])\n",
    "        SPLITS[\"bounds\"], SPLITS[\"sizes\"], SPLITS[\"embargo\"] = bounds, sizes, STATE[\"EMBARGO\"]\n",
    "        print(\"bounds:\", json.dumps(bounds, indent=2))\n",
    "        print(\"sizes:\", json.dumps(sizes, indent=2))\n",
    "        embargo_check = check_embargo(NORM[\"inter\"], bounds, STATE[\"EMBARGO\"])\n",
    "        print(\"embargo_check:\", embargo_check)\n",
    "        if sizes[\"val\"]==0 or sizes[\"test\"]==0:\n",
    "            raise AssertionError(\"–û–¥–∏–Ω –∏–∑ —Å–ø–ª–∏—Ç–æ–≤ –ø—É—Å—Ç (val/test)\")\n",
    "        if not embargo_check[\"ok\"]:\n",
    "            print(\"‚ö†Ô∏è embargo –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ:\", embargo_check[\"msg\"])\n",
    "\n",
    "btn_split.on_click(on_split)\n",
    "W.VBox([btn_split, out_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cs = W.Output()\n",
    "btn_cs = W.Button(description=\"–ü–æ—Å—á–∏—Ç–∞—Ç—å —Ö–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç/coverage\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "COVER = dict(cold_items=None, cold_users=None, overlap=None)\n",
    "\n",
    "def cold_start_stats(inter: pd.DataFrame, bounds: dict):\n",
    "    t_train_end = pd.to_datetime(bounds[\"train_end\"])\n",
    "    t_val_end   = pd.to_datetime(bounds[\"val_end\"])\n",
    "    tr = inter[inter[\"ts\"] <= t_train_end]\n",
    "    va = inter[(inter[\"ts\"] > t_train_end) & (inter[\"ts\"] <= t_val_end)]\n",
    "    te = inter[inter[\"ts\"] > t_val_end]\n",
    "\n",
    "    tr_items = set(tr[\"item_id\"].unique()); va_items = set(va[\"item_id\"].unique()); te_items = set(te[\"item_id\"].unique())\n",
    "    tr_users = set(tr[\"user_id\"].unique()); va_users = set(va[\"user_id\"].unique()); te_users = set(te[\"user_id\"].unique())\n",
    "\n",
    "    cold_items_val = len(va_items - tr_items) / max(1,len(va_items))\n",
    "    cold_items_test= len(te_items - tr_items) / max(1,len(te_items))\n",
    "    cold_users_val = len(va_users - tr_users) / max(1,len(va_users))\n",
    "    cold_users_test= len(te_users - tr_users) / max(1,len(te_users))\n",
    "\n",
    "    overlap = dict(\n",
    "        item_val_vs_train = len(va_items & tr_items) / max(1,len(va_items)),\n",
    "        item_test_vs_train= len(te_items & tr_items) / max(1,len(te_items)),\n",
    "    )\n",
    "    return dict(\n",
    "        cold_items=dict(val=cold_items_val, test=cold_items_test),\n",
    "        cold_users=dict(val=cold_users_val, test=cold_users_test),\n",
    "        overlap=overlap\n",
    "    )\n",
    "\n",
    "def on_cs(_):\n",
    "    with out_cs:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None or SPLITS[\"bounds\"] is None:\n",
    "            print(\"–ù—É–∂–Ω—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–ø–ª–∏—Ç—ã.\")\n",
    "            return\n",
    "        stats = cold_start_stats(NORM[\"inter\"], SPLITS[\"bounds\"])\n",
    "        COVER.update(stats)\n",
    "        print(json.dumps(stats, indent=2))\n",
    "\n",
    "btn_cs.on_click(on_cs)\n",
    "W.VBox([btn_cs, out_cs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_lbl = W.Output()\n",
    "btn_lbl = W.Button(description=\"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–µ–π–±–ª—ã / –±–∞–ª–∞–Ω—Å\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "\n",
    "LABELS = dict(pos_rate=None, drift=None)\n",
    "\n",
    "def labels_stats(inter: pd.DataFrame):\n",
    "    if \"label\" not in inter.columns:\n",
    "        return dict(has_label=False)\n",
    "    inter = inter.copy()\n",
    "    inter[\"label\"] = pd.to_numeric(inter[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    pos_rate = float(inter[\"label\"].mean())\n",
    "    drift = inter.set_index(\"ts\")[\"label\"].resample(\"D\").mean().dropna().tail(30).to_dict()\n",
    "    return dict(has_label=True, pos_rate=pos_rate, drift_last30=drift)\n",
    "\n",
    "def on_lbl(_):\n",
    "    with out_lbl:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã.\")\n",
    "            return\n",
    "        stats = labels_stats(NORM[\"inter\"])\n",
    "        LABELS.update(stats)\n",
    "        print(json.dumps(stats, indent=2))\n",
    "\n",
    "btn_lbl.on_click(on_lbl)\n",
    "W.VBox([btn_lbl, out_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_leak = W.Output()\n",
    "btn_leak = W.Button(description=\"–ê–Ω—Ç–∏-—É—Ç–µ—á–∫–∏: –±—ã—Å—Ç—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "\n",
    "LEAK = dict(items_future=False, msg_items=\"\", ok=True)\n",
    "\n",
    "def check_item_created_vs_events(inter: pd.DataFrame, items: pd.DataFrame):\n",
    "    if \"created_ts\" not in items.columns:\n",
    "        return dict(ok=True, msg=\"no created_ts in items\")\n",
    "    # join –ø–æ item_id (–ø—Ä–∏–º–µ—Ä: —Å–ª—É—á–∞–π–Ω–∞—è 100k –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)\n",
    "    sample = inter.sample(min(len(inter), 100_000), random_state=1)\n",
    "    df = sample[[\"item_id\",\"ts\"]].merge(items[[\"item_id\",\"created_ts\"]], on=\"item_id\", how=\"left\")\n",
    "    bad = df[df[\"created_ts\"].notna() & (df[\"created_ts\"] > df[\"ts\"])].shape[0]\n",
    "    return dict(ok=(bad==0), msg=f\"items created_ts > ts events: {bad} / {len(df)} (sample)\")\n",
    "\n",
    "def check_embargo_strict(inter: pd.DataFrame, bounds: dict, embargo_str: str):\n",
    "    emb = parse_embargo(embargo_str)\n",
    "    if emb == pd.Timedelta(0):\n",
    "        return dict(ok=True, msg=\"embargo=0\")\n",
    "    t_train_end = pd.to_datetime(bounds[\"train_end\"])\n",
    "    val_st = t_train_end + pd.Timedelta(0)\n",
    "    # —Å—Ç—Ä–æ–≥–∏–π –≤–∞—Ä–∏–∞–Ω—Ç: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π ts –≤ val –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å >= train_end + emb\n",
    "    min_val = inter[inter[\"ts\"] > t_train_end][\"ts\"].min()\n",
    "    ok = pd.isna(min_val) or (min_val >= t_train_end + emb)\n",
    "    return dict(ok=ok, msg=f\"min_val={min_val}, needs ‚â• {t_train_end+emb}\")\n",
    "\n",
    "def on_leak(_):\n",
    "    with out_leak:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã.\")\n",
    "            return\n",
    "        res1 = check_item_created_vs_events(NORM[\"inter\"], NORM[\"items\"])\n",
    "        print(\"items future check:\", res1)\n",
    "        res2 = dict(ok=True, msg=\"skip (–Ω–µ—Ç —Å–ø–ª–∏—Ç–æ–≤)\")\n",
    "        if SPLITS[\"bounds\"] is not None:\n",
    "            res2 = check_embargo_strict(NORM[\"inter\"], SPLITS[\"bounds\"], STATE[\"EMBARGO\"])\n",
    "            print(\"embargo strict check:\", res2)\n",
    "        ok = res1[\"ok\"] and res2[\"ok\"]\n",
    "        LEAK[\"ok\"] = ok\n",
    "        LEAK[\"items_future\"] = not res1[\"ok\"]\n",
    "        LEAK[\"msg_items\"] = res1[\"msg\"]\n",
    "        print(\"‚Üí LEAK OK:\", ok)\n",
    "\n",
    "btn_leak.on_click(on_leak)\n",
    "W.VBox([btn_leak, out_leak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864780ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_save = W.Output()\n",
    "btn_save = W.Button(description=\"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å parquet + splits + report\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "\n",
    "REPORT = dict()\n",
    "\n",
    "def save_artifacts(inter: pd.DataFrame, items: pd.DataFrame, dataset_id: str, splits: dict, qc: dict, cover: dict, labels: dict, leak: dict):\n",
    "    out_dir = ART_ROOT / dataset_id\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # interactions_norm\n",
    "    inter2 = inter.copy()\n",
    "    # —É–ø–æ—Ä—è–¥–æ—á–∏–º —Å—Ç–æ–ª–±—Ü—ã\n",
    "    base_cols = [c for c in [\"user_id\",\"item_id\",\"ts\",\"session_id\",\"event_type\",\"price\",\"brand\",\"category\",\"label\"] if c in inter2.columns]\n",
    "    other_cols= [c for c in inter2.columns if c not in base_cols]\n",
    "    inter2 = inter2[base_cols + other_cols]\n",
    "    inter2.to_parquet(out_dir/\"interactions_norm.parquet\", index=False)\n",
    "    # items_norm\n",
    "    items2 = items.copy()\n",
    "    items2.to_parquet(out_dir/\"items_norm.parquet\", index=False)\n",
    "    # interactions_with_split ‚Äî –ø–æ –∂–µ–ª–∞–Ω–∏—é (–∑–¥–µ—Å—å –Ω–µ –ø–∏—à–µ–º, —Å–ø–ª–∏—Ç—ã –≤ json)\n",
    "    # splits.json\n",
    "    splits_out = dict(bounds=splits.get(\"bounds\"), sizes=splits.get(\"sizes\"), embargo=splits.get(\"embargo\"))\n",
    "    (out_dir/\"splits.json\").write_text(json.dumps(splits_out, ensure_ascii=False, indent=2))\n",
    "\n",
    "    # report.json\n",
    "    rep = dict(\n",
    "        counts=NORM[\"notes\"].get(\"counts\",{}),\n",
    "        time_span=NORM[\"notes\"].get(\"time_span\",{}),\n",
    "        sessions=NORM[\"notes\"].get(\"sessions\",{}),\n",
    "        dup_rate=qc.get(\"dup_rate\"),\n",
    "        nan_by_col=qc.get(\"nan_by_col\"),\n",
    "        splits=splits_out,\n",
    "        cold_start=cover,\n",
    "        labels=labels,\n",
    "        leak_checks=leak,\n",
    "        saved_at=datetime.utcnow().isoformat()+\"Z\"\n",
    "    )\n",
    "    (out_dir/\"report.json\").write_text(json.dumps(rep, ensure_ascii=False, indent=2))\n",
    "    return out_dir, rep\n",
    "\n",
    "def on_save(_):\n",
    "    with out_save:\n",
    "        clear_output()\n",
    "        if NORM[\"inter\"] is None or SPLITS[\"bounds\"] is None:\n",
    "            print(\"–ù—É–∂–Ω—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–ø–ª–∏—Ç—ã.\")\n",
    "            return\n",
    "        out_dir, rep = save_artifacts(NORM[\"inter\"], NORM[\"items\"], STATE[\"DATASET_ID\"], SPLITS, QC, COVER, LABELS, LEAK)\n",
    "        REPORT.update(rep)\n",
    "        print(\"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤:\", out_dir)\n",
    "        print(json.dumps(rep, ensure_ascii=False, indent=2))\n",
    "\n",
    "btn_save.on_click(on_save)\n",
    "W.VBox([btn_save, out_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6881c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gate = W.Output()\n",
    "btn_gate = W.Button(description=\"–ü–æ–∫–∞–∑–∞—Ç—å PASS/FAIL –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "\n",
    "def pass_fail():\n",
    "    fails = []\n",
    "    warns = []\n",
    "    # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ\n",
    "    if QC.get(\"dup_rate\", 0) > 0.01:\n",
    "        warns.append(f\"–í—ã—Å–æ–∫–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã: {QC['dup_rate']:.2%} (–Ω–æ—Ä–º <0.5%)\")\n",
    "    if NORM[\"inter\"][[\"user_id\",\"item_id\",\"ts\"]].isna().any().any():\n",
    "        fails.append(\"NaN –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö\")\n",
    "    if SPLITS.get(\"sizes\",{}).get(\"val\",0)==0 or SPLITS.get(\"sizes\",{}).get(\"test\",0)==0:\n",
    "        fails.append(\"–ü—É—Å—Ç–æ–π val/test\")\n",
    "    if not LEAK.get(\"ok\", True):\n",
    "        fails.append(\"–°—Ä–∞–±–æ—Ç–∞–ª–∏ –∞–Ω—Ç–∏-—É—Ç–µ—á–∫–∏\")\n",
    "    # –•–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç\n",
    "    cs = COVER.get(\"cold_items\",{})\n",
    "    if cs:\n",
    "        if cs.get(\"test\",0) > 0.3:\n",
    "            warns.append(f\"–°–∏–ª—å–Ω—ã–π —Ö–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç –ø–æ item –≤ test: {cs['test']:.1%} ‚Üí —É—Å–∏–ª–∏–≤–∞–π retrieval (–∫–æ–Ω—Ç–µ–Ω—Ç/—Å–∏–º–∏–ª—è—Ä–∏—Ç–∏)\")\n",
    "    return fails, warns\n",
    "\n",
    "def on_gate(_):\n",
    "    with out_gate:\n",
    "        clear_output()\n",
    "        if not REPORT:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (–±—É–¥–µ—Ç report.json).\")\n",
    "            return\n",
    "        fails, warns = pass_fail()\n",
    "        html = \"<h3>–ò—Ç–æ–≥</h3>\"\n",
    "        if fails:\n",
    "            html += f\"<p style='color:#c62828'><b>FAILS:</b><br>‚Ä¢ \" + \"<br>‚Ä¢ \".join(fails) + \"</p>\"\n",
    "        else:\n",
    "            html += \"<p style='color:#2e7d32'><b>PASS:</b> –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ</p>\"\n",
    "        if warns:\n",
    "            html += f\"<p style='color:#f57c00'><b>WARNS:</b><br>‚Ä¢ \" + \"<br>‚Ä¢ \".join(warns) + \"</p>\"\n",
    "        html += \"<hr><p>–î–∞–ª—å—à–µ: –æ—Ç–∫—Ä–æ–π 02_candidates_lab.ipynb (–∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏ retrieval –∏–∑ runbook).</p>\"\n",
    "        display(HTML(html))\n",
    "\n",
    "btn_gate.on_click(on_gate)\n",
    "W.VBox([btn_gate, out_gate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73684b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_all = W.Button(description=\"üöÄ –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–æ–Ω: load ‚Üí schema ‚Üí dups ‚Üí sessions ‚Üí splits ‚Üí labels ‚Üí CS ‚Üí save ‚Üí gate\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_all = W.Output()\n",
    "\n",
    "def on_all(_):\n",
    "    with out_all:\n",
    "        clear_output()\n",
    "        try:\n",
    "            print(\"1) load\")\n",
    "            inter, items = load_raw()\n",
    "            RAW[\"inter\"], RAW[\"items\"] = inter, items\n",
    "\n",
    "            print(\"2) schema\")\n",
    "            inter, items, notes = normalize_schema(inter, items)\n",
    "            NORM[\"inter\"], NORM[\"items\"], NORM[\"notes\"] = inter, items, notes\n",
    "\n",
    "            print(\"3) dups\")\n",
    "            inter2, dup_rate, nans = drop_dups(inter)\n",
    "            NORM[\"inter\"] = inter2\n",
    "            QC[\"dup_rate\"], QC[\"nan_by_col\"] = dup_rate, nans\n",
    "\n",
    "            print(\"4) sessions\")\n",
    "            inter3, stats = build_sessions(NORM[\"inter\"], STATE[\"SESSION_GAP_MIN\"], STATE[\"MAX_SESSION_LEN\"])\n",
    "            NORM[\"inter\"] = inter3\n",
    "            NORM[\"notes\"][\"sessions\"] = stats\n",
    "\n",
    "            print(\"5) splits\")\n",
    "            bounds, sizes = build_time_splits(NORM[\"inter\"], STATE[\"VAL_FRAC\"], STATE[\"TEST_FRAC\"])\n",
    "            SPLITS[\"bounds\"], SPLITS[\"sizes\"], SPLITS[\"embargo\"] = bounds, sizes, STATE[\"EMBARGO\"]\n",
    "\n",
    "            print(\"6) labels\")\n",
    "            LABELS.update(labels_stats(NORM[\"inter\"]))\n",
    "\n",
    "            print(\"7) cold start\")\n",
    "            COVER.update(cold_start_stats(NORM[\"inter\"], SPLITS[\"bounds\"]))\n",
    "\n",
    "            print(\"8) leaks\")\n",
    "            res1 = check_item_created_vs_events(NORM[\"inter\"], NORM[\"items\"])\n",
    "            res2 = check_embargo_strict(NORM[\"inter\"], SPLITS[\"bounds\"], STATE[\"EMBARGO\"])\n",
    "            LEAK[\"ok\"] = res1[\"ok\"] and res2[\"ok\"]\n",
    "            LEAK[\"items_future\"] = not res1[\"ok\"]\n",
    "            LEAK[\"msg_items\"] = res1[\"msg\"]\n",
    "\n",
    "            print(\"9) save\")\n",
    "            out_dir, rep = save_artifacts(NORM[\"inter\"], NORM[\"items\"], STATE[\"DATASET_ID\"], SPLITS, QC, COVER, LABELS, LEAK)\n",
    "            REPORT.update(rep)\n",
    "            print(\"‚úì done ‚Üí\", out_dir)\n",
    "        except Exception as e:\n",
    "            print(\"–û–®–ò–ë–ö–ê:\", e)\n",
    "            raise\n",
    "\n",
    "btn_all.on_click(on_all)\n",
    "W.VBox([btn_all, out_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = W.Output()\n",
    "btn_list = W.Button(description=\"–ü–æ–∫–∞–∑–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "\n",
    "def on_list(_):\n",
    "    with out_list:\n",
    "        clear_output()\n",
    "        d = ART_ROOT / STATE[\"DATASET_ID\"]\n",
    "        if not d.exists():\n",
    "            print(\"–ö–∞—Ç–∞–ª–æ–≥ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω:\", d)\n",
    "            return\n",
    "        files = sorted(d.rglob(\"*\"))\n",
    "        df = pd.DataFrame([{ \"path\":str(p), \"size_MB\": round(p.stat().st_size/1024/1024,3)} for p in files if p.is_file()])\n",
    "        display(df)\n",
    "btn_list.on_click(on_list)\n",
    "W.VBox([btn_list, out_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
