{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167977c2",
   "metadata": {},
   "source": [
    "# 02 ¬∑ Candidates Lab ‚Äî —Å–±–æ—Ä –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É–ª–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ üéØ\n",
    "\n",
    "–¶–µ–ª—å: –±—ã—Å—Ç—Ä–æ –ø–æ–ª—É—á–∏—Ç—å –≤—ã—Å–æ–∫–∏–π **Recall@K** –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø—É–ª –¥–ª—è —Ä–∞–Ω–∫–µ—Ä–∞.\n",
    "\n",
    "–ß—Ç–æ –∑–¥–µ—Å—å:\n",
    "- –≤–∫–ª—é—á–µ–Ω–∏–µ/–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (covis, seq-ngrams, pop/recency, item2vec/ALS, –∫–æ–Ω—Ç–µ–Ω—Ç, –≥—Ä–∞—Ñ);\n",
    "- –±—ã—Å—Ç—Ä—ã–π –±–µ–π–∑–ª–∞–π–Ω –∏ PANIC;\n",
    "- Recall@K / NDCG@K, —Å—Ä–µ–∑—ã, ¬´–¥—ã—Ä—è–≤—ã–µ¬ª –∑–∞–ø—Ä–æ—Å—ã;\n",
    "- –∫–≤–æ—Ç—ã/–≤–µ—Å–∞/–¥–µ–¥—É–ø;\n",
    "- —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ `candidates.parquet` + `candidates_report.json`.\n",
    "\n",
    "–í—Å–µ –¥–µ–π—Å—Ç–≤–∏—è time-safe, –±–µ–∑ —É—Ç–µ—á–µ–∫ –ø–æ –≤—Ä–µ–º–µ–Ω–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e45301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* ipywidgets v8 (JupyterLab 4) */\n",
    ".jp-OutputArea .widget-button .widget-label { \n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "/* fallback –¥–ª—è ipywidgets v7 */\n",
    ".jupyter-widgets.widget-button .widget-label {\n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579222e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time, math, glob, shlex, subprocess, warnings, pathlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as W\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_colwidth\", 140)\n",
    "\n",
    "REPO = Path.cwd()\n",
    "sys.path.insert(0, str(REPO))\n",
    "\n",
    "def run_cmd(cmd_list, check=True, env=None):\n",
    "    print(\"‚ñ∂\", \" \".join(shlex.quote(x) for x in cmd_list))\n",
    "    p = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)\n",
    "    try:\n",
    "        for line in iter(p.stdout.readline, ''):\n",
    "            print(line, end='')\n",
    "        p.stdout.close()\n",
    "        ret = p.wait()\n",
    "    except KeyboardInterrupt:\n",
    "        p.terminate(); ret = p.wait(); print(\"\n",
    "[aborted]\")\n",
    "    if check and ret != 0:\n",
    "        raise RuntimeError(f\"Command failed ({ret}): {' '.join(cmd_list)}\")\n",
    "    return ret\n",
    "\n",
    "def run_tool(script_rel, **kwargs):\n",
    "    args = []\n",
    "    for k,v in kwargs.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if isinstance(v, bool):\n",
    "            v = \"1\" if v else \"0\"\n",
    "        args += [f\"--{k}\", str(v)]\n",
    "    return run_cmd([\"python\", script_rel] + args)\n",
    "\n",
    "def now_tag():\n",
    "    return datetime.now().strftime(\"%m%d_%H%M\")\n",
    "\n",
    "def profile_name(path):\n",
    "    return Path(path).stem\n",
    "\n",
    "def art_paths(dataset_id, profile_path):\n",
    "    prof = profile_name(profile_path)\n",
    "    root = Path(\"artifacts\")\n",
    "    return dict(\n",
    "        dataio_dir = root / \"recsys\" / \"dataio\" / dataset_id,\n",
    "        profile_dir = root / \"recsys\" / \"dataio\" / dataset_id / prof,\n",
    "        cand_dir = root / \"recsys\" / \"candidates\" / dataset_id / prof,\n",
    "    )\n",
    "\n",
    "def exists(p):\n",
    "    try: return Path(p).exists()\n",
    "    except: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_LAYOUT = W.Layout(min_width=\"220px\", width=\"auto\", height=\"36px\", flex=\"0 0 auto\")\n",
    "ROW_LAYOUT = W.Layout(flex_flow=\"row wrap\", grid_gap=\"8px\")\n",
    "GRID_LAYOUT = W.Layout(grid_template_columns=\"repeat(3, minmax(220px, 1fr))\", grid_gap=\"8px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d26f0",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 3 ‚Äî –ü–∞–Ω–µ–ª—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = dict(\n",
    "    DATASET_ID = \"s5e11\",\n",
    "    PROFILE_PATH = \"configs/recsys/profiles/gate.yaml\",\n",
    "    SEED = 42,\n",
    "    JOBS = -1,\n",
    "    K_TARGET = 300,\n",
    "    FAST = True,\n",
    "    PANIC = False,\n",
    ")\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã (–≤–∫–ª—é—á–µ–Ω–∏–µ/–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ)\n",
    "GEN = dict(\n",
    "    covis=True,\n",
    "    session_ngrams=True,\n",
    "    pop=True,\n",
    "    recency=True,\n",
    "    item2vec=False,\n",
    "    als=False,\n",
    "    content_tfidf=False,\n",
    "    graph_ppr=False,\n",
    "    brand_fallback=True,\n",
    "    category_fallback=True,\n",
    ")\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤\n",
    "PARAMS = dict(\n",
    "    windows_days = \"3,7,30\",   # covis/seq –æ–∫–Ω–∞ (—Å—Ç—Ä–æ–∫–∞: \"3,7,30\")\n",
    "    decay_alpha = 0.9,         # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –¥–µ–∫–µ–π (0‚Ä¶1)\n",
    "    last_k = 5,                # seq-ngrams: —É—á–∏—Ç—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ K\n",
    ")\n",
    "\n",
    "# –í–∏–¥–∂–µ—Ç—ã\n",
    "w_dataset = W.Text(STATE[\"DATASET_ID\"], description=\"dataset_id:\", layout=W.Layout(width=\"280px\"))\n",
    "w_profile = W.Text(STATE[\"PROFILE_PATH\"], description=\"profile:\", layout=W.Layout(width=\"520px\"))\n",
    "w_seed    = W.IntText(STATE[\"SEED\"], description=\"seed:\", layout=W.Layout(width=\"140px\"))\n",
    "w_jobs    = W.IntText(STATE[\"JOBS\"], description=\"jobs:\", layout=W.Layout(width=\"140px\"))\n",
    "w_k       = W.IntText(STATE[\"K_TARGET\"], description=\"K target:\", layout=W.Layout(width=\"180px\"))\n",
    "w_fast    = W.Checkbox(STATE[\"FAST\"], description=\"FAST\")\n",
    "w_panic   = W.Checkbox(STATE[\"PANIC\"], description=\"PANIC\")\n",
    "\n",
    "toggles = [\n",
    "    W.Checkbox(GEN[\"covis\"], description=\"covis\"),\n",
    "    W.Checkbox(GEN[\"session_ngrams\"], description=\"session_ngrams\"),\n",
    "    W.Checkbox(GEN[\"pop\"], description=\"pop\"),\n",
    "    W.Checkbox(GEN[\"recency\"], description=\"recency\"),\n",
    "    W.Checkbox(GEN[\"item2vec\"], description=\"item2vec\"),\n",
    "    W.Checkbox(GEN[\"als\"], description=\"ALS/BPR\"),\n",
    "    W.Checkbox(GEN[\"content_tfidf\"], description=\"content\"),\n",
    "    W.Checkbox(GEN[\"graph_ppr\"], description=\"graph_PPR\"),\n",
    "    W.Checkbox(GEN[\"brand_fallback\"], description=\"brand_fallback\"),\n",
    "    W.Checkbox(GEN[\"category_fallback\"], description=\"category_fallback\"),\n",
    "]\n",
    "\n",
    "w_windows = W.Text(PARAMS[\"windows_days\"], description=\"windows_days:\", layout=W.Layout(width=\"260px\"))\n",
    "w_decay   = W.FloatText(PARAMS[\"decay_alpha\"], description=\"decay_alpha:\", layout=W.Layout(width=\"240px\"))\n",
    "w_lastk   = W.IntText(PARAMS[\"last_k\"], description=\"last_k:\", layout=W.Layout(width=\"200px\"))\n",
    "\n",
    "btn_apply = W.Button(description=\"–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_apply = W.Output()\n",
    "\n",
    "def on_apply(_):\n",
    "    with out_apply:\n",
    "        clear_output()\n",
    "        STATE[\"DATASET_ID\"]  = w_dataset.value.strip()\n",
    "        STATE[\"PROFILE_PATH\"] = w_profile.value.strip()\n",
    "        STATE[\"SEED\"]        = int(w_seed.value)\n",
    "        STATE[\"JOBS\"]        = int(w_jobs.value)\n",
    "        STATE[\"K_TARGET\"]    = int(w_k.value)\n",
    "        STATE[\"FAST\"]        = bool(w_fast.value)\n",
    "        STATE[\"PANIC\"]       = bool(w_panic.value)\n",
    "        # toggles\n",
    "        keys = [\"covis\",\"session_ngrams\",\"pop\",\"recency\",\"item2vec\",\"als\",\"content_tfidf\",\"graph_ppr\",\"brand_fallback\",\"category_fallback\"]\n",
    "        for k, w in zip(keys, toggles):\n",
    "            GEN[k] = bool(w.value)\n",
    "        PARAMS[\"windows_days\"] = w_windows.value.strip()\n",
    "        PARAMS[\"decay_alpha\"]  = float(w_decay.value)\n",
    "        PARAMS[\"last_k\"]       = int(w_lastk.value)\n",
    "        print(\"STATE:\")\n",
    "        print(json.dumps(STATE, ensure_ascii=False, indent=2))\n",
    "        print(\"GEN:\")\n",
    "        print(json.dumps(GEN, ensure_ascii=False, indent=2))\n",
    "        print(\"PARAMS:\")\n",
    "        print(json.dumps(PARAMS, ensure_ascii=False, indent=2))\n",
    "\n",
    "btn_apply.on_click(on_apply)\n",
    "\n",
    "W.VBox([\n",
    "    W.HTML(\"<h3>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\"),\n",
    "    W.HBox([w_dataset, w_seed, w_jobs, w_k, w_fast, w_panic], layout=ROW_LAYOUT),\n",
    "    w_profile,\n",
    "    W.HTML(\"<b>–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤</b>\"),\n",
    "    W.HBox(toggles[:5], layout=ROW_LAYOUT),\n",
    "    W.HBox(toggles[5:], layout=ROW_LAYOUT),\n",
    "    W.HTML(\"<b>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤</b>\"),\n",
    "    W.HBox([w_windows, w_decay, w_lastk], layout=ROW_LAYOUT),\n",
    "    btn_apply,\n",
    "    out_apply\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5feb52",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 4 ‚Äî –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑–º–µ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_check = W.Button(description=\"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "out_check = W.Output()\n",
    "\n",
    "def on_check(_):\n",
    "    with out_check:\n",
    "        clear_output()\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        need = [\n",
    "            A[\"dataio_dir\"]/\"interactions_norm.parquet\",\n",
    "            A[\"dataio_dir\"]/\"items_norm.parquet\",\n",
    "            A[\"dataio_dir\"]/\"splits.json\",\n",
    "            A[\"profile_dir\"]/\"pairs_val.parquet\",      # –≤–∞–ª –ø–∞—Ä—ã (label=1/0)\n",
    "            A[\"profile_dir\"]/\"queries_val.parquet\",    # –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n",
    "        ]\n",
    "        ok = True\n",
    "        for p in need:\n",
    "            print((\"OK  \" if exists(p) else \"MISS\"), p)\n",
    "            ok &= exists(p)\n",
    "        if not ok:\n",
    "            print(\"\n",
    "‚ö†Ô∏è –ß–∞—Å—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –ó–∞–≤–µ—Ä—à–∏ 01_data_sanity –∏–ª–∏ run_splits.\")\n",
    "            return\n",
    "        # —Ä–∞–∑–º–µ—Ä—ã\n",
    "        inter = pd.read_parquet(need[0])\n",
    "        qv = pd.read_parquet(need[4])\n",
    "        print(\"\n",
    "interactions:\", inter.shape, \"| unique users:\", inter.user_id.nunique(), \"| items:\", inter.item_id.nunique())\n",
    "        print(\"queries_val:\", qv.shape[0])\n",
    "\n",
    "btn_check.on_click(on_check)\n",
    "W.VBox([btn_check, out_check])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f59f73",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 5 ‚Äî –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ overrides –∏ –≤—ã–∑–æ–≤ run_candidates.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3757b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_build = W.Button(description=\"–°–æ–±—Ä–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–ø–æ —Ç–µ–∫—É—â–∏–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º)\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_build = W.Output()\n",
    "\n",
    "def build_overrides_json(path_json:str):\n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º ¬´–ø–ª–æ—Å–∫–∏–π¬ª overrides –¥–ª—è tools/run_candidates.py (–µ—Å–ª–∏ –æ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç --overrides)\n",
    "    # –ï—Å–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç ‚Äî —Ç–∞–∫–∏–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –ø—Ä–æ—Ñ–∏–ª–µ/–∫–æ–Ω—Ñ–∏–≥–∞—Ö.\n",
    "    srcs = []\n",
    "    if GEN[\"covis\"]:\n",
    "        srcs.append(dict(name=\"covis\", windows_days=PARAMS[\"windows_days\"], decay_alpha=PARAMS[\"decay_alpha\"]))\n",
    "    if GEN[\"session_ngrams\"]:\n",
    "        srcs.append(dict(name=\"session_ngrams\", last_k=PARAMS[\"last_k\"], windows_days=PARAMS[\"windows_days\"]))\n",
    "    if GEN[\"pop\"]:\n",
    "        srcs.append(dict(name=\"pop\"))\n",
    "    if GEN[\"recency\"]:\n",
    "        srcs.append(dict(name=\"recency\"))\n",
    "    if GEN[\"item2vec\"]:\n",
    "        srcs.append(dict(name=\"item2vec\", train=STATE[\"FAST\"]==False))\n",
    "    if GEN[\"als\"]:\n",
    "        srcs.append(dict(name=\"als\", train=STATE[\"FAST\"]==False))\n",
    "    if GEN[\"content_tfidf\"]:\n",
    "        srcs.append(dict(name=\"content_tfidf\"))\n",
    "    if GEN[\"graph_ppr\"]:\n",
    "        srcs.append(dict(name=\"graph_ppr\"))\n",
    "    if GEN[\"brand_fallback\"]:\n",
    "        srcs.append(dict(name=\"brand_fallback\"))\n",
    "    if GEN[\"category_fallback\"]:\n",
    "        srcs.append(dict(name=\"category_fallback\"))\n",
    "\n",
    "    overrides = dict(\n",
    "        seed=STATE[\"SEED\"],\n",
    "        jobs=STATE[\"JOBS\"],\n",
    "        K=STATE[\"K_TARGET\"],\n",
    "        fast=STATE[\"FAST\"],\n",
    "        panic=STATE[\"PANIC\"],\n",
    "        sources=srcs\n",
    "    )\n",
    "    Path(path_json).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(path_json).write_text(json.dumps(overrides, ensure_ascii=False, indent=2))\n",
    "    return overrides\n",
    "\n",
    "def on_build(_):\n",
    "    with out_build:\n",
    "        clear_output()\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        overrides_path = f\"artifacts/tmp/{STATE['DATASET_ID']}_{profile_name(STATE['PROFILE_PATH'])}_cands_overrides.json\"\n",
    "        ov = build_overrides_json(overrides_path)\n",
    "        print(\"Overrides ‚Üí\", overrides_path)\n",
    "        t0 = time.time()\n",
    "        # –í—ã–∑–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
    "        run_tool(\"recsys/tools/run_candidates.py\",\n",
    "                 dataset_id=STATE[\"DATASET_ID\"],\n",
    "                 profile=STATE[\"PROFILE_PATH\"],\n",
    "                 overrides=overrides_path,      # –µ—Å–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è ‚Äî —É–±–µ—Ä–∏ —ç—Ç–æ—Ç —Ñ–ª–∞–≥\n",
    "                 K=STATE[\"K_TARGET\"],\n",
    "                 jobs=STATE[\"JOBS\"],\n",
    "                 seed=STATE[\"SEED\"],\n",
    "                 cache=1)\n",
    "        dt = time.time() - t0\n",
    "        print(f\"\n",
    "‚úì –ì–æ—Ç–æ–≤–æ –∑–∞ {dt:.1f}s\")\n",
    "        # –ü–æ–∫–∞–∑–∞—Ç—å –≥–¥–µ —Ñ–∞–π–ª\n",
    "        cand_path = A[\"cand_dir\"]/\"candidates.parquet\"\n",
    "        print(\"candidates:\", cand_path, \"exists:\", exists(cand_path))\n",
    "\n",
    "btn_build.on_click(on_build)\n",
    "W.VBox([btn_build, out_build])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53085c62",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 6 ‚Äî –ü–æ–¥—Å—á—ë—Ç Recall@K / NDCG@K –ø–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_eval = W.Button(description=\"–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (Recall/NDCG) –Ω–∞ val\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "out_eval = W.Output()\n",
    "\n",
    "def _load_val_and_cands():\n",
    "    A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "    pairs_val = pd.read_parquet(A[\"profile_dir\"]/\"pairs_val.parquet\")\n",
    "    cands = pd.read_parquet(A[\"cand_dir\"]/\"candidates.parquet\")\n",
    "    # –û–∂–∏–¥–∞–µ–º—ã–µ –ø–æ–ª—è: query_id, item_id, score, source (source ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    need = {\"query_id\",\"item_id\"}\n",
    "    miss = need - set(cands.columns)\n",
    "    if miss:\n",
    "        raise AssertionError(f\"candidates.parquet –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç {miss}\")\n",
    "    return pairs_val, cands\n",
    "\n",
    "def _recall_ndcg_at_k(pairs_val, cands, ks=(10,20,50,100)):\n",
    "    # –æ–∂–∏–¥–∞–µ–º –ø–æ pairs_val: query_id,item_id,label (binary)\n",
    "    pv = pairs_val[[\"query_id\",\"item_id\",\"label\"]].copy()\n",
    "    pv[\"label\"] = pv[\"label\"].astype(int)\n",
    "    pos = pv[pv[\"label\"]==1].groupby(\"query_id\")[\"item_id\"].apply(set).to_dict()\n",
    "    # —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
    "    cands = cands.sort_values([\"query_id\",\"score\"], ascending=[True, False]).copy() if \"score\" in cands.columns else cands.copy()\n",
    "    group = cands.groupby(\"query_id\")[\"item_id\"].apply(list)\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        hits = 0; tot = 0; dcg = 0.0; idcg = 0.0; covered = 0\n",
    "        for q, true_items in pos.items():\n",
    "            pred = group.get(q, [])[:k]\n",
    "            if len(pred)>0: covered += 1\n",
    "            # Recall@K (–∏–ª–∏ HitRate –µ—Å–ª–∏ 1 –ø–æ–∑–∏—Ç–∏–≤)\n",
    "            hit = int(any(it in true_items for it in pred))\n",
    "            hits += hit; tot += 1\n",
    "            # NDCG@K (binary relevance)\n",
    "            # gain = 1/log2(rank+1) –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è\n",
    "            _dcg = 0.0\n",
    "            for r, it in enumerate(pred, start=1):\n",
    "                if it in true_items:\n",
    "                    _dcg = 1.0 / math.log2(r+1); break\n",
    "            dcg += _dcg\n",
    "            idcg += 1.0  # —Ç.–∫. –º–∞–∫—Å–∏–º—É–º –æ–¥–∏–Ω —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π (next-item)\n",
    "        results[f\"recall@{k}\"] = hits / max(1, tot)\n",
    "        results[f\"ndcg@{k}\"] = (dcg / max(1.0, idcg))\n",
    "        results[f\"coverage@{k}\"] = covered / max(1, len(pos))\n",
    "    results[\"queries\"] = len(pos)\n",
    "    return results\n",
    "\n",
    "def on_eval(_):\n",
    "    with out_eval:\n",
    "        clear_output()\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        res = _recall_ndcg_at_k(pv, cd, ks=(10,20,50,100))\n",
    "        print(json.dumps(res, indent=2))\n",
    "\n",
    "btn_eval.on_click(on_eval)\n",
    "W.VBox([btn_eval, out_eval])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc9bcb",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 7 ‚Äî –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: –≤–∫–ª–∞–¥, –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è, ¬´–¥—ã—Ä—ã¬ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_sources = W.Button(description=\"–†–∞–∑–ª–æ–∂–∏—Ç—å –≤–∫–ª–∞–¥ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "out_sources = W.Output()\n",
    "\n",
    "def on_sources(_):\n",
    "    with out_sources:\n",
    "        clear_output()\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        if \"source\" not in cd.columns:\n",
    "            print(\"–í candidates.parquet –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ source ‚Äî –≤–∫–ª–∞–¥ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –Ω–µ –ø–æ—Å—á–∏—Ç–∞—Ç—å.\")\n",
    "            return\n",
    "        # –≤–∫–ª–∞–¥ –ø–æ –ø–æ–ø–∞–¥–∞–Ω–∏—è–º (—Ö–æ—Ç—å –æ–¥–Ω–æ –ø–æ–ø–∞–¥–∞–Ω–∏–µ —Å—Ä–µ–¥–∏ top-K ‚Üí –∞—Ç—Ä–∏–±—É—Ç–Ω—É—Ç—å ¬´–ø–µ—Ä–≤–æ–º—É –∏—Å—Ç–æ—á–Ω–∏–∫—É, –∫–æ—Ç–æ—Ä—ã–π –¥–∞–ª –ø–æ–ø–∞–¥–∞–Ω–∏–µ¬ª)\n",
    "        K = 20\n",
    "        cd_sorted = cd.sort_values([\"query_id\",\"score\"], ascending=[True,False])\n",
    "        grp = cd_sorted.groupby(\"query_id\")\n",
    "        pos = pv[pv[\"label\"]==1].groupby(\"query_id\")[\"item_id\"].apply(set).to_dict()\n",
    "        counts = Counter()\n",
    "        misses = []\n",
    "        for q, dfq in grp:\n",
    "            true_items = pos.get(q, set())\n",
    "            if not true_items:\n",
    "                continue\n",
    "            top = dfq.head(K)\n",
    "            hit_rows = top[top[\"item_id\"].isin(true_items)]\n",
    "            if len(hit_rows):\n",
    "                src = hit_rows.iloc[0][\"source\"] if \"source\" in hit_rows.columns else \"?\"\n",
    "                counts[str(src)] += 1\n",
    "            else:\n",
    "                misses.append(q)\n",
    "        total = len(pos)\n",
    "        rows = [{\"source\": s, \"hit_queries\": c, \"share\": c/max(1,total)} for s,c in counts.most_common()]\n",
    "        df = pd.DataFrame(rows)\n",
    "        display(df if len(df) else \"–Ω–µ—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–π\")\n",
    "        print(f\"Queries with no hit in top@{K}: {len(misses)}/{total}\")\n",
    "        if len(misses):\n",
    "            miss_df = pd.DataFrame({\"query_id\": misses[:50]})\n",
    "            display(miss_df)\n",
    "\n",
    "btn_sources.on_click(on_sources)\n",
    "W.VBox([btn_sources, out_sources])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da204c",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 8 ‚Äî –ù–∞—Å—Ç—Ä–æ–π–∫–∞ covis / seq-ngrams –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —á–∞—Å—Ç–∏—á–Ω–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62dd884",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_tune_covis = W.Button(description=\"–ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å covis/seq —Å –Ω–æ–≤—ã–º–∏ –æ–∫–Ω–∞–º–∏\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "out_tune = W.Output()\n",
    "\n",
    "def on_tune_covis(_):\n",
    "    with out_tune:\n",
    "        clear_output()\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        overrides_path = f\"artifacts/tmp/{STATE['DATASET_ID']}_{profile_name(STATE['PROFILE_PATH'])}_cands_overrides.json\"\n",
    "        ov = build_overrides_json(overrides_path)\n",
    "        print(\"New windows:\", PARAMS[\"windows_days\"], \"last_k:\", PARAMS[\"last_k\"])\n",
    "        run_tool(\"recsys/tools/run_candidates.py\",\n",
    "                 dataset_id=STATE[\"DATASET_ID\"],\n",
    "                 profile=STATE[\"PROFILE_PATH\"],\n",
    "                 overrides=overrides_path,\n",
    "                 K=STATE[\"K_TARGET\"],\n",
    "                 jobs=STATE[\"JOBS\"],\n",
    "                 seed=STATE[\"SEED\"],\n",
    "                 only=\"covis,session_ngrams\",   # –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ\n",
    "                 cache=1)\n",
    "        print(\"‚úì –ü–µ—Ä–µ—Å—á—ë—Ç covis/seq –∑–∞–≤–µ—Ä—à—ë–Ω\")\n",
    "        # –º–µ—Ç—Ä–∏–∫–∏\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        res = _recall_ndcg_at_k(pv, cd, ks=(10,20,50,100))\n",
    "        print(json.dumps(res, indent=2))\n",
    "\n",
    "btn_tune_covis.on_click(on_tune_covis)\n",
    "W.VBox([btn_tune_covis, out_tune])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09fcb1",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 9 ‚Äî –í–∫–ª—é—á–µ–Ω–∏–µ item2vec/ALS/–∫–æ–Ω—Ç–µ–Ω—Ç/–≥—Ä–∞—Ñ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É–ª–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_heavy = W.Button(description=\"–î–æ–±–∞–≤–∏—Ç—å item2vec/ALS/–∫–æ–Ω—Ç–µ–Ω—Ç/–≥—Ä–∞—Ñ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã)\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "out_heavy = W.Output()\n",
    "\n",
    "def on_heavy(_):\n",
    "    with out_heavy:\n",
    "        clear_output()\n",
    "        overrides_path = f\"artifacts/tmp/{STATE['DATASET_ID']}_{profile_name(STATE['PROFILE_PATH'])}_cands_overrides.json\"\n",
    "        ov = build_overrides_json(overrides_path)\n",
    "        print(\"heavy sources flags:\", {k:v for k,v in GEN.items() if k in [\"item2vec\",\"als\",\"content_tfidf\",\"graph_ppr\"]})\n",
    "        run_tool(\"recsys/tools/run_candidates.py\",\n",
    "                 dataset_id=STATE[\"DATASET_ID\"],\n",
    "                 profile=STATE[\"PROFILE_PATH\"],\n",
    "                 overrides=overrides_path,\n",
    "                 K=STATE[\"K_TARGET\"],\n",
    "                 jobs=STATE[\"JOBS\"],\n",
    "                 seed=STATE[\"SEED\"],\n",
    "                 only=\"item2vec,als,content_tfidf,graph_ppr\",  # –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "                 cache=1)\n",
    "        print(\"‚úì –û–±–Ω–æ–≤–ª—ë–Ω –ø—É–ª heavy-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏\")\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        res = _recall_ndcg_at_k(pv, cd, ks=(10,20,50,100))\n",
    "        print(json.dumps(res, indent=2))\n",
    "\n",
    "btn_heavy.on_click(on_heavy)\n",
    "W.VBox([btn_heavy, out_heavy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fcb2c",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 10 ‚Äî –ö–≤–æ—Ç—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ—Ä–∞–Ω–∂ –ø—É–ª–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_quotas = W.Button(description=\"–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–≤–æ—Ç—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏ –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "out_quotas = W.Output()\n",
    "\n",
    "# –ø—Ä–æ—Å—Ç–æ–π UI –¥–ª—è –∫–≤–æ—Ç (–∑–∞–¥–∞—ë–º –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤)\n",
    "w_quota_text = W.Text(\"covis:140,session_ngrams:80,pop:40,recency:40,item2vec:60,als:60,content_tfidf:40,graph_ppr:40,brand_fallback:30,category_fallback:30\",\n",
    "                      description=\"quotas:\", layout=W.Layout(width=\"900px\"))\n",
    "\n",
    "def _apply_quotas(cands: pd.DataFrame, quotas: dict, K_target: int):\n",
    "    if \"source\" not in cands.columns:\n",
    "        # –±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ‚Äî –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∂–µ–º –¥–æ K\n",
    "        return cands.sort_values([\"query_id\",\"score\"], ascending=[True,False]).groupby(\"query_id\").head(K_target).reset_index(drop=True)\n",
    "    out_rows = []\n",
    "    for q, dfq in cands.groupby(\"query_id\", sort=False):\n",
    "        parts = []\n",
    "        for s, g in dfq.sort_values(\"score\", ascending=False).groupby(\"source\"):\n",
    "            k = int(quotas.get(str(s), 0))\n",
    "            if k>0:\n",
    "                parts.append(g.head(k))\n",
    "        if parts:\n",
    "            merged = pd.concat(parts, axis=0)\n",
    "        else:\n",
    "            merged = dfq.sort_values(\"score\", ascending=False)\n",
    "        merged = merged.drop_duplicates(subset=[\"item_id\"], keep=\"first\").head(K_target)\n",
    "        merged[\"query_id\"] = q\n",
    "        out_rows.append(merged)\n",
    "    res = pd.concat(out_rows, axis=0).reset_index(drop=True)\n",
    "    return res\n",
    "\n",
    "def on_quotas(_):\n",
    "    with out_quotas:\n",
    "        clear_output()\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        if \"source\" not in cd.columns:\n",
    "            print(\"–ù–µ—Ç source –≤ candidates ‚Äî –∫–≤–æ—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.\")\n",
    "            return\n",
    "        # —Ä–∞—Å–ø–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ \"name:k,name:k,...\"\n",
    "        quotas = {}\n",
    "        for tok in w_quota_text.value.split(\",\"):\n",
    "            tok = tok.strip()\n",
    "            if not tok: continue\n",
    "            if \":\" in tok:\n",
    "                name, val = tok.split(\":\")\n",
    "                quotas[name.strip()] = int(val.strip())\n",
    "        new_cd = _apply_quotas(cd, quotas, STATE[\"K_TARGET\"])\n",
    "        print(\"–î–æ:\", cd.groupby(\"query_id\").size().describe()[[\"mean\",\"min\",\"max\"]].to_dict())\n",
    "        print(\"–ü–æ—Å–ª–µ:\", new_cd.groupby(\"query_id\").size().describe()[[\"mean\",\"min\",\"max\"]].to_dict())\n",
    "        # –ª–æ–∫–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "        res = _recall_ndcg_at_k(pv, new_cd, ks=(10,20,50,100))\n",
    "        print(json.dumps(res, indent=2))\n",
    "        # –ø—Ä–µ–¥–ª–æ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ ¬´–ª–æ–∫–∞–ª—å–Ω—É—é¬ª –≤–µ—Ä—Å–∏—é\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        out_p = A[\"cand_dir\"] / \"candidates_local_quota.parquet\"\n",
    "        new_cd.to_parquet(out_p, index=False)\n",
    "        print(\"‚úì candidates_local_quota.parquet —Å–æ—Ö—Ä–∞–Ω—ë–Ω ‚Üí\", out_p)\n",
    "\n",
    "btn_quotas.on_click(on_quotas)\n",
    "W.VBox([w_quota_text, btn_quotas, out_quotas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e23954",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 11 ‚Äî PANIC-—Ä–µ–∂–∏–º (–º–∏–Ω–∏–º—É–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –º–∞–∫—Å–∏–º—É–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3abcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_panic = W.Button(description=\"‚ö° PANIC: covis+pop+fallback (K=300)\", button_style=\"danger\", layout=BTN_LAYOUT)\n",
    "out_panic = W.Output()\n",
    "\n",
    "def on_panic(_):\n",
    "    with out_panic:\n",
    "        clear_output()\n",
    "        # –∂—ë—Å—Ç–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–∞–Ω–∏–∫–∞\n",
    "        GEN[\"covis\"]=True; GEN[\"session_ngrams\"]=True; GEN[\"pop\"]=True; GEN[\"recency\"]=True\n",
    "        GEN[\"item2vec\"]=GEN[\"als\"]=GEN[\"content_tfidf\"]=GEN[\"graph_ppr\"]=False\n",
    "        GEN[\"brand_fallback\"]=GEN[\"category_fallback\"]=True\n",
    "        STATE[\"K_TARGET\"]=max(200, STATE[\"K_TARGET\"])\n",
    "        PARAMS[\"windows_days\"]=\"7,30\"; PARAMS[\"last_k\"]=5; PARAMS[\"decay_alpha\"]=0.9\n",
    "        overrides_path = f\"artifacts/tmp/{STATE['DATASET_ID']}_{profile_name(STATE['PROFILE_PATH'])}_panic_overrides.json\"\n",
    "        build_overrides_json(overrides_path)\n",
    "        run_tool(\"recsys/tools/run_candidates.py\",\n",
    "                 dataset_id=STATE[\"DATASET_ID\"],\n",
    "                 profile=STATE[\"PROFILE_PATH\"],\n",
    "                 overrides=overrides_path,\n",
    "                 K=STATE[\"K_TARGET\"],\n",
    "                 jobs=STATE[\"JOBS\"],\n",
    "                 seed=STATE[\"SEED\"],\n",
    "                 cache=1)\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        res = _recall_ndcg_at_k(pv, cd, ks=(10,20,50,100))\n",
    "        print(\"PANIC metrics:\")\n",
    "        print(json.dumps(res, indent=2))\n",
    "\n",
    "btn_panic.on_click(on_panic)\n",
    "W.VBox([btn_panic, out_panic])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0615b6",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 12 ‚Äî –ü–∞—Å–ø–æ—Ä—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_pass = W.Button(description=\"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å candidates_report.json\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_pass = W.Output()\n",
    "\n",
    "def on_pass(_):\n",
    "    with out_pass:\n",
    "        clear_output()\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        pv, cd = _load_val_and_cands()\n",
    "        metrics = _recall_ndcg_at_k(pv, cd, ks=(10,20,50,100))\n",
    "        report = dict(\n",
    "            dataset_id=STATE[\"DATASET_ID\"],\n",
    "            profile=STATE[\"PROFILE_PATH\"],\n",
    "            seed=STATE[\"SEED\"],\n",
    "            jobs=STATE[\"JOBS\"],\n",
    "            k_target=STATE[\"K_TARGET\"],\n",
    "            fast=STATE[\"FAST\"],\n",
    "            panic=STATE[\"PANIC\"],\n",
    "            generators=GEN,\n",
    "            params=PARAMS,\n",
    "            metrics=metrics,\n",
    "            saved_at=datetime.utcnow().isoformat()+\"Z\"\n",
    "        )\n",
    "        out_json = A[\"cand_dir\"] / \"candidates_report.json\"\n",
    "        A[\"cand_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "        out_json.write_text(json.dumps(report, ensure_ascii=False, indent=2))\n",
    "        print(\"‚úì report saved:\", out_json)\n",
    "        print(json.dumps(metrics, indent=2))\n",
    "\n",
    "btn_pass.on_click(on_pass)\n",
    "W.VBox([btn_pass, out_pass])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e671671",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 13 ‚Äî –ü—Ä–æ—Å–º–æ—Ç—Ä –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_list = W.Button(description=\"–ü–æ–∫–∞–∑–∞—Ç—å —Ñ–∞–π–ª—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "out_list = W.Output()\n",
    "\n",
    "def on_list(_):\n",
    "    with out_list:\n",
    "        clear_output()\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        d = A[\"cand_dir\"]\n",
    "        if not d.exists():\n",
    "            print(\"–ü–∞–ø–∫–∞ –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω–∞:\", d)\n",
    "            return\n",
    "        files = sorted(d.rglob(\"*\"))\n",
    "        df = pd.DataFrame([{\"path\":str(p), \"size_MB\": round(p.stat().st_size/1024/1024,3)} for p in files if p.is_file()])\n",
    "        display(df)\n",
    "\n",
    "btn_list.on_click(on_list)\n",
    "W.VBox([btn_list, out_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c89db",
   "metadata": {},
   "source": [
    "### –Ø—á–µ–π–∫–∞ 14 ‚Äî –ë—ã—Å—Ç—Ä—ã–π one-click —Å—Ü–µ–Ω–∞—Ä–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_all = W.Button(description=\"üöÄ –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–æ–Ω: check ‚Üí build ‚Üí eval ‚Üí sources ‚Üí save report\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_all = W.Output()\n",
    "\n",
    "def on_all(_):\n",
    "    with out_all:\n",
    "        clear_output()\n",
    "        try:\n",
    "            # 1) check\n",
    "            on_check(None)\n",
    "            # 2) build\n",
    "            on_build(None)\n",
    "            # 3) eval\n",
    "            on_eval(None)\n",
    "            # 4) sources\n",
    "            on_sources(None)\n",
    "            # 5) save report\n",
    "            on_pass(None)\n",
    "        except Exception as e:\n",
    "            print(\"–û–®–ò–ë–ö–ê:\", e)\n",
    "            raise\n",
    "\n",
    "btn_all.on_click(on_all)\n",
    "W.VBox([btn_all, out_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11215aed",
   "metadata": {},
   "source": [
    "### –ü–æ—Ä–æ–≥–æ–≤—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã\n",
    "- **Recall@20** (next-item): —Ü–µ–ª–∏–º—Å—è ‚â• 0.90; PANIC ‚Äî ‚â• 0.88.\n",
    "- Queries –±–µ–∑ –ø–æ–ø–∞–¥–∞–Ω–∏–π ‚â§ 2‚Äì3%. –ï—Å–ª–∏ –≤—ã—à–µ ‚Äî –≤–∫–ª—é—á–∏ `brand/category fallback`.\n",
    "- –ï—Å–ª–∏ Recall –≤—ã—Å–æ–∫, —Å–º–µ–ª–æ **—Å–Ω–∏–∂–∞–π K_target** (—É—Å–∫–æ—Ä–∏—à—å —Ñ–∏—á–∏/—Ä–∞–Ω–∫–µ—Ä).\n",
    "- –°–∏–ª—å–Ω—ã–µ –ø—Ä–æ—Å–∞–¥–∫–∏ –Ω–∞ CS-—Å—Ä–µ–∑–∞—Ö ‚Üí –¥–æ–±–∞–≤–ª—è–π `content`/`graph`.\n",
    "\n",
    "**–î–∞–ª—å—à–µ:** `03_ranker_lab.ipynb` ‚Äî —Ñ–∏—á–∏ + —Ä–∞–Ω–∫–µ—Ä + –∞–Ω–∞–ª–∏–∑ OOF, –∑–∞—Ç–µ–º `04_blend_eval` –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∞ –∏ –º–µ—Ç–∞-–±–ª–µ–Ω–¥–∞."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
