{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8870f74",
   "metadata": {},
   "source": [
    "# 04 ¬∑ Blend & Eval ‚Äî –∞–Ω—Å–∞–º–±–ª—å —Ä–∞–Ω–∫–µ—Ä–æ–≤, —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å üß™\n",
    "\n",
    "–¶–µ–ª—å: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å 2‚Äì6 —Ä–∞–Ω–∫–µ—Ä–æ–≤ –≤ —É—Å—Ç–æ–π—á–∏–≤—ã–π –±–ª–µ–Ω–¥ (RRF/Borda/Comb*, –≤–µ—Å–æ–≤–æ–π, level-2), –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ OOF,\n",
    "—Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å –ø–æ —Å—Ä–µ–∑–∞–º –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –±—É—Ç—Å—Ç—Ä—ç–ø–æ–º, –∏ –≤—ã–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π `ranked.parquet` –¥–ª—è —Å–∞–±–º–∏—Ç–∞.\n",
    "\n",
    "–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:\n",
    "`artifacts/recsys/ensemble/<dataset>/<profile>/<ens_id>/{ranked.parquet, scores_blend.parquet, weights.json, blender_config.json, oof_metrics.json, slices.json, stability.json, report.json}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdef585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* ipywidgets v8 (JupyterLab 4) */\n",
    ".jp-OutputArea .widget-button .widget-label { \n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "/* fallback –¥–ª—è ipywidgets v7 */\n",
    ".jupyter-widgets.widget-button .widget-label {\n",
    "  white-space: normal !important; \n",
    "  overflow: visible !important; \n",
    "  text-overflow: clip !important;\n",
    "  line-height: 1.2 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad43ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time, math, warnings, random\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as W\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_colwidth\", 140)\n",
    "\n",
    "# ML utils\n",
    "try:\n",
    "    from sklearn.isotonic import IsotonicRegression\n",
    "    from sklearn.linear_model import LogisticRegression, Ridge\n",
    "    from sklearn.model_selection import KFold\n",
    "except Exception:\n",
    "    IsotonicRegression = None\n",
    "    LogisticRegression = None\n",
    "    Ridge = None\n",
    "    KFold = None\n",
    "\n",
    "REPO = Path.cwd()\n",
    "\n",
    "def mem_gb(obj=None):\n",
    "    try:\n",
    "        import psutil\n",
    "        if obj is None: return psutil.Process().memory_info().rss/(1024**3)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if hasattr(obj, \"memory_usage\"):\n",
    "            return float(obj.memory_usage(deep=True).sum())/(1024**3)\n",
    "        return float(np.array(obj).nbytes)/(1024**3)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2))\n",
    "\n",
    "def now_tag(): \n",
    "    return datetime.now().strftime(\"%m%d_%H%M\")\n",
    "\n",
    "def art_paths(dataset_id, profile_path):\n",
    "    prof = Path(profile_path).stem\n",
    "    root = Path(\"artifacts\")\n",
    "    return dict(\n",
    "        dataio  = root/\"recsys\"/\"dataio\"/dataset_id,\n",
    "        rankers = root/\"recsys\"/\"ranker\"/dataset_id/prof,\n",
    "        ens     = root/\"recsys\"/\"ensemble\"/dataset_id/prof,\n",
    "        profile = root/\"recsys\"/\"dataio\"/dataset_id/prof\n",
    "    )\n",
    "\n",
    "def exists(p): \n",
    "    try: return Path(p).exists()\n",
    "    except: return False\n",
    "\n",
    "def list_ranker_runs(dataset_id, profile_path) -> List[Path]:\n",
    "    A = art_paths(dataset_id, profile_path)\n",
    "    d = A[\"rankers\"]\n",
    "    if not d.exists(): return []\n",
    "    runs = [p for p in sorted(d.iterdir()) if p.is_dir()]\n",
    "    # —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∞–ª–∏—á–∏—é oof –∏–ª–∏ ranked\n",
    "    out = []\n",
    "    for r in runs:\n",
    "        if (r/\"oof.parquet\").exists() or (r/\"ranked.parquet\").exists():\n",
    "            out.append(r)\n",
    "    return out\n",
    "\n",
    "def read_parquet_safe(path: Path, cols: List[str] = None):\n",
    "    df = pd.read_parquet(path)\n",
    "    if cols:\n",
    "        miss = [c for c in cols if c not in df.columns]\n",
    "        if miss: \n",
    "            raise AssertionError(f\"{path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–æ–ª–±—Ü—ã: {miss}\")\n",
    "        return df[cols].copy()\n",
    "    return df\n",
    "\n",
    "def safe_rank_in_group(df, by=[\"query_id\",\"score\"], ascending=[True,False], k_col=\"rank\"):\n",
    "    df = df.sort_values(by, ascending=ascending)\n",
    "    df[k_col] = df.groupby(\"query_id\")[\"score\"].rank(ascending=False, method=\"first\").astype(\"int32\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTN_LAYOUT = W.Layout(min_width=\"220px\", width=\"auto\", height=\"36px\", flex=\"0 0 auto\")\n",
    "ROW_LAYOUT = W.Layout(flex_flow=\"row wrap\", grid_gap=\"8px\")\n",
    "GRID_LAYOUT = W.Layout(grid_template_columns=\"repeat(3, minmax(220px, 1fr))\", grid_gap=\"8px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc77b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = dict(\n",
    "    DATASET_ID   = \"s5e11\",\n",
    "    PROFILE_PATH = \"configs/recsys/profiles/gate.yaml\",\n",
    "    K_OUT        = 100,\n",
    "    RANDOM_SEED  = 42,\n",
    ")\n",
    "\n",
    "EVAL = dict(\n",
    "    KS = [10,20,50,100],\n",
    "    MAIN_K = 20\n",
    ")\n",
    "\n",
    "NORM = dict(\n",
    "    method = \"zscore_query\",  # zscore_query | minmax_query | quantile_query | none\n",
    "    calibrate = \"none\"        # none | platt | isotonic\n",
    ")\n",
    "\n",
    "BLEND = dict(\n",
    "    use_rrf=True, rrf_k=60,\n",
    "    use_borda=True,\n",
    "    use_combsum=True, use_combmnz=True,\n",
    "    use_weight_search=True, weight_nonneg=True, weight_sum_to_one=True, weight_trials=300,\n",
    "    use_meta_l2=True, meta_algo=\"ridge\", meta_splits=5\n",
    ")\n",
    "\n",
    "# –í–∏–¥–∂–µ—Ç—ã\n",
    "w_ds   = W.Text(STATE[\"DATASET_ID\"], description=\"dataset_id:\", layout=W.Layout(width=\"240px\"))\n",
    "w_prof = W.Text(STATE[\"PROFILE_PATH\"], description=\"profile:\", layout=W.Layout(width=\"520px\"))\n",
    "w_kout = W.IntText(STATE[\"K_OUT\"], description=\"K_OUT:\", layout=W.Layout(width=\"160px\"))\n",
    "w_seed = W.IntText(STATE[\"RANDOM_SEED\"], description=\"seed:\", layout=W.Layout(width=\"160px\"))\n",
    "\n",
    "w_ks   = W.Text(\",\".join(map(str,EVAL[\"KS\"])), description=\"KS:\", layout=W.Layout(width=\"220px\"))\n",
    "w_main = W.IntText(EVAL[\"MAIN_K\"], description=\"main@K:\", layout=W.Layout(width=\"180px\"))\n",
    "\n",
    "w_norm = W.Dropdown(options=[\"zscore_query\",\"minmax_query\",\"quantile_query\",\"none\"], value=NORM[\"method\"], description=\"normalize:\")\n",
    "w_cal  = W.Dropdown(options=[\"none\",\"platt\",\"isotonic\"], value=NORM[\"calibrate\"], description=\"calibrate:\")\n",
    "\n",
    "tog_rrf   = W.Checkbox(BLEND[\"use_rrf\"], description=\"RRF\")\n",
    "w_rrf_k   = W.IntText(BLEND[\"rrf_k\"], description=\"rrf_k:\")\n",
    "tog_borda = W.Checkbox(BLEND[\"use_borda\"], description=\"Borda\")\n",
    "tog_csum  = W.Checkbox(BLEND[\"use_combsum\"], description=\"CombSUM\")\n",
    "tog_cmnz  = W.Checkbox(BLEND[\"use_combmnz\"], description=\"CombMNZ\")\n",
    "tog_wght  = W.Checkbox(BLEND[\"use_weight_search\"], description=\"WeightSearch\")\n",
    "w_trials  = W.IntText(BLEND[\"weight_trials\"], description=\"trials:\")\n",
    "w_nonneg  = W.Checkbox(BLEND[\"weight_nonneg\"], description=\"nonneg\")\n",
    "w_sum1    = W.Checkbox(BLEND[\"weight_sum_to_one\"], description=\"sum_to_one\")\n",
    "tog_meta  = W.Checkbox(BLEND[\"use_meta_l2\"], description=\"Level-2 (Ridge)\")\n",
    "w_malgo   = W.Dropdown(options=[\"ridge\"], value=BLEND[\"meta_algo\"], description=\"meta:\")\n",
    "w_msplits = W.IntText(BLEND[\"meta_splits\"], description=\"splits:\")\n",
    "\n",
    "btn_scan  = W.Button(description=\"–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–Ω–∫–µ—Ä—ã\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "out_scan  = W.Output()\n",
    "\n",
    "# Placeholder –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ä–∞–Ω–∫–µ—Ä–æ–≤\n",
    "SEL = dict(runs=[], widget=None)\n",
    "\n",
    "def on_scan(_):\n",
    "    with out_scan:\n",
    "        clear_output()\n",
    "        # apply\n",
    "        STATE.update(DATASET_ID=w_ds.value.strip(), PROFILE_PATH=w_prof.value.strip(), K_OUT=int(w_kout.value), RANDOM_SEED=int(w_seed.value))\n",
    "        EVAL.update(KS=[int(x) for x in w_ks.value.split(\",\") if x.strip()], MAIN_K=int(w_main.value))\n",
    "        NORM.update(method=w_norm.value, calibrate=w_cal.value)\n",
    "        BLEND.update(\n",
    "            use_rrf=bool(tog_rrf.value), rrf_k=int(w_rrf_k.value),\n",
    "            use_borda=bool(tog_borda.value),\n",
    "            use_combsum=bool(tog_csum.value), use_combmnz=bool(tog_cmnz.value),\n",
    "            use_weight_search=bool(tog_wght.value), weight_trials=int(w_trials.value),\n",
    "            weight_nonneg=bool(w_nonneg.value), weight_sum_to_one=bool(w_sum1.value),\n",
    "            use_meta_l2=bool(tog_meta.value), meta_algo=w_malgo.value, meta_splits=int(w_msplits.value)\n",
    "        )\n",
    "\n",
    "        runs = list_ranker_runs(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        if not runs:\n",
    "            print(\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–Ω–∫–µ—Ä–æ–≤. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≥–æ–Ω–∏ 03_ranker_lab.\")\n",
    "            return\n",
    "        SEL[\"runs\"]=runs\n",
    "        options = [(f\"{r.name}  ‚Äî  {r}\", str(r)) for r in runs]\n",
    "        SEL[\"widget\"] = W.SelectMultiple(options=options, description=\"runs\", rows=min(10, len(options)))\n",
    "        display(HTML(\"<b>–í—ã–±–µ—Ä–∏ 2‚Äì6 —Ä–∞–Ω–∫–µ—Ä–æ–≤ –¥–ª—è –±–ª–µ–Ω–¥–∞</b>\"))\n",
    "        display(SEL[\"widget\"])\n",
    "\n",
    "btn_scan.on_click(on_scan)\n",
    "\n",
    "W.VBox([\n",
    "    W.HTML(\"<h3>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã</h3>\"),\n",
    "    W.HBox([w_ds, w_seed, w_kout], layout=ROW_LAYOUT),\n",
    "    w_prof,\n",
    "    W.HTML(\"<b>–ú–µ—Ç—Ä–∏–∫–∏</b>\"),\n",
    "    W.HBox([w_ks, w_main], layout=ROW_LAYOUT),\n",
    "    W.HTML(\"<b>–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞</b>\"),\n",
    "    W.HBox([w_norm, w_cal], layout=ROW_LAYOUT),\n",
    "    W.HTML(\"<b>–ë–ª–µ–Ω–¥–∏–Ω–≥</b>\"),\n",
    "    W.HBox([tog_rrf, w_rrf_k, tog_borda, tog_csum, tog_cmnz], layout=ROW_LAYOUT),\n",
    "    W.HBox([tog_wght, w_trials, w_nonneg, w_sum1], layout=ROW_LAYOUT),\n",
    "    W.HBox([tog_meta, w_malgo, w_msplits], layout=ROW_LAYOUT),\n",
    "    btn_scan, out_scan\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79204793",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_load = W.Button(description=\"–ó–∞–≥—Ä—É–∑–∏—Ç—å OOF/TEST –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ä–∞–Ω–∫–µ—Ä–æ–≤\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_load = W.Output()\n",
    "\n",
    "RUNS = dict()  # run_id -> {path, oof_df, test_df, K_in}\n",
    "\n",
    "def _load_single_run(run_path: Path):\n",
    "    oof_path  = run_path/\"oof.parquet\"\n",
    "    test_path = run_path/\"test_scores.parquet\"\n",
    "    ranked_tk = run_path/\"ranked.parquet\"\n",
    "    if not exists(oof_path):\n",
    "        raise AssertionError(f\"–ù–µ—Ç {oof_path}\")\n",
    "    oof = read_parquet_safe(oof_path, [\"query_id\",\"item_id\",\"label\",\"oof_score\"]).rename(columns={\"oof_score\":\"score\"})\n",
    "    # test\n",
    "    if exists(test_path):\n",
    "        test = read_parquet_safe(test_path, [\"query_id\",\"item_id\",\"score\"])\n",
    "    elif exists(ranked_tk):\n",
    "        test = read_parquet_safe(ranked_tk, [\"query_id\",\"item_id\",\"score\"])\n",
    "    else:\n",
    "        raise AssertionError(f\"–ù–µ—Ç test_scores/ranked –≤ {run_path}\")\n",
    "    # K_in ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ query –≤ OOF\n",
    "    K_in = int(oof.groupby(\"query_id\").size().mean())\n",
    "    return oof, test, K_in\n",
    "\n",
    "def on_load(_):\n",
    "    with out_load:\n",
    "        clear_output()\n",
    "        chosen = SEL.get(\"widget\")\n",
    "        if not chosen:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ –æ—Ç—Å–∫–∞–Ω–∏—Ä—É–π —Ä–∞–Ω–∫–µ—Ä—ã –∏ –≤—ã–±–µ—Ä–∏ –∏—Ö.\")\n",
    "            return\n",
    "        sel_ids = [Path(v) for v in chosen.value]\n",
    "        if len(sel_ids)<2:\n",
    "            print(\"–ù—É–∂–Ω–æ ‚â•2 —Ä–∞–Ω–∫–µ—Ä–æ–≤.\")\n",
    "            return\n",
    "        random.seed(STATE[\"RANDOM_SEED\"]); np.random.seed(STATE[\"RANDOM_SEED\"])\n",
    "        RUNS.clear()\n",
    "        for rp in sel_ids:\n",
    "            oof, test, kin = _load_single_run(rp)\n",
    "            rid = rp.name\n",
    "            RUNS[rid] = dict(path=rp, oof=oof, test=test, K_in=kin)\n",
    "            print(f\"OK {rid}: OOF {oof.shape} | TEST {test.shape} | ~K_in‚âà{kin}\")\n",
    "        # –ø–æ–¥—Å–≤–æ–¥–∫–∞ –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—é)\n",
    "        ids = list(RUNS.keys())\n",
    "        print(\"\n",
    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è OOF –ø–æ –ø–∞—Ä–∞–º —Ä–∞–Ω–∫–µ—Ä–æ–≤ (–∫–æ–ª-–≤–æ –æ–±—â–∏—Ö (q,i)):\")\n",
    "        M = []\n",
    "        for i,a in enumerate(ids):\n",
    "            row=[]\n",
    "            for j,b in enumerate(ids):\n",
    "                if j<i: row.append(\"\")\n",
    "                else:\n",
    "                    aa = RUNS[a][\"oof\"][ [\"query_id\",\"item_id\"] ]\n",
    "                    bb = RUNS[b][\"oof\"][ [\"query_id\",\"item_id\"] ]\n",
    "                    inter = aa.merge(bb, on=[\"query_id\",\"item_id\"], how=\"inner\").shape[0]\n",
    "                    row.append(inter)\n",
    "            M.append(row)\n",
    "        display(pd.DataFrame(M, index=ids, columns=ids))\n",
    "\n",
    "btn_load.on_click(on_load)\n",
    "W.VBox([btn_load, out_load])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_norm = W.Button(description=\"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å/–∫–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å OOF\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "out_norm = W.Output()\n",
    "\n",
    "NORMED = dict()  # run_id -> {oof_norm, test_norm, per_query_norm? ‚Äî –Ω–µ –Ω—É–∂–µ–Ω; –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä}\n",
    "\n",
    "def _normalize_querywise(df: pd.DataFrame, method: str):\n",
    "    # df: (query_id, item_id, score)\n",
    "    d = df.copy()\n",
    "    if method==\"none\":\n",
    "        return d\n",
    "    if method==\"zscore_query\":\n",
    "        g = d.groupby(\"query_id\")[\"score\"]\n",
    "        mu = g.transform(\"mean\"); sd = g.transform(\"std\").replace(0, 1.0)\n",
    "        d[\"score\"] = (d[\"score\"] - mu) / sd\n",
    "    elif method==\"minmax_query\":\n",
    "        g = d.groupby(\"query_id\")[\"score\"]\n",
    "        mn = g.transform(\"min\"); mx = g.transform(\"max\")\n",
    "        d[\"score\"] = (d[\"score\"] - mn) / (mx - mn + 1e-9)\n",
    "    elif method==\"quantile_query\":\n",
    "        # –∑–∞–º–µ–Ω–∏–º —Ä–∞–Ω–≥–∏ –Ω–∞ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ –∫–≤–∞–Ω—Ç–∏–ª—å–∫–∏ (1..K)/K\n",
    "        d = d.sort_values([\"query_id\",\"score\"], ascending=[True,False])\n",
    "        d[\"score\"] = d.groupby(\"query_id\")[\"score\"].rank(ascending=False, method=\"first\")\n",
    "        d[\"score\"] = d[\"score\"] / d.groupby(\"query_id\")[\"score\"].transform(\"max\")\n",
    "    else:\n",
    "        return d\n",
    "    return d\n",
    "\n",
    "def _fit_calibrator(scores, labels, method=\"none\"):\n",
    "    if method==\"none\":\n",
    "        return None\n",
    "    if method==\"platt\":\n",
    "        if LogisticRegression is None:\n",
    "            print(\"sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî Platt –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\"); return None\n",
    "        lr = LogisticRegression(max_iter=1000, n_jobs=None if hasattr(LogisticRegression, \"n_jobs\") else None)\n",
    "        lr.fit(scores.reshape(-1,1), labels.astype(int))\n",
    "        return (\"platt\", lr)\n",
    "    if method==\"isotonic\":\n",
    "        if IsotonicRegression is None:\n",
    "            print(\"sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî Isotonic –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\"); return None\n",
    "        ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "        ir.fit(scores, labels.astype(float))\n",
    "        return (\"isotonic\", ir)\n",
    "    return None\n",
    "\n",
    "def _apply_calibrator(scores, calib):\n",
    "    if calib is None:\n",
    "        return scores\n",
    "    kind, model = calib\n",
    "    if kind==\"platt\":\n",
    "        p = model.predict_proba(scores.reshape(-1,1))[:,1]\n",
    "        return p.astype(\"float32\")\n",
    "    if kind==\"isotonic\":\n",
    "        p = model.predict(scores)\n",
    "        return p.astype(\"float32\")\n",
    "    return scores\n",
    "\n",
    "def on_norm(_):\n",
    "    with out_norm:\n",
    "        clear_output()\n",
    "        if not RUNS:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–∞–Ω–∫–µ—Ä—ã.\")\n",
    "            return\n",
    "        NORMED.clear()\n",
    "        for rid, R in RUNS.items():\n",
    "            oof = R[\"oof\"][ [\"query_id\",\"item_id\",\"label\",\"score\"] ].copy()\n",
    "            test= R[\"test\"][ [\"query_id\",\"item_id\",\"score\"] ].copy()\n",
    "            # normalize per query\n",
    "            oofn = _normalize_querywise(oof.drop(columns=[\"label\"]), NORM[\"method\"])\n",
    "            testn= _normalize_querywise(test, NORM[\"method\"])\n",
    "            # calibrate on OOF if requested\n",
    "            calib = None\n",
    "            if NORM[\"calibrate\"]!=\"none\":\n",
    "                calib = _fit_calibrator(oofn[\"score\"].values, oof[\"label\"].values, NORM[\"calibrate\"])\n",
    "                if calib is not None:\n",
    "                    oofn[\"score\"]  = _apply_calibrator(oofn[\"score\"].values, calib)\n",
    "                    testn[\"score\"] = _apply_calibrator(testn[\"score\"].values, calib)\n",
    "            # cache\n",
    "            NORMED[rid] = dict(\n",
    "                oof=oofn, oof_label=oof[\"label\"].values.copy(),\n",
    "                test=testn, calib=None if calib is None else NORM[\"calibrate\"]\n",
    "            )\n",
    "            print(f\"‚úì {rid} –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω ({NORM['method']}, calib={NORM['calibrate']})\")\n",
    "        print(\"–ì–æ—Ç–æ–≤–æ.\")\n",
    "\n",
    "btn_norm.on_click(on_norm)\n",
    "W.VBox([btn_norm, out_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eaf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_ndcg_at_k(qids, labels, scores, ks=(10,20,50,100)):\n",
    "    df = pd.DataFrame({\"q\":qids, \"y\":labels, \"s\":scores})\n",
    "    df = df.sort_values([\"q\",\"s\"], ascending=[True,False])\n",
    "    out={}\n",
    "    for K in ks:\n",
    "        hits=0; tot=0; dcg=0.0; idcg=0.0\n",
    "        for q, grp in df.groupby(\"q\", sort=False):\n",
    "            arr = grp[\"y\"].values[:K]\n",
    "            hit = int(arr.sum()>0)\n",
    "            hits += hit; tot += 1\n",
    "            nd=0.0\n",
    "            for r,v in enumerate(arr, start=1):\n",
    "                if v>0:\n",
    "                    nd = 1.0/math.log2(r+1); break\n",
    "            dcg += nd; idcg += 1.0\n",
    "        out[f\"recall@{K}\"]=hits/max(1,tot)\n",
    "        out[f\"ndcg@{K}\"]=dcg/max(1.0,idcg)\n",
    "    return out\n",
    "\n",
    "def union_queries_items(runs_oof: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º union –ø–æ (query_id,item_id), –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º score_<rid> –∏ label\n",
    "    keys = list(runs_oof.keys())\n",
    "    # —Å—Ç–∞—Ä—Ç: –ø–µ—Ä–≤—ã–π\n",
    "    rid0 = keys[0]\n",
    "    base = runs_oof[rid0][[\"query_id\",\"item_id\"]].drop_duplicates().copy()\n",
    "    for rid in keys[1:]:\n",
    "        base = base.merge(runs_oof[rid][[\"query_id\",\"item_id\"]].drop_duplicates(), on=[\"query_id\",\"item_id\"], how=\"outer\")\n",
    "    # label –≤–æ–∑—å–º—ë–º –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –Ω–æ –æ–Ω —É –≤—Å–µ—Ö –æ–¥–∏–Ω–∞–∫–æ–≤ (label 0/1 –¥–ª—è –ø–∞—Ä—ã)\n",
    "    lab = runs_oof[rid0][[\"query_id\",\"item_id\"]].merge(\n",
    "        RUNS[rid0][\"oof\"][ [\"query_id\",\"item_id\",\"label\"] ],\n",
    "        on=[\"query_id\",\"item_id\"], how=\"left\"\n",
    "    )[\"label\"]\n",
    "    base[\"label\"] = lab.fillna(0).astype(\"int8\")\n",
    "    # –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º —Å–∫–æ—Ä—ã\n",
    "    for rid in keys:\n",
    "        base = base.merge(runs_oof[rid][[\"query_id\",\"item_id\",\"score\"]].rename(columns={\"score\":f\"s_{rid}\"}),\n",
    "                          on=[\"query_id\",\"item_id\"], how=\"left\")\n",
    "    return base\n",
    "\n",
    "def compute_rrf(df_scores: pd.DataFrame, rids: List[str], rrf_k:int=60):\n",
    "    # –î–ª—è RRF —Å—á–∏—Ç–∞–µ–º —Ä–∞–Ω–≥–∏ –ø–æ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ (—á–µ–º –º–µ–Ω—å—à–µ ‚Äî —Ç–µ–º –ª—É—á—à–µ), –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—é —Å—Ç–∞–≤–∏–º –±–æ–ª—å—à–æ–π —Ä–∞–Ω–≥\n",
    "    df = df_scores.copy()\n",
    "    for rid in rids:\n",
    "        col = f\"s_{rid}\"\n",
    "        # —Ä–∞–Ω–≥–∏ –≤–Ω—É—Ç—Ä–∏ query; –µ—Å–ª–∏ NaN ‚Äî –ø–æ—Å—Ç–∞–≤–∏–º –ø–ª–æ—Ö–æ–π —Ä–∞–Ω–≥ = max_rank + 1000\n",
    "        df = df.sort_values([\"query_id\", col], ascending=[True, False])\n",
    "        df[f\"rk_{rid}\"] = df.groupby(\"query_id\")[col].rank(ascending=False, method=\"first\")\n",
    "    # max rank per query\n",
    "    max_rk = df.groupby(\"query_id\")[[f\"rk_{rid}\" for rid in rids]].max().max(axis=1)\n",
    "    max_rk = max_rk.rename(\"maxrk\")\n",
    "    df = df.merge(max_rk, left_on=\"query_id\", right_index=True, how=\"left\")\n",
    "    score = np.zeros(len(df), dtype=\"float32\")\n",
    "    for rid in rids:\n",
    "        rk = df[f\"rk_{rid}\"].values\n",
    "        rk = np.where(np.isnan(df[f\"s_{rid}\"].values), df[\"maxrk\"].values + 1000.0, rk)\n",
    "        score += 1.0/(rrf_k + rk)\n",
    "    return score\n",
    "\n",
    "def compute_borda(df_scores: pd.DataFrame, rids: List[str]):\n",
    "    df = df_scores.copy()\n",
    "    score = np.zeros(len(df), dtype=\"float32\")\n",
    "    for rid in rids:\n",
    "        col = f\"s_{rid}\"\n",
    "        df = df.sort_values([\"query_id\", col], ascending=[True, False])\n",
    "        rk = df.groupby(\"query_id\")[col].rank(ascending=False, method=\"first\")\n",
    "        # Borda: (K + 1 - rank)\n",
    "        K = df.groupby(\"query_id\").size().rename(\"K\")\n",
    "        df = df.merge(K, left_on=\"query_id\", right_index=True, how=\"left\")\n",
    "        part = (df[\"K\"] + 1 - rk).values.astype(\"float32\")\n",
    "        part[np.isnan(df[col].values)] = 0.0\n",
    "        score += part\n",
    "        df = df.drop(columns=[\"K\"])\n",
    "    return score\n",
    "\n",
    "def compute_combsum(df_scores: pd.DataFrame, rids: List[str]):\n",
    "    score = np.zeros(len(df_scores), dtype=\"float32\")\n",
    "    for rid in rids:\n",
    "        col = f\"s_{rid}\"\n",
    "        v = df_scores[col].fillna(0.0).values\n",
    "        score += v.astype(\"float32\")\n",
    "    return score\n",
    "\n",
    "def compute_combmnz(df_scores: pd.DataFrame, rids: List[str]):\n",
    "    score = compute_combsum(df_scores, rids)\n",
    "    present = np.zeros(len(df_scores), dtype=\"int32\")\n",
    "    for rid in rids:\n",
    "        present += (~df_scores[f\"s_{rid}\"].isna()).astype(\"int32\").values\n",
    "    return (score * present).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd982d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_simple = W.Button(description=\"–û—Ü–µ–Ω–∏—Ç—å RRF/Borda/Comb* –Ω–∞ OOF\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "out_simple = W.Output()\n",
    "\n",
    "EVALS = dict(simple_table=None, union_oof=None, rids=None, per_method_scores=None)\n",
    "\n",
    "def on_simple(_):\n",
    "    with out_simple:\n",
    "        clear_output()\n",
    "        if not NORMED:\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–π/–∫–∞–ª–∏–±—Ä—É–π OOF.\")\n",
    "            return\n",
    "        # Union OOF –ø–æ runs\n",
    "        rids = list(NORMED.keys())\n",
    "        runs_oof = {rid: NORMED[rid][\"oof\"][ [\"query_id\",\"item_id\",\"score\"] ] for rid in rids}\n",
    "        union = union_queries_items(runs_oof)\n",
    "        EVALS[\"union_oof\"] = union\n",
    "        EVALS[\"rids\"] = rids\n",
    "        y = union[\"label\"].values\n",
    "        # –°—á–∏—Ç–∞–µ–º —Ñ—å—é–∂–Ω—ã\n",
    "        rows=[]; per_method={}\n",
    "        if BLEND[\"use_rrf\"]:\n",
    "            s = compute_rrf(union, rids, BLEND[\"rrf_k\"])\n",
    "            m = recall_ndcg_at_k(union[\"query_id\"].values, y, s, ks=EVAL[\"KS\"])\n",
    "            rows.append(dict(method=f\"RRF(k={BLEND['rrf_k']})\", **m)); per_method[\"RRF\"]=s\n",
    "        if BLEND[\"use_borda\"]:\n",
    "            s = compute_borda(union, rids)\n",
    "            m = recall_ndcg_at_k(union[\"query_id\"].values, y, s, ks=EVAL[\"KS\"])\n",
    "            rows.append(dict(method=\"Borda\", **m)); per_method[\"Borda\"]=s\n",
    "        if BLEND[\"use_combsum\"]:\n",
    "            s = compute_combsum(union, rids)\n",
    "            m = recall_ndcg_at_k(union[\"query_id\"].values, y, s, ks=EVAL[\"KS\"])\n",
    "            rows.append(dict(method=\"CombSUM\", **m)); per_method[\"CombSUM\"]=s\n",
    "        if BLEND[\"use_combmnz\"]:\n",
    "            s = compute_combmnz(union, rids)\n",
    "            m = recall_ndcg_at_k(union[\"query_id\"].values, y, s, ks=EVAL[\"KS\"])\n",
    "            rows.append(dict(method=\"CombMNZ\", **m)); per_method[\"CombMNZ\"]=s\n",
    "        df = pd.DataFrame(rows).sort_values(f\"ndcg@{EVAL['MAIN_K']}\", ascending=False) if rows else pd.DataFrame()\n",
    "        EVALS[\"simple_table\"]=df; EVALS[\"per_method_scores\"]=per_method\n",
    "        display(df if len(df) else \"–ù–µ—Ç –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö —Ñ—å—é–∂–Ω–æ–≤\")\n",
    "\n",
    "btn_simple.on_click(on_simple)\n",
    "W.VBox([btn_simple, out_simple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_weight = W.Button(description=\"–ü–æ–∏—Å–∫ –≤–µ—Å–æ–≤ (OOF)\", button_style=\"warning\", layout=BTN_LAYOUT)\n",
    "out_weight = W.Output()\n",
    "\n",
    "WEIGHTS = dict(best=None, table=None)\n",
    "\n",
    "def _init_weights(n, nonneg=True, sum_to_one=True):\n",
    "    w = np.random.rand(n).astype(\"float32\")\n",
    "    if not nonneg:\n",
    "        w = (w - 0.5)*2.0\n",
    "    if sum_to_one and nonneg:\n",
    "        w = w/ (w.sum()+1e-9)\n",
    "    return w\n",
    "\n",
    "def _project_weights(w, nonneg=True, sum_to_one=True):\n",
    "    v = w.copy()\n",
    "    if nonneg:\n",
    "        v = np.maximum(v, 0.0)\n",
    "    if sum_to_one and nonneg:\n",
    "        s = v.sum()\n",
    "        if s>0: v = v/s\n",
    "        else: v = np.ones_like(v)/len(v)\n",
    "    return v\n",
    "\n",
    "def on_weight(_):\n",
    "    with out_weight:\n",
    "        clear_output()\n",
    "        if not EVALS.get(\"union_oof\"):\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ –ø–æ—Å—á–∏—Ç–∞–π –ø—Ä–æ—Å—Ç—ã–µ —Ñ—å—é–∂–Ω—ã (–æ–Ω–∏ –≥–æ—Ç–æ–≤—è—Ç union OOF).\")\n",
    "            return\n",
    "        union = EVALS[\"union_oof\"]\n",
    "        rids  = EVALS[\"rids\"]\n",
    "        y = union[\"label\"].values\n",
    "        X = np.vstack([union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float32\") for rid in rids]).T  # [N, M]\n",
    "        M = X.shape[1]\n",
    "        best_w=None; best_score=-1; trials=BLEND[\"weight_trials\"]\n",
    "        mainK = EVAL[\"MAIN_K\"]\n",
    "        for t in range(trials):\n",
    "            if t==0:\n",
    "                w = np.ones(M, dtype=\"float32\")/M\n",
    "            else:\n",
    "                # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω–æ–µ –≤—Å—Ç—Ä—è—Ö–∏–≤–∞–Ω–∏–µ: —Å–ª–µ–≥–∫–∞ –≤–∞—Ä—å–∏—Ä—É–µ–º –ª—É—á—à—É—é —Ç–æ—á–∫—É\n",
    "                if best_w is not None and np.random.rand()<0.7:\n",
    "                    w = best_w + 0.1*np.random.randn(M).astype(\"float32\")\n",
    "                else:\n",
    "                    w = _init_weights(M, BLEND[\"weight_nonneg\"], BLEND[\"weight_sum_to_one\"])\n",
    "            w = _project_weights(w, BLEND[\"weight_nonneg\"], BLEND[\"weight_sum_to_one\"])\n",
    "            s = X.dot(w)\n",
    "            m = recall_ndcg_at_k(union[\"query_id\"].values, y, s, ks=[mainK])[f\"ndcg@{mainK}\"]\n",
    "            if m>best_score:\n",
    "                best_score=m; best_w=w.copy()\n",
    "        WEIGHTS[\"best\"] = dict(weights={rid: float(best_w[i]) for i,rid in enumerate(rids)}, ndcg_at_main=float(best_score))\n",
    "        print(\"–õ—É—á—à–∏–µ –≤–µ—Å–∞:\", WEIGHTS[\"best\"])\n",
    "\n",
    "btn_weight.on_click(on_weight)\n",
    "W.VBox([btn_weight, out_weight])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_meta = W.Button(description=\"Level-2 (Ridge) –Ω–∞ OOF\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_meta = W.Output()\n",
    "\n",
    "META = dict(oof_scores=None, coefs=None, alpha=None, metrics=None)\n",
    "\n",
    "def on_meta(_):\n",
    "    with out_meta:\n",
    "        clear_output()\n",
    "        if not EVALS.get(\"union_oof\"):\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤—å union OOF.\")\n",
    "            return\n",
    "        if Ridge is None or KFold is None:\n",
    "            print(\"sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (Ridge/KFold) ‚Äî meta –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\"); return\n",
    "        union = EVALS[\"union_oof\"]; rids=EVALS[\"rids\"]; y = union[\"label\"].values.astype(int)\n",
    "        X = np.vstack([union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float32\") for rid in rids]).T\n",
    "        q = union[\"query_id\"].values\n",
    "        uniq_q = np.unique(q)\n",
    "        kf = KFold(n_splits=BLEND[\"meta_splits\"], shuffle=True, random_state=STATE[\"RANDOM_SEED\"])\n",
    "        alphas = [1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "        best_alpha=None; best_score=-1.0; best_oof=None; best_coefs=None\n",
    "        for a in alphas:\n",
    "            oof_pred = np.zeros(len(X), dtype=\"float32\")\n",
    "            coefs_fold=[]\n",
    "            for tr_q, va_q in kf.split(uniq_q):\n",
    "                tr_mask = np.isin(q, uniq_q[tr_q]); va_mask = np.isin(q, uniq_q[va_q])\n",
    "                model = Ridge(alpha=a, fit_intercept=True, random_state=STATE[\"RANDOM_SEED\"])\n",
    "                model.fit(X[tr_mask], y[tr_mask])\n",
    "                oof_pred[va_mask] = model.predict(X[va_mask]).astype(\"float32\")\n",
    "                coefs_fold.append(model.coef_.copy())\n",
    "            m = recall_ndcg_at_k(q, y, oof_pred, ks=[EVAL[\"MAIN_K\"]])[f\"ndcg@{EVAL['MAIN_K']}\"]\n",
    "            if m>best_score:\n",
    "                best_score=m; best_alpha=a; best_oof=oof_pred; best_coefs=np.mean(coefs_fold, axis=0)\n",
    "        META[\"oof_scores\"]=best_oof\n",
    "        META[\"coefs\"]={rid: float(best_coefs[i]) for i,rid in enumerate(rids)}\n",
    "        META[\"alpha\"]=float(best_alpha)\n",
    "        META[\"metrics\"]=recall_ndcg_at_k(q, y, best_oof, ks=EVAL[\"KS\"])\n",
    "        print(\"Meta-Ridge:\", dict(alpha=META[\"alpha\"], **{k:round(v,4) for k,v in META[\"metrics\"].items()}))\n",
    "        print(\"–ö–æ—ç—Ñ—ã:\", META[\"coefs\"])\n",
    "\n",
    "btn_meta.on_click(on_meta)\n",
    "W.VBox([btn_meta, out_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_compare = W.Button(description=\"–°–æ–±—Ä–∞—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –≤—ã–±—Ä–∞—Ç—å BEST\", button_style=\"primary\", layout=BTN_LAYOUT)\n",
    "out_compare = W.Output()\n",
    "\n",
    "BEST = dict(name=None, kind=None, params=None, oof_metrics=None)\n",
    "\n",
    "def on_compare(_):\n",
    "    with out_compare:\n",
    "        clear_output()\n",
    "        if not EVALS.get(\"union_oof\"):\n",
    "            print(\"–ù–µ—Ç union OOF.\")\n",
    "            return\n",
    "        union = EVALS[\"union_oof\"]; y = union[\"label\"].values; q = union[\"query_id\"].values\n",
    "        rows=[]\n",
    "        # –ø—Ä–æ—Å—Ç—ã–µ\n",
    "        if EVALS.get(\"per_method_scores\"):\n",
    "            for name, s in EVALS[\"per_method_scores\"].items():\n",
    "                m = recall_ndcg_at_k(q, y, s, ks=EVAL[\"KS\"])\n",
    "                rows.append(dict(method=name, **m))\n",
    "        # –≤–µ—Å–∞\n",
    "        if WEIGHTS.get(\"best\"):\n",
    "            rids = EVALS[\"rids\"]\n",
    "            w = np.array([WEIGHTS[\"best\"][\"weights\"][rid] for rid in rids], dtype=\"float32\")\n",
    "            X = np.vstack([union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float32\") for rid in rids]).T\n",
    "            s = X.dot(w)\n",
    "            m = recall_ndcg_at_k(q, y, s, ks=EVAL[\"KS\"])\n",
    "            rows.append(dict(method=\"WeightSearch\", **m))\n",
    "        # meta\n",
    "        if META.get(\"oof_scores\") is not None:\n",
    "            m = META[\"metrics\"]\n",
    "            rows.append(dict(method=\"Level2_Ridge\", **m))\n",
    "        df = pd.DataFrame(rows).sort_values(f\"ndcg@{EVAL['MAIN_K']}\", ascending=False) if rows else pd.DataFrame()\n",
    "        display(df if len(df) else \"–ù–µ—Ç –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\")\n",
    "        if len(df):\n",
    "            top = df.iloc[0]\n",
    "            BEST[\"name\"]=str(top[\"method\"])\n",
    "            BEST[\"kind\"]=BEST[\"name\"]\n",
    "            # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "            if BEST[\"name\"].startswith(\"RRF\"):\n",
    "                BEST[\"params\"]=dict(rrf_k=BLEND[\"rrf_k\"])\n",
    "            elif BEST[\"name\"]==\"WeightSearch\":\n",
    "                BEST[\"params\"]=WEIGHTS[\"best\"][\"weights\"]\n",
    "            elif BEST[\"name\"]==\"Level2_Ridge\":\n",
    "                BEST[\"params\"]=dict(alpha=META[\"alpha\"], coefs=META[\"coefs\"])\n",
    "            else:\n",
    "                BEST[\"params\"]={}\n",
    "            BEST[\"oof_metrics\"]=top.to_dict()\n",
    "            print(\"\n",
    "‚Üí BEST:\", BEST[\"name\"], \"| ndcg@{} = {:.5f}\".format(EVAL[\"MAIN_K\"], top[f\"ndcg@{EVAL['MAIN_K']}\"]))\n",
    "\n",
    "btn_compare.on_click(on_compare)\n",
    "W.VBox([btn_compare, out_compare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_slices = W.Button(description=\"OOF —Å—Ä–µ–∑—ã –¥–ª—è BEST\", button_style=\"\", layout=BTN_LAYOUT)\n",
    "out_slices = W.Output()\n",
    "\n",
    "SLICES = dict(result=None)\n",
    "\n",
    "def on_slices(_):\n",
    "    with out_slices:\n",
    "        clear_output()\n",
    "        if not BEST.get(\"name\"):\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ BEST (—Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞).\")\n",
    "            return\n",
    "        union = EVALS[\"union_oof\"]; y = union[\"label\"].values; q = union[\"query_id\"].values\n",
    "        # –ø–æ–ª—É—á–∞–µ–º scores –¥–ª—è BEST\n",
    "        if BEST[\"name\"] in (EVALS.get(\"per_method_scores\") or {}):\n",
    "            s = EVALS[\"per_method_scores\"][BEST[\"name\"]]\n",
    "        elif BEST[\"name\"]==\"WeightSearch\":\n",
    "            rids = EVALS[\"rids\"]\n",
    "            w = np.array([WEIGHTS[\"best\"][\"weights\"][rid] for rid in rids], dtype=\"float32\")\n",
    "            X = np.vstack([union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float32\") for rid in rids]).T\n",
    "            s = X.dot(w)\n",
    "        elif BEST[\"name\"]==\"Level2_Ridge\":\n",
    "            s = META[\"oof_scores\"]\n",
    "        else:\n",
    "            print(\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π BEST.\"); return\n",
    "\n",
    "        # –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º —Å—Ä–µ–∑—ã (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏–∑ 03_ranker_lab –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–µ–ª—å–∑—è ‚Äî –ø–æ—ç—Ç–æ–º—É —Å–º–æ—Ç—Ä–∏–º —Ñ–ª–∞–≥–∏ –≤ union –Ω–µ—Ç.\n",
    "        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–æ–∫—Å–∏ (–µ—Å–ª–∏ –≤ union –µ—Å—Ç—å is_cold_item/is_cold_user ‚Äî —Å–∫–æ—Ä–µ–µ –Ω–µ—Ç).\n",
    "        # –ó–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–µ–¥–µ–º –±–∞–∑–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É + —Å–ø–∏—Å–æ–∫ worst-queries –±–µ–∑ —Ö–∏—Ç–∞:\n",
    "        base = recall_ndcg_at_k(q, y, s, ks=[EVAL[\"MAIN_K\"]])\n",
    "        print(\"BEST OOF:\", base)\n",
    "        nohit = pd.DataFrame({\"q\":q, \"y\":y, \"s\":s}).sort_values([\"q\",\"s\"], ascending=[True,False])                 .groupby(\"q\").head(EVAL[\"MAIN_K\"]).groupby(\"q\")[\"y\"].max().reset_index()\n",
    "        miss = nohit[nohit[\"y\"]==0][\"q\"].values\n",
    "        print(f\"Queries –±–µ–∑ —Ö–∏—Ç–∞ @ {EVAL['MAIN_K']}: {len(miss)}\")\n",
    "        SLICES[\"result\"]=dict(main=base, nohit_count=int(len(miss)))\n",
    "\n",
    "btn_slices.on_click(on_slices)\n",
    "W.VBox([btn_slices, out_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4365623",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_boot = W.Button(description=\"–ë—É—Ç—Å—Ç—Ä—ç–ø —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\", button_style=\"info\", layout=BTN_LAYOUT)\n",
    "out_boot = W.Output()\n",
    "\n",
    "STAB = dict(ci=None, dist=None)\n",
    "\n",
    "def _bootstrap_ndcg(q, y, s, B=200, K=20, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    uq = np.unique(q)\n",
    "    vals=[]\n",
    "    for _ in range(B):\n",
    "        sample_q = rng.choice(uq, size=len(uq), replace=True)\n",
    "        mask = np.isin(q, sample_q)\n",
    "        m = recall_ndcg_at_k(q[mask], y[mask], s[mask], ks=[K])[f\"ndcg@{K}\"]\n",
    "        vals.append(m)\n",
    "    vals = np.array(vals, dtype=\"float64\")\n",
    "    lo, hi = np.percentile(vals, [2.5, 97.5])\n",
    "    return dict(mean=float(vals.mean()), ci=[float(lo), float(hi)], samples=vals)\n",
    "\n",
    "def on_boot(_):\n",
    "    with out_boot:\n",
    "        clear_output()\n",
    "        if not BEST.get(\"name\"):\n",
    "            print(\"–ù–µ—Ç BEST.\")\n",
    "            return\n",
    "        union = EVALS[\"union_oof\"]; y = union[\"label\"].values; q = union[\"query_id\"].values\n",
    "        # scores –¥–ª—è BEST\n",
    "        if BEST[\"name\"] in (EVALS.get(\"per_method_scores\") or {}):\n",
    "            s = EVALS[\"per_method_scores\"][BEST[\"name\"]]\n",
    "        elif BEST[\"name\"]==\"WeightSearch\":\n",
    "            rids = EVALS[\"rids\"]\n",
    "            w = np.array([WEIGHTS[\"best\"][\"weights\"][rid] for rid in rids], dtype=\"float32\")\n",
    "            X = np.vstack([union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float32\") for rid in rids]).T\n",
    "            s = X.dot(w)\n",
    "        elif BEST[\"name\"]==\"Level2_Ridge\":\n",
    "            s = META[\"oof_scores\"]\n",
    "        else:\n",
    "            print(\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π BEST.\"); return\n",
    "        res = _bootstrap_ndcg(q, y, s, B=200, K=EVAL[\"MAIN_K\"], seed=STATE[\"RANDOM_SEED\"])\n",
    "        STAB.update(ci=res[\"ci\"], dist=res[\"samples\"])\n",
    "        print(f\"–ë—É—Ç—Å—Ç—Ä—ç–ø ndcg@{EVAL['MAIN_K']}: mean={res['mean']:.5f}, 95% CI={res['ci']}\")\n",
    "\n",
    "btn_boot.on_click(on_boot)\n",
    "W.VBox([btn_boot, out_boot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_infer = W.Button(description=\"–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ TEST (BEST) –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\", button_style=\"danger\", layout=BTN_LAYOUT)\n",
    "out_infer = W.Output()\n",
    "\n",
    "FILES = dict(ens_dir=None, ranked=None, scores=None)\n",
    "\n",
    "def _build_test_union() -> pd.DataFrame:\n",
    "    # Union test –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º runs: –≤–µ—Ä–Ω—ë–º (query_id,item_id, s_<rid>...)\n",
    "    rids = list(NORMED.keys())\n",
    "    base=None\n",
    "    for rid in rids:\n",
    "        df = NORMED[rid][\"test\"][ [\"query_id\",\"item_id\",\"score\"] ].rename(columns={\"score\":f\"s_{rid}\"})\n",
    "        base = df if base is None else base.merge(df, on=[\"query_id\",\"item_id\"], how=\"outer\")\n",
    "    return base\n",
    "\n",
    "def on_infer(_):\n",
    "    with out_infer:\n",
    "        clear_output()\n",
    "        if not BEST.get(\"name\"):\n",
    "            print(\"–í—ã–±–µ—Ä–∏ BEST.\")\n",
    "            return\n",
    "        A = art_paths(STATE[\"DATASET_ID\"], STATE[\"PROFILE_PATH\"])\n",
    "        ens_id = f\"{now_tag()}_{BEST['name'].lower()}\"\n",
    "        ens_dir = A[\"ens\"]/ens_id\n",
    "        ens_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        test_union = _build_test_union()\n",
    "        rids = list(NORMED.keys())\n",
    "        # —Å–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Å–∫–æ—Ä—ã\n",
    "        if BEST[\"name\"].startswith(\"RRF\"):\n",
    "            # –¥–ª—è RRF –Ω—É–∂–Ω—ã —Ä–∞–Ω–≥–∏ –ø–æ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏\n",
    "            tmp = test_union.copy()\n",
    "            for rid in rids:\n",
    "                col = f\"s_{rid}\"\n",
    "                tmp = tmp.sort_values([\"query_id\", col], ascending=[True, False])\n",
    "                tmp[f\"rk_{rid}\"] = tmp.groupby(\"query_id\")[col].rank(ascending=False, method=\"first\")\n",
    "            max_rk = tmp.groupby(\"query_id\")[[f\"rk_{rid}\" for rid in rids]].max().max(axis=1).rename(\"maxrk\")\n",
    "            tmp = tmp.merge(max_rk, left_on=\"query_id\", right_index=True, how=\"left\")\n",
    "            s = np.zeros(len(tmp), dtype=\"float32\")\n",
    "            for rid in rids:\n",
    "                rk = tmp[f\"rk_{rid}\"].values\n",
    "                rk = np.where(np.isnan(tmp[f\"s_{rid}\"].values), tmp[\"maxrk\"].values + 1000.0, rk)\n",
    "                s += 1.0/(BLEND[\"rrf_k\"] + rk)\n",
    "            scores = s\n",
    "            out = tmp[[\"query_id\",\"item_id\"]].copy()\n",
    "        elif BEST[\"name\"]==\"Borda\":\n",
    "            tmp = test_union.copy()\n",
    "            s = np.zeros(len(tmp), dtype=\"float32\")\n",
    "            for rid in rids:\n",
    "                col = f\"s_{rid}\"\n",
    "                tmp = tmp.sort_values([\"query_id\", col], ascending=[True, False])\n",
    "                rk = tmp.groupby(\"query_id\")[col].rank(ascending=False, method=\"first\")\n",
    "                K = tmp.groupby(\"query_id\").size().rename(\"K\")\n",
    "                tmp = tmp.merge(K, left_on=\"query_id\", right_index=True, how=\"left\")\n",
    "                part = (tmp[\"K\"] + 1 - rk).values.astype(\"float32\")\n",
    "                part[np.isnan(tmp[col].values)] = 0.0\n",
    "                s += part\n",
    "                tmp = tmp.drop(columns=[\"K\"])\n",
    "            scores = s\n",
    "            out = tmp[[\"query_id\",\"item_id\"]].copy()\n",
    "        elif BEST[\"name\"]==\"CombSUM\":\n",
    "            out = test_union[[\"query_id\",\"item_id\"]].copy()\n",
    "            scores = compute_combsum(test_union, rids)\n",
    "        elif BEST[\"name\"]==\"CombMNZ\":\n",
    "            out = test_union[[\"query_id\",\"item_id\"]].copy()\n",
    "            scores = compute_combmnz(test_union, rids)\n",
    "        elif BEST[\"name\"]==\"WeightSearch\":\n",
    "            w = np.array([WEIGHTS[\"best\"][\"weights\"][rid] for rid in rids], dtype=\"float32\")\n",
    "            X = np.vstack([test_union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float32\") for rid in rids]).T\n",
    "            scores = X.dot(w)\n",
    "            out = test_union[[\"query_id\",\"item_id\"]].copy()\n",
    "        elif BEST[\"name\"]==\"Level2_Ridge\":\n",
    "            coefs = np.array([META[\"coefs\"][rid] for rid in rids], dtype=\"float64\")\n",
    "            X = np.vstack([test_union[f\"s_{rid}\"].fillna(0.0).values.astype(\"float64\") for rid in rids]).T\n",
    "            scores = X.dot(coefs)\n",
    "            out = test_union[[\"query_id\",\"item_id\"]].copy()\n",
    "        else:\n",
    "            print(\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π BEST\"); return\n",
    "\n",
    "        out[\"score\"]=scores.astype(\"float32\")\n",
    "        out = out.sort_values([\"query_id\",\"score\"], ascending=[True,False]).groupby(\"query_id\").head(STATE[\"K_OUT\"]).reset_index(drop=True)\n",
    "        out[\"rank\"] = out.groupby(\"query_id\")[\"score\"].rank(ascending=False, method=\"first\").astype(\"int32\")\n",
    "\n",
    "        out.to_parquet(ens_dir/\"ranked.parquet\", index=False)\n",
    "        test_union.assign(score_blend=scores).to_parquet(ens_dir/\"scores_blend.parquet\", index=False)\n",
    "\n",
    "        FILES.update(ens_dir=str(ens_dir), ranked=str(ens_dir/\"ranked.parquet\"), scores=str(ens_dir/\"scores_blend.parquet\"))\n",
    "\n",
    "        print(\"‚úì saved:\", ens_dir/\"ranked.parquet\")\n",
    "\n",
    "btn_infer.on_click(on_infer)\n",
    "W.VBox([btn_infer, out_infer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_save = W.Button(description=\"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥/–º–µ—Ç—Ä–∏–∫–∏/—Ä–µ–ø–æ—Ä—Ç\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_save = W.Output()\n",
    "\n",
    "def on_save(_):\n",
    "    with out_save:\n",
    "        clear_output()\n",
    "        if not FILES.get(\"ens_dir\"):\n",
    "            print(\"–°–Ω–∞—á–∞–ª–∞ —Å–¥–µ–ª–∞–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ test.\")\n",
    "            return\n",
    "        ens_dir = Path(FILES[\"ens_dir\"])\n",
    "        # blender_config\n",
    "        cfg = dict(\n",
    "            dataset_id=STATE[\"DATASET_ID\"],\n",
    "            profile=STATE[\"PROFILE_PATH\"],\n",
    "            runs=list(NORMED.keys()),\n",
    "            normalize=NORM[\"method\"],\n",
    "            calibrate=NORM[\"calibrate\"],\n",
    "            method=BEST[\"name\"],\n",
    "            params=BEST.get(\"params\", {}),\n",
    "            K_OUT=STATE[\"K_OUT\"]\n",
    "        )\n",
    "        save_json(ens_dir/\"blender_config.json\", cfg)\n",
    "        # oof_metrics: —Å–æ–±–µ—Ä—ë–º —Å–≤–æ–¥–Ω—ã–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è–º, –µ—Å–ª–∏ –±—ã–ª–∏\n",
    "        if out_compare.outputs:\n",
    "            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø–µ—Ä–µ—Å–æ–±–µ—Ä—ë–º —Ç–∞–±–ª–∏—Ü—É –∏–∑ BEST[\"oof_metrics\"] –∏ simple/weight/meta, –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "            rows=[]\n",
    "            if EVALS.get(\"simple_table\") is not None and len(EVALS[\"simple_table\"]):\n",
    "                rows += EVALS[\"simple_table\"].to_dict(orient=\"records\")\n",
    "            if WEIGHTS.get(\"best\"):\n",
    "                rows.append(dict(method=\"WeightSearch\", **{k:v for k,v in WEIGHTS[\"best\"].items() if k.startswith(\"ndcg@\")==False}))\n",
    "            if META.get(\"metrics\"):\n",
    "                rows.append(dict(method=\"Level2_Ridge\", **META[\"metrics\"]))\n",
    "            save_json(ens_dir/\"oof_metrics.json\", dict(rows=rows, best=BEST[\"oof_metrics\"]))\n",
    "        # slices\n",
    "        if SLICES.get(\"result\"):\n",
    "            save_json(ens_dir/\"slices.json\", SLICES[\"result\"])\n",
    "        # stability\n",
    "        if STAB.get(\"ci\") is not None:\n",
    "            save_json(ens_dir/\"stability.json\", dict(ci=STAB[\"ci\"]))\n",
    "        # report\n",
    "        rep = dict(\n",
    "            dataset_id=STATE[\"DATASET_ID\"],\n",
    "            profile=STATE[\"PROFILE_PATH\"],\n",
    "            ens_id=ens_dir.name,\n",
    "            best=BEST,\n",
    "            files=dict(ranked=FILES.get(\"ranked\"), scores=FILES.get(\"scores\")),\n",
    "            saved_at=datetime.utcnow().isoformat()+\"Z\"\n",
    "        )\n",
    "        save_json(ens_dir/\"report.json\", rep)\n",
    "        print(\"‚úì saved config & report ‚Üí\", ens_dir)\n",
    "\n",
    "btn_save.on_click(on_save)\n",
    "W.VBox([btn_save, out_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_panic = W.Button(description=\"‚ö° PANIC: zscore + RRF + –∏–Ω—Ñ–µ—Ä–µ–Ω—Å\", button_style=\"danger\", layout=BTN_LAYOUT)\n",
    "out_panic = W.Output()\n",
    "\n",
    "def on_panic(_):\n",
    "    with out_panic:\n",
    "        clear_output()\n",
    "        # –ø—Ä–∏–º–µ–Ω–∏–º zscore_query+none, RRF(k=60)\n",
    "        NORM[\"method\"]=\"zscore_query\"; NORM[\"calibrate\"]=\"none\"\n",
    "        BLEND.update(use_rrf=True, rrf_k=60, use_borda=False, use_combsum=False, use_combmnz=False, use_weight_search=False, use_meta_l2=False)\n",
    "        on_norm(None)\n",
    "        on_simple(None)\n",
    "        # –≤—ã–±–µ—Ä–µ–º RRF –∫–∞–∫ BEST\n",
    "        if \"RRF\" in (EVALS.get(\"per_method_scores\") or {}):\n",
    "            BEST.update(name=\"RRF\", kind=\"RRF\", params=dict(rrf_k=BLEND[\"rrf_k\"]), oof_metrics=EVALS[\"simple_table\"].query(\"method.str.contains('RRF')\", engine=\"python\").iloc[0].to_dict())\n",
    "            on_infer(None)\n",
    "            on_save(None)\n",
    "        else:\n",
    "            print(\"PANIC: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—á–∏—Ç–∞—Ç—å RRF (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö).\")\n",
    "\n",
    "btn_panic.on_click(on_panic)\n",
    "W.VBox([btn_panic, out_panic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_all = W.Button(description=\"üöÄ –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–æ–Ω –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\", button_style=\"success\", layout=BTN_LAYOUT)\n",
    "out_all = W.Output()\n",
    "\n",
    "def on_all(_):\n",
    "    with out_all:\n",
    "        clear_output()\n",
    "        try:\n",
    "            on_scan(None)\n",
    "            on_load(None)\n",
    "            on_norm(None)\n",
    "            on_simple(None)\n",
    "            on_weight(None)\n",
    "            on_meta(None)\n",
    "            on_compare(None)\n",
    "            on_slices(None)\n",
    "            on_boot(None)\n",
    "            on_infer(None)\n",
    "            on_save(None)\n",
    "            print(\"\n",
    "‚úì –ì–æ—Ç–æ–≤–æ.\")\n",
    "        except Exception as e:\n",
    "            print(\"–û–®–ò–ë–ö–ê:\", e)\n",
    "            raise\n",
    "\n",
    "btn_all.on_click(on_all)\n",
    "W.VBox([btn_all, out_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476e66b",
   "metadata": {},
   "source": [
    "### –ü–∞–º—è—Ç–∫–∞\n",
    "- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî **per-query** (`zscore/minmax/quantile`) ‚Üí –æ–ø—Ü. –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø–æ OOF (Platt/Isotonic).\n",
    "- –§—å—é–∂–Ω: RRF/Borda/Comb* –±—ã—Å—Ç—Ä—ã –∏ —Ä–æ–±–∞—Å—Ç–Ω—ã; –≤–µ—Å–æ–≤–æ–π –±–ª–µ–Ω–¥ —á–∞—â–µ –¥–∞—ë—Ç +0.002‚Ä¶0.01 ndcg@20; Level-2 (Ridge) ‚Äî –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–µ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω—ã.\n",
    "- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –±—É—Ç—Å—Ç—Ä—ç–ø –ø–æ queries (200 –≤—ã–±–æ—Ä–æ–∫) ‚Äî —Å–º–æ—Ç—Ä–∏ CI; –µ—Å–ª–∏ BEST ‚âà –æ–¥–∏–Ω–æ—á–Ω–æ–º—É —Ä–∞–Ω–∫–µ—Ä—É, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑—å–º–∏ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è.\n",
    "\n",
    "**–°—Ç–æ–ø-—Ñ–ª–∞–≥–∏**\n",
    "- ndcg@20 –±–ª–µ–Ω–¥–∞ ‚â§ –ª—É—á—à–µ–≥–æ —Å–æ–ª–æ (–∏–ª–∏ < +0.001) ‚Äî –Ω–µ —Å—Ç–æ–∏—Ç –±—Ä–∞—Ç—å –±–ª–µ–Ω–¥.\n",
    "- –£–≤–µ–ª–∏—á–∏–ª–∏—Å—å queries –±–µ–∑ —Ö–∏—Ç–∞ @K ‚Äî –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏ union/–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é.\n",
    "- –°–∏–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ ‚Äî –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∏–º–µ–Ω–Ω–æ –µ—ë.\n",
    "\n",
    "–î–∞–ª—å—à–µ: `05_submit.ipynb` ‚Äî —É–ø–∞–∫–æ–≤–∫–∞ —Å–∞–±–º–∏—Ç–∞."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
