{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ba87c7",
   "metadata": {},
   "source": [
    "# 00 — Retrieval Debug Sandbox\n",
    "\n",
    "Этот ноутбук — песочница для отладки ретрива:\n",
    "\n",
    "- проверить, как работают BM25 / dense / hybrid,\n",
    "- подобрать `k`, `alpha`, MMR и чанкеры,\n",
    "- глазами посмотреть, **что именно** возвращает ретривер для конкретных запросов.\n",
    "\n",
    "Идея: сначала подружиться с корпусом и ретривом, а уже потом строить полноценный RAG-пайплайн.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38f48b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Импорты основных библиотек ===\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Если хочешь использовать pandas для красивых табличек\n",
    "import pandas as pd\n",
    "\n",
    "# === Импорты из нашего RAG-пакета ===\n",
    "from rag.corpus import build_corpus_from_texts, Corpus\n",
    "from rag.chunkers import paragraph_chunker, char_chunker, token_chunker\n",
    "from rag.indices import build_bm25_index, build_dense_index, BM25Index, DenseIndex\n",
    "from rag.retrieval import (\n",
    "    bm25_candidates,\n",
    "    dense_candidates,\n",
    "    hybrid_candidates,\n",
    ")\n",
    "from rag.candidates import Candidate\n",
    "from rag.debug import (\n",
    "    summarize_candidates,\n",
    "    analyze_stage_transition,  # если понадобится смотреть до/после CE/MMR\n",
    ")\n",
    "\n",
    "# === (Опционально) эмбеддинг-модель ===\n",
    "# Тут оставляю TODO: под конкретную задачу подставишь нужную модель.\n",
    "# Частый вариант: sentence-transformers или huggingface transformers.\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "\n",
    "# === Пути к данным (TODO: поменяй под задачу) ===\n",
    "DATA_DIR = \"../data\"   # корень с данными задачи\n",
    "CORPUS_PATH = os.path.join(DATA_DIR, \"corpus.jsonl\")     # или .csv / что дадут\n",
    "QUESTIONS_PATH = os.path.join(DATA_DIR, \"questions.jsonl\")  # если есть вопросы\n",
    "\n",
    "# === Базовые параметры ===\n",
    "\n",
    "# Тип чанкера (можно переопределить ниже)\n",
    "DEFAULT_CHUNKER = paragraph_chunker\n",
    "\n",
    "# Сколько top-k документов смотреть глазами\n",
    "TOP_K_DEBUG = 5\n",
    "\n",
    "# Фиксируем seed, чтобы результаты были воспроизводимы\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b45223c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_corpus_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Пример загрузки корпуса из .jsonl.\n",
    "\n",
    "    Ожидаемый формат одной строки (пример):\n",
    "      {\n",
    "        \"id\": \"doc_1\",\n",
    "        \"title\": \"Название документа\",\n",
    "        \"text\": \"Полный текст документа\",\n",
    "        ... (любые другие поля)\n",
    "      }\n",
    "\n",
    "    TODO: ПОДГОНИ ЭТУ ФУНКЦИЮ ПОД РЕАЛЬНЫЙ ФОРМАТ ДАННЫХ.\n",
    "    Если корпус в .csv или в другой структуре — перепиши логику чтения.\n",
    "    \"\"\"\n",
    "    docs: List[Dict[str, Any]] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            docs.append(obj)\n",
    "    return docs\n",
    "\n",
    "\n",
    "# === Загружаем сырые документы ===\n",
    "raw_docs = load_corpus_jsonl(CORPUS_PATH)\n",
    "\n",
    "print(f\"Загружено документов: {len(raw_docs)}\")\n",
    "print(\"Пример документа:\")\n",
    "print(raw_docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa549a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Готовим списки для build_corpus_from_texts\n",
    "doc_texts = [d[\"text\"] for d in raw_docs]\n",
    "doc_ids = [str(d.get(\"id\", i)) for i, d in enumerate(raw_docs)]\n",
    "doc_titles = [d.get(\"title\", \"\") for d in raw_docs]\n",
    "doc_meta = [\n",
    "    {k: v for k, v in d.items() if k not in (\"id\", \"title\", \"text\")}\n",
    "    for d in raw_docs\n",
    "]\n",
    "\n",
    "# TODO: выбери чанкер для этой задачи\n",
    "#   - paragraph_chunker: хорошо, если текст уже разбит на абзацы\n",
    "#   - char_chunker: если текст с длинными абзацами/кодом\n",
    "#   - token_chunker: если важен контроль по токенам (чуть сложнее)\n",
    "CHUNKER = DEFAULT_CHUNKER\n",
    "\n",
    "corpus, chunk_texts = build_corpus_from_texts(\n",
    "    texts=doc_texts,\n",
    "    doc_ids=doc_ids,\n",
    "    titles=doc_titles,\n",
    "    meta_list=doc_meta,\n",
    "    chunker=CHUNKER,\n",
    ")\n",
    "\n",
    "print(\"=== Статистика корпуса ===\")\n",
    "print(f\"Документов: {len(corpus.documents)}\")\n",
    "print(f\"Чанков: {len(corpus.chunks)}\")\n",
    "\n",
    "# Покажем один пример чанка\n",
    "example_chunk = corpus.chunks[0]\n",
    "print(\"\\nПример чанка:\")\n",
    "print(f\"chunk_idx: {example_chunk.chunk_idx}\")\n",
    "print(f\"doc_id:    {example_chunk.doc_id}\")\n",
    "print(f\"start-end: {example_chunk.start_char}-{example_chunk.end_char}\")\n",
    "print(\"text:\", example_chunk.text[:300].replace(\"\\n\", \" \") + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df02749",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === BM25 индекс ===\n",
    "# build_bm25_index ожидает список текстов чанков (и, возможно, мету).\n",
    "# Мы уже получили chunk_texts из build_corpus_from_texts.\n",
    "\n",
    "bm25_index: BM25Index = build_bm25_index(\n",
    "    texts=chunk_texts,\n",
    "    meta=None,  # можно передать список метаданных по чанкам, если нужно\n",
    ")\n",
    "\n",
    "print(\"BM25Index готов.\")\n",
    "print(f\"Количество документов в BM25Index: {bm25_index.n_docs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5afbd50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Эмбеддинг-модель ===\n",
    "# TODO: подставь реальную модель эмбеддингов.\n",
    "# Частый кейс: sentence-transformers (если разрешены в окружении олимпиады).\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # TODO: поменяй при необходимости\n",
    "    print(f\"Загружаем эмбеддинг-модель: {EMB_MODEL_NAME}\")\n",
    "    emb_model = SentenceTransformer(EMB_MODEL_NAME)\n",
    "except ImportError:\n",
    "    emb_model = None\n",
    "    print(\"⚠️ sentence_transformers не установлен. \"\n",
    "          \"Либо поставь пакет, либо подставь свою модель/обёртку.\")\n",
    "\n",
    "# === Dense индекс ===\n",
    "\n",
    "if emb_model is not None:\n",
    "    dense_index: DenseIndex = build_dense_index(\n",
    "        texts=chunk_texts,\n",
    "        emb_model=emb_model,\n",
    "        batch_size=256,   # TODO: можно уменьшать/увеличивать в зависимости от VRAM\n",
    "        cache_dir=os.path.join(DATA_DIR, \"emb_cache\"),  # кэш эмбеддингов\n",
    "        model_id=EMB_MODEL_NAME,\n",
    "    )\n",
    "    print(\"DenseIndex готов.\")\n",
    "    print(f\"Форма матрицы эмбеддингов: {dense_index.embeddings.shape}\")\n",
    "else:\n",
    "    dense_index = None\n",
    "    print(\"DenseIndex не построен (нет emb_model). \"\n",
    "          \"Если нужен dense/hybrid — вернись и инициализируй модель.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f4f3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def show_chunk(corpus: Corpus, chunk_idx: int, max_chars: int = 400) -> None:\n",
    "    \"\"\"\n",
    "    Печатает один чанк с контекстом: doc_id, позиция, сам текст (обрезанный).\n",
    "    \"\"\"\n",
    "    if chunk_idx < 0 or chunk_idx >= len(corpus.chunks):\n",
    "        print(f\"chunk_idx {chunk_idx} вне диапазона.\")\n",
    "        return\n",
    "\n",
    "    ch = corpus.chunks[chunk_idx]\n",
    "    doc = corpus.get_document(ch.doc_id)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[chunk_idx={ch.chunk_idx}]  doc_id={ch.doc_id}\")\n",
    "    if doc is not None and getattr(doc, \"title\", None):\n",
    "        print(f\"title: {doc.title}\")\n",
    "    print(f\"start-end: {ch.start_char}-{ch.end_char}\")\n",
    "    print(\"-\" * 80)\n",
    "    text = ch.text.replace(\"\\n\", \" \")\n",
    "    if len(text) > max_chars:\n",
    "        text = text[:max_chars] + \"...\"\n",
    "    print(text)\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9566286",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_bm25(\n",
    "    query: str,\n",
    "    bm25_index: BM25Index,\n",
    "    k: int = TOP_K_DEBUG,\n",
    ") -> List[Candidate]:\n",
    "    return bm25_candidates(\n",
    "        query=query,\n",
    "        bm25_index=bm25_index,\n",
    "        top_k=k,\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieve_dense(\n",
    "    query: str,\n",
    "    dense_index: DenseIndex,\n",
    "    emb_model,\n",
    "    k: int = TOP_K_DEBUG,\n",
    ") -> List[Candidate]:\n",
    "    if dense_index is None or emb_model is None:\n",
    "        raise ValueError(\"DenseIndex или emb_model не инициализированы.\")\n",
    "    return dense_candidates(\n",
    "        query=query,\n",
    "        dense_index=dense_index,\n",
    "        emb_model=emb_model,\n",
    "        top_k=k,\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieve_hybrid(\n",
    "    query: str,\n",
    "    bm25_index: BM25Index,\n",
    "    dense_index: Optional[DenseIndex],\n",
    "    emb_model,\n",
    "    k_bm25: int = 50,\n",
    "    k_dense: int = 50,\n",
    "    k_hybrid: int = TOP_K_DEBUG,\n",
    "    alpha: float = 0.5,\n",
    ") -> List[Candidate]:\n",
    "    \"\"\"\n",
    "    Hybrid: alpha * bm25_score + (1 - alpha) * dense_score.\n",
    "\n",
    "    k_bm25, k_dense — сколько кандидатов брать с каждой стороны,\n",
    "    k_hybrid — сколько вернуть после объединения.\n",
    "    \"\"\"\n",
    "    if dense_index is None or emb_model is None:\n",
    "        raise ValueError(\"Для hybrid нужен и dense_index, и emb_model.\")\n",
    "\n",
    "    return hybrid_candidates(\n",
    "        query=query,\n",
    "        bm25_index=bm25_index,\n",
    "        dense_index=dense_index,\n",
    "        emb_model=emb_model,\n",
    "        top_k_bm25=k_bm25,\n",
    "        top_k_dense=k_dense,\n",
    "        top_k=k_hybrid,\n",
    "        alpha=alpha,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2875e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def print_candidates(\n",
    "    name: str,\n",
    "    cands: List[Candidate],\n",
    "    corpus: Corpus,\n",
    "    max_items: int = TOP_K_DEBUG,\n",
    "    max_chars: int = 300,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Печатает список кандидатов: rank, score, doc_id, кусочек текста.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name} (top {min(max_items, len(cands))}) ===\")\n",
    "    if not cands:\n",
    "        print(\"Пусто.\")\n",
    "        return\n",
    "\n",
    "    for c in cands[:max_items]:\n",
    "        print(f\"\\n[r={c.rank:2d}] chunk_idx={c.chunk_idx:4d}  score={c.score:.4f}  source={c.source}\")\n",
    "        show_chunk(corpus, c.chunk_idx, max_chars=max_chars)\n",
    "\n",
    "\n",
    "def compare_retrievers_for_query(\n",
    "    query: str,\n",
    "    bm25_index: BM25Index,\n",
    "    dense_index: Optional[DenseIndex],\n",
    "    emb_model,\n",
    "    alpha: float = 0.5,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Запускает BM25 / Dense / Hybrid для одного запроса и печатает результат.\n",
    "    \"\"\"\n",
    "    print(\"#\" * 80)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    bm25_cands = retrieve_bm25(query, bm25_index=bm25_index, k=TOP_K_DEBUG)\n",
    "    print_candidates(\"BM25\", bm25_cands, corpus)\n",
    "\n",
    "    if dense_index is not None and emb_model is not None:\n",
    "        dense_cands = retrieve_dense(query, dense_index=dense_index, emb_model=emb_model, k=TOP_K_DEBUG)\n",
    "        print_candidates(\"Dense\", dense_cands, corpus)\n",
    "\n",
    "        hybrid_cands = retrieve_hybrid(\n",
    "            query,\n",
    "            bm25_index=bm25_index,\n",
    "            dense_index=dense_index,\n",
    "            emb_model=emb_model,\n",
    "            k_bm25=50,\n",
    "            k_dense=50,\n",
    "            k_hybrid=TOP_K_DEBUG,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "        print_candidates(f\"Hybrid (alpha={alpha})\", hybrid_cands, corpus)\n",
    "    else:\n",
    "        print(\"\\n⚠️ Dense/Hybrid пропущены (нет dense_index или emb_model).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c18859",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Примеры запросов для отладки ===\n",
    "# TODO: подставь реальные вопросы/запросы под конкретную задачу.\n",
    "debug_queries = [\n",
    "    \"Что такое градиентный бустинг?\",\n",
    "    \"Когда был запущен первый искусственный спутник Земли?\",\n",
    "    \"Основные идеи метода преобразования Фурье\",\n",
    "]\n",
    "\n",
    "for q in debug_queries:\n",
    "    compare_retrievers_for_query(\n",
    "        query=q,\n",
    "        bm25_index=bm25_index,\n",
    "        dense_index=dense_index,\n",
    "        emb_model=emb_model,\n",
    "        alpha=0.5,   # можно крутить, чтобы смотреть, как меняется выдача\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b3df7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def inspect_bm25_vs_hybrid_for_query(\n",
    "    query: str,\n",
    "    bm25_index: BM25Index,\n",
    "    dense_index: Optional[DenseIndex],\n",
    "    emb_model,\n",
    "    alpha: float = 0.5,\n",
    "    k_debug: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Показывает табличку с кандидатами BM25 vs Hybrid — удобно для просмотра,\n",
    "    какие чанки «поднимаются»/«падают» при переходе к hybrid.\n",
    "    \"\"\"\n",
    "    bm25_cands = retrieve_bm25(query, bm25_index=bm25_index, k=k_debug)\n",
    "    if dense_index is None or emb_model is None:\n",
    "        print(\"Нет dense_index/emb_model, показываем только BM25.\")\n",
    "        df = summarize_candidates(bm25_cands, corpus)\n",
    "        display(df.head(10))\n",
    "        return\n",
    "\n",
    "    hybrid_cands = retrieve_hybrid(\n",
    "        query,\n",
    "        bm25_index=bm25_index,\n",
    "        dense_index=dense_index,\n",
    "        emb_model=emb_model,\n",
    "        k_bm25=k_debug,\n",
    "        k_dense=k_debug,\n",
    "        k_hybrid=k_debug,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "\n",
    "    df_before = summarize_candidates(bm25_cands, corpus)\n",
    "    df_after = summarize_candidates(hybrid_cands, corpus)\n",
    "\n",
    "    print(\"=== BM25 (до hybrid) ===\")\n",
    "    display(df_before.head(10))\n",
    "\n",
    "    print(\"=== Hybrid (после объединения) ===\")\n",
    "    display(df_after.head(10))\n",
    "\n",
    "    print(\"=== Анализ перехода (если нужен) ===\")\n",
    "    transition_df = analyze_stage_transition(\n",
    "        before=bm25_cands,\n",
    "        after=hybrid_cands,\n",
    "        corpus=corpus,\n",
    "    )\n",
    "    display(transition_df.head(10))\n",
    "\n",
    "\n",
    "# Пример использования:\n",
    "inspect_bm25_vs_hybrid_for_query(\n",
    "    query=\"Что такое градиентный бустинг?\",\n",
    "    bm25_index=bm25_index,\n",
    "    dense_index=dense_index,\n",
    "    emb_model=emb_model,\n",
    "    alpha=0.5,\n",
    "    k_debug=30,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
